{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "import sklearn\n",
    "from sklearn import pipeline, preprocessing, feature_extraction\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "y_train = pd.DataFrame(X_train['is_duplicate'])\n",
    "y_train.columns = ['y']\n",
    "del X_train['is_duplicate']\n",
    "\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "folds = []\n",
    "for itr, ite in skf.split(X_train, y_train.y):\n",
    "    folds += [[itr, ite]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train_inter.csv\")\n",
    "\n",
    "X_train['question1'] = X_train['question1'].apply(lambda x: str(x))\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "X_train['question1'] = X_train['question1'].apply(lambda x: x.lower().split())\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: x.lower().split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/test_inter.csv\")\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(lambda x: str(x))\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: str(x))\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(lambda x: x.lower().split())\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = map(lambda x: ' '.join(x), X_train['question1'])\n",
    "X1 = map(lambda x: ' '.join(x), X_train['question2'])\n",
    "Y = map(lambda x: ' '.join(x), X_test['question1'])\n",
    "Y1 = map(lambda x: ' '.join(x), X_test['question2'])\n",
    "\n",
    "hw = HashingVectorizer(n_features=200).fit(X_train['question1'] + X_train['question2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(hw.transform(X).todense())\n",
    "X1 = pd.DataFrame(hw.transform(X1).todense())\n",
    "Y = pd.DataFrame(hw.transform(Y).todense())\n",
    "Y1 = pd.DataFrame(hw.transform(Y1).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(X+X1)\n",
    "\n",
    "X = pd.DataFrame(tfidf.transform(X).todense())\n",
    "X1 = pd.DataFrame(tfidf.transform(X1).todense())\n",
    "Y = pd.DataFrame(tfidf.transform(Y).todense())\n",
    "Y1 = pd.DataFrame(tfidf.transform(Y1).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X], axis=1, join_axes=[X_train.index])\n",
    "del X\n",
    "X_train = pd.concat([X_train, X1], axis=1, join_axes=[X_train.index])\n",
    "del X1\n",
    "X_test = pd.concat([X_test, Y], axis=1, join_axes=[X_test.index])\n",
    "del Y\n",
    "X_test = pd.concat([X_test, Y1], axis=1, join_axes=[X_test.index])\n",
    "del Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train['question1']\n",
    "del X_train['question2']\n",
    "del X_train['qid1']\n",
    "del X_train['qid2']\n",
    "del X_train['id']\n",
    "\n",
    "del X_test['question1']\n",
    "del X_test['question2']\n",
    "del X_test['test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp = abs(X_train.ix[:, 2:202] * X_train.ix[:, -200:])\n",
    "#X_train = pd.concat([X_train, tmp], axis=1, join_axes=[X_train.index])\n",
    "tmp = abs(X_train.ix[:, 2:202] - X_train.ix[:, -200:])\n",
    "X_train = pd.concat([X_train, tmp], axis=1, join_axes=[X_train.index])\n",
    "\n",
    "#tmp = abs(X_test.ix[:, 2:202] * X_test.ix[:, -200:])\n",
    "#X_test = pd.concat([X_test, tmp], axis=1, join_axes=[X_test.index])\n",
    "tmp = abs(X_test.ix[:, 2:202] - X_test.ix[:, -200:])\n",
    "X_test = pd.concat([X_test, tmp], axis=1, join_axes=[X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(\"data/train_inter.csv\")\n",
    "q_train = pd.read_csv(\"data/freq_train.csv\")\n",
    "X_train = pd.concat([X_train, q_train], axis=1)\n",
    "\n",
    "f_train = pd.read_csv(\"data/train_features.csv\", encoding = \"ISO-8859-1\")\n",
    "f_train = f_train.ix[:, 2:]\n",
    "X_train = pd.concat([X_train, f_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_train = pd.read_csv(\"data/f1_train.csv\")\n",
    "X_train = pd.concat([X_train, q_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "      <th>q1_q2_intersect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.023324</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>-0.091902</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>0.337301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.588090</td>\n",
       "      <td>1.012091</td>\n",
       "      <td>0.455910</td>\n",
       "      <td>0.592655</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>0.284010</td>\n",
       "      <td>-0.034444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match    0    1    2    3    4    5    6    7  \\\n",
       "0    0.727273          0.772164  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    0.307692          0.361758  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        ...         jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "0       ...                      1.0          94.023324            0.371408   \n",
       "1       ...                      1.0         177.588090            1.012091   \n",
       "\n",
       "   minkowski_distance  braycurtis_distance  skew_q1vec  skew_q2vec  kur_q1vec  \\\n",
       "0            0.168999             0.186557    0.031817   -0.091902   0.050416   \n",
       "1            0.455910             0.592655    0.008735    0.094704   0.284010   \n",
       "\n",
       "   kur_q2vec  q1_q2_intersect  \n",
       "0   0.337301                0  \n",
       "1  -0.034444                0  \n",
       "\n",
       "[2 rows x 633 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_test = pd.read_csv(\"data/freq_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, q_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_test = pd.read_csv(\"data/test_features.csv\", encoding = \"ISO-8859-1\")\n",
    "f_test = f_test.ix[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, f_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_test = pd.read_csv(\"data/f1_test.csv\")\n",
    "X_test = pd.concat([X_test, q_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "      <th>q1_q2_intersect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.156312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.254264</td>\n",
       "      <td>0.889327</td>\n",
       "      <td>0.407153</td>\n",
       "      <td>0.483565</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.039938</td>\n",
       "      <td>-0.144866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.164904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.512012</td>\n",
       "      <td>0.466698</td>\n",
       "      <td>0.210239</td>\n",
       "      <td>0.245248</td>\n",
       "      <td>-0.017419</td>\n",
       "      <td>-0.046821</td>\n",
       "      <td>0.207580</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match    0    1    2    3    4         5    6    7  \\\n",
       "0    0.266667          0.274019  0.0  0.0  0.0  0.0  0.0 -0.156312  0.0  0.0   \n",
       "1    0.500000          0.480962  0.0  0.0  0.0  0.0  0.0 -0.164904  0.0  0.0   \n",
       "\n",
       "        ...         jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "0       ...                      1.0         164.254264            0.889327   \n",
       "1       ...                      1.0         115.512012            0.466698   \n",
       "\n",
       "   minkowski_distance  braycurtis_distance  skew_q1vec  skew_q2vec  kur_q1vec  \\\n",
       "0            0.407153             0.483565    0.045990    0.009958   0.039938   \n",
       "1            0.210239             0.245248   -0.017419   -0.046821   0.207580   \n",
       "\n",
       "   kur_q2vec  q1_q2_intersect  \n",
       "0  -0.144866                0  \n",
       "1  -0.042937                0  \n",
       "\n",
       "[2 rows x 633 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.633406\teval-logloss:0.633945\n",
      "[15]\ttrain-logloss:0.323145\teval-logloss:0.326977\n",
      "[30]\ttrain-logloss:0.270691\teval-logloss:0.276499\n",
      "[45]\ttrain-logloss:0.255941\teval-logloss:0.263202\n",
      "[60]\ttrain-logloss:0.246739\teval-logloss:0.256193\n",
      "[75]\ttrain-logloss:0.239862\teval-logloss:0.251667\n",
      "[90]\ttrain-logloss:0.234469\teval-logloss:0.248654\n",
      "[105]\ttrain-logloss:0.229885\teval-logloss:0.246465\n",
      "[120]\ttrain-logloss:0.226364\teval-logloss:0.244956\n",
      "[135]\ttrain-logloss:0.223236\teval-logloss:0.243628\n",
      "[150]\ttrain-logloss:0.220392\teval-logloss:0.242614\n",
      "[165]\ttrain-logloss:0.217771\teval-logloss:0.241669\n",
      "[180]\ttrain-logloss:0.215602\teval-logloss:0.240993\n",
      "[195]\ttrain-logloss:0.213443\teval-logloss:0.240306\n",
      "[210]\ttrain-logloss:0.211177\teval-logloss:0.239514\n",
      "[225]\ttrain-logloss:0.209166\teval-logloss:0.238887\n",
      "[240]\ttrain-logloss:0.207445\teval-logloss:0.23856\n",
      "[255]\ttrain-logloss:0.20596\teval-logloss:0.238262\n",
      "[270]\ttrain-logloss:0.203797\teval-logloss:0.237604\n",
      "[285]\ttrain-logloss:0.202477\teval-logloss:0.237331\n",
      "[300]\ttrain-logloss:0.200953\teval-logloss:0.237018\n",
      "[315]\ttrain-logloss:0.199446\teval-logloss:0.23672\n",
      "[330]\ttrain-logloss:0.198027\teval-logloss:0.236361\n",
      "[345]\ttrain-logloss:0.19692\teval-logloss:0.236196\n",
      "[360]\ttrain-logloss:0.195545\teval-logloss:0.235914\n",
      "[375]\ttrain-logloss:0.194598\teval-logloss:0.235799\n",
      "[390]\ttrain-logloss:0.193627\teval-logloss:0.23556\n",
      "[405]\ttrain-logloss:0.192136\teval-logloss:0.235316\n",
      "[420]\ttrain-logloss:0.190982\teval-logloss:0.23512\n",
      "[435]\ttrain-logloss:0.190102\teval-logloss:0.235049\n",
      "[450]\ttrain-logloss:0.189101\teval-logloss:0.234953\n",
      "[465]\ttrain-logloss:0.187933\teval-logloss:0.234687\n",
      "[480]\ttrain-logloss:0.187083\teval-logloss:0.234591\n",
      "[495]\ttrain-logloss:0.185828\teval-logloss:0.234312\n",
      "[510]\ttrain-logloss:0.184724\teval-logloss:0.23412\n",
      "[525]\ttrain-logloss:0.18398\teval-logloss:0.234075\n",
      "[540]\ttrain-logloss:0.18314\teval-logloss:0.234063\n",
      "[555]\ttrain-logloss:0.18208\teval-logloss:0.233963\n",
      "[570]\ttrain-logloss:0.180633\teval-logloss:0.23355\n",
      "[585]\ttrain-logloss:0.179973\teval-logloss:0.233517\n",
      "[600]\ttrain-logloss:0.179266\teval-logloss:0.233441\n",
      "[615]\ttrain-logloss:0.178555\teval-logloss:0.2334\n",
      "[630]\ttrain-logloss:0.17755\teval-logloss:0.233269\n",
      "[645]\ttrain-logloss:0.17659\teval-logloss:0.233139\n",
      "[660]\ttrain-logloss:0.17567\teval-logloss:0.232979\n",
      "[675]\ttrain-logloss:0.175114\teval-logloss:0.232975\n",
      "[690]\ttrain-logloss:0.174443\teval-logloss:0.232931\n",
      "[705]\ttrain-logloss:0.173623\teval-logloss:0.232919\n",
      "[720]\ttrain-logloss:0.172396\teval-logloss:0.232763\n",
      "[735]\ttrain-logloss:0.171543\teval-logloss:0.232623\n",
      "[750]\ttrain-logloss:0.170951\teval-logloss:0.23258\n",
      "[765]\ttrain-logloss:0.170256\teval-logloss:0.232452\n",
      "[780]\ttrain-logloss:0.169501\teval-logloss:0.232389\n",
      "[795]\ttrain-logloss:0.16884\teval-logloss:0.232411\n",
      "[810]\ttrain-logloss:0.168083\teval-logloss:0.232384\n",
      "[825]\ttrain-logloss:0.16744\teval-logloss:0.232351\n",
      "[840]\ttrain-logloss:0.166645\teval-logloss:0.232324\n",
      "[855]\ttrain-logloss:0.165357\teval-logloss:0.232083\n",
      "[870]\ttrain-logloss:0.164573\teval-logloss:0.231973\n",
      "[885]\ttrain-logloss:0.164082\teval-logloss:0.231983\n",
      "[900]\ttrain-logloss:0.163338\teval-logloss:0.231927\n",
      "[915]\ttrain-logloss:0.162713\teval-logloss:0.231884\n",
      "[930]\ttrain-logloss:0.162135\teval-logloss:0.231808\n",
      "[945]\ttrain-logloss:0.161523\teval-logloss:0.231787\n",
      "[960]\ttrain-logloss:0.160736\teval-logloss:0.231671\n",
      "[975]\ttrain-logloss:0.159656\teval-logloss:0.231478\n",
      "[990]\ttrain-logloss:0.159071\teval-logloss:0.231498\n",
      "[1005]\ttrain-logloss:0.158181\teval-logloss:0.231405\n",
      "[1020]\ttrain-logloss:0.157622\teval-logloss:0.231369\n",
      "[1035]\ttrain-logloss:0.157046\teval-logloss:0.231326\n",
      "[1050]\ttrain-logloss:0.156266\teval-logloss:0.23121\n",
      "[1065]\ttrain-logloss:0.155618\teval-logloss:0.231225\n",
      "[1080]\ttrain-logloss:0.154482\teval-logloss:0.231064\n",
      "[1095]\ttrain-logloss:0.153786\teval-logloss:0.231015\n",
      "[1110]\ttrain-logloss:0.1531\teval-logloss:0.230957\n",
      "[1125]\ttrain-logloss:0.152494\teval-logloss:0.230975\n",
      "[1140]\ttrain-logloss:0.151868\teval-logloss:0.230973\n",
      "[1155]\ttrain-logloss:0.151334\teval-logloss:0.230954\n",
      "[1170]\ttrain-logloss:0.150612\teval-logloss:0.230929\n",
      "[1185]\ttrain-logloss:0.150035\teval-logloss:0.230859\n",
      "[1200]\ttrain-logloss:0.149473\teval-logloss:0.230842\n",
      "[1215]\ttrain-logloss:0.148937\teval-logloss:0.230799\n",
      "[1230]\ttrain-logloss:0.148\teval-logloss:0.230637\n",
      "[1245]\ttrain-logloss:0.147379\teval-logloss:0.230558\n",
      "[1260]\ttrain-logloss:0.146549\teval-logloss:0.230411\n",
      "[1275]\ttrain-logloss:0.145885\teval-logloss:0.230445\n",
      "[1290]\ttrain-logloss:0.145417\teval-logloss:0.230398\n",
      "[1305]\ttrain-logloss:0.144886\teval-logloss:0.23037\n",
      "[1320]\ttrain-logloss:0.144321\teval-logloss:0.230336\n",
      "[1335]\ttrain-logloss:0.143676\teval-logloss:0.23027\n",
      "[1350]\ttrain-logloss:0.143076\teval-logloss:0.230251\n",
      "[1365]\ttrain-logloss:0.142636\teval-logloss:0.230282\n",
      "[1380]\ttrain-logloss:0.142007\teval-logloss:0.230218\n",
      "[1395]\ttrain-logloss:0.141478\teval-logloss:0.230192\n",
      "[1410]\ttrain-logloss:0.140772\teval-logloss:0.230123\n",
      "[1425]\ttrain-logloss:0.140102\teval-logloss:0.230085\n",
      "[1440]\ttrain-logloss:0.139415\teval-logloss:0.230017\n",
      "[1455]\ttrain-logloss:0.138698\teval-logloss:0.229972\n",
      "[1470]\ttrain-logloss:0.138214\teval-logloss:0.229913\n",
      "[1485]\ttrain-logloss:0.137678\teval-logloss:0.22985\n",
      "[1500]\ttrain-logloss:0.137355\teval-logloss:0.229861\n",
      "[1515]\ttrain-logloss:0.136758\teval-logloss:0.229806\n",
      "[1530]\ttrain-logloss:0.136381\teval-logloss:0.229811\n",
      "[1545]\ttrain-logloss:0.135983\teval-logloss:0.229825\n",
      "[1560]\ttrain-logloss:0.135414\teval-logloss:0.229797\n",
      "[1575]\ttrain-logloss:0.134836\teval-logloss:0.229745\n",
      "[1590]\ttrain-logloss:0.134306\teval-logloss:0.229736\n",
      "[1605]\ttrain-logloss:0.133611\teval-logloss:0.2297\n",
      "[1620]\ttrain-logloss:0.132947\teval-logloss:0.229634\n",
      "[1635]\ttrain-logloss:0.132401\teval-logloss:0.229616\n",
      "[1650]\ttrain-logloss:0.131913\teval-logloss:0.229639\n",
      "[1665]\ttrain-logloss:0.131364\teval-logloss:0.229651\n",
      "[1680]\ttrain-logloss:0.130401\teval-logloss:0.22953\n",
      "[1695]\ttrain-logloss:0.129807\teval-logloss:0.229525\n",
      "[1710]\ttrain-logloss:0.129276\teval-logloss:0.229515\n",
      "[1725]\ttrain-logloss:0.128792\teval-logloss:0.229483\n",
      "[1740]\ttrain-logloss:0.128258\teval-logloss:0.229451\n",
      "[1755]\ttrain-logloss:0.1278\teval-logloss:0.229427\n",
      "[1770]\ttrain-logloss:0.127357\teval-logloss:0.229436\n",
      "[1785]\ttrain-logloss:0.126939\teval-logloss:0.22941\n",
      "[1800]\ttrain-logloss:0.126396\teval-logloss:0.229371\n",
      "[1815]\ttrain-logloss:0.125638\teval-logloss:0.22924\n",
      "[1830]\ttrain-logloss:0.12521\teval-logloss:0.229242\n",
      "[1845]\ttrain-logloss:0.124563\teval-logloss:0.229257\n",
      "[1860]\ttrain-logloss:0.123843\teval-logloss:0.229152\n",
      "[1875]\ttrain-logloss:0.123394\teval-logloss:0.229113\n",
      "[1890]\ttrain-logloss:0.122828\teval-logloss:0.229052\n",
      "[1905]\ttrain-logloss:0.122425\teval-logloss:0.229022\n",
      "[1920]\ttrain-logloss:0.12196\teval-logloss:0.228992\n",
      "[1935]\ttrain-logloss:0.121326\teval-logloss:0.228982\n",
      "[1950]\ttrain-logloss:0.120847\teval-logloss:0.22895\n",
      "[1965]\ttrain-logloss:0.120462\teval-logloss:0.228934\n",
      "[1980]\ttrain-logloss:0.120002\teval-logloss:0.228874\n",
      "[1995]\ttrain-logloss:0.119385\teval-logloss:0.228869\n",
      "[0]\ttrain-logloss:0.633453\teval-logloss:0.633743\n",
      "[15]\ttrain-logloss:0.322959\teval-logloss:0.326479\n",
      "[30]\ttrain-logloss:0.270742\teval-logloss:0.276697\n",
      "[45]\ttrain-logloss:0.255729\teval-logloss:0.263662\n",
      "[60]\ttrain-logloss:0.246673\teval-logloss:0.257076\n",
      "[75]\ttrain-logloss:0.23973\teval-logloss:0.252889\n",
      "[90]\ttrain-logloss:0.233879\teval-logloss:0.249907\n",
      "[105]\ttrain-logloss:0.229412\teval-logloss:0.247656\n",
      "[120]\ttrain-logloss:0.225568\teval-logloss:0.246027\n",
      "[135]\ttrain-logloss:0.222264\teval-logloss:0.244752\n",
      "[150]\ttrain-logloss:0.219234\teval-logloss:0.243668\n",
      "[165]\ttrain-logloss:0.216813\teval-logloss:0.242924\n",
      "[180]\ttrain-logloss:0.214281\teval-logloss:0.24211\n",
      "[195]\ttrain-logloss:0.21237\teval-logloss:0.241628\n",
      "[210]\ttrain-logloss:0.210134\teval-logloss:0.24104\n",
      "[225]\ttrain-logloss:0.208408\teval-logloss:0.240675\n",
      "[240]\ttrain-logloss:0.206329\teval-logloss:0.239919\n",
      "[255]\ttrain-logloss:0.204902\teval-logloss:0.239637\n",
      "[270]\ttrain-logloss:0.203265\teval-logloss:0.239312\n",
      "[285]\ttrain-logloss:0.201575\teval-logloss:0.238933\n",
      "[300]\ttrain-logloss:0.200386\teval-logloss:0.238683\n",
      "[315]\ttrain-logloss:0.198537\teval-logloss:0.238186\n",
      "[330]\ttrain-logloss:0.197356\teval-logloss:0.237982\n",
      "[345]\ttrain-logloss:0.196343\teval-logloss:0.237838\n",
      "[360]\ttrain-logloss:0.195158\teval-logloss:0.237641\n",
      "[375]\ttrain-logloss:0.193926\teval-logloss:0.237535\n",
      "[390]\ttrain-logloss:0.192729\teval-logloss:0.237269\n",
      "[405]\ttrain-logloss:0.191576\teval-logloss:0.237119\n",
      "[420]\ttrain-logloss:0.190437\teval-logloss:0.236941\n",
      "[435]\ttrain-logloss:0.189305\teval-logloss:0.236767\n",
      "[450]\ttrain-logloss:0.188059\teval-logloss:0.236526\n",
      "[465]\ttrain-logloss:0.187155\teval-logloss:0.236376\n",
      "[480]\ttrain-logloss:0.186163\teval-logloss:0.236142\n",
      "[495]\ttrain-logloss:0.185181\teval-logloss:0.235953\n",
      "[510]\ttrain-logloss:0.183799\teval-logloss:0.235692\n",
      "[525]\ttrain-logloss:0.182884\teval-logloss:0.235554\n",
      "[540]\ttrain-logloss:0.18219\teval-logloss:0.235462\n",
      "[555]\ttrain-logloss:0.181292\teval-logloss:0.235404\n",
      "[570]\ttrain-logloss:0.180426\teval-logloss:0.235361\n",
      "[585]\ttrain-logloss:0.179659\teval-logloss:0.235315\n",
      "[600]\ttrain-logloss:0.178794\teval-logloss:0.235181\n",
      "[615]\ttrain-logloss:0.177623\teval-logloss:0.235071\n",
      "[630]\ttrain-logloss:0.1769\teval-logloss:0.234967\n",
      "[645]\ttrain-logloss:0.175589\teval-logloss:0.234701\n",
      "[660]\ttrain-logloss:0.174432\teval-logloss:0.234496\n",
      "[675]\ttrain-logloss:0.173587\teval-logloss:0.23435\n",
      "[690]\ttrain-logloss:0.172915\teval-logloss:0.23432\n",
      "[705]\ttrain-logloss:0.172203\teval-logloss:0.234281\n",
      "[720]\ttrain-logloss:0.171556\teval-logloss:0.234231\n",
      "[735]\ttrain-logloss:0.170772\teval-logloss:0.23416\n",
      "[750]\ttrain-logloss:0.169768\teval-logloss:0.234002\n",
      "[765]\ttrain-logloss:0.168969\teval-logloss:0.233933\n",
      "[780]\ttrain-logloss:0.168334\teval-logloss:0.233906\n",
      "[795]\ttrain-logloss:0.167461\teval-logloss:0.233793\n",
      "[810]\ttrain-logloss:0.166938\teval-logloss:0.233756\n",
      "[825]\ttrain-logloss:0.166233\teval-logloss:0.233699\n",
      "[840]\ttrain-logloss:0.165556\teval-logloss:0.233544\n",
      "[855]\ttrain-logloss:0.164853\teval-logloss:0.23348\n",
      "[870]\ttrain-logloss:0.164393\teval-logloss:0.233492\n",
      "[885]\ttrain-logloss:0.163437\teval-logloss:0.233353\n",
      "[900]\ttrain-logloss:0.162481\teval-logloss:0.233213\n",
      "[915]\ttrain-logloss:0.161508\teval-logloss:0.233065\n",
      "[930]\ttrain-logloss:0.160959\teval-logloss:0.233036\n",
      "[945]\ttrain-logloss:0.160241\teval-logloss:0.232939\n",
      "[960]\ttrain-logloss:0.159595\teval-logloss:0.232926\n",
      "[975]\ttrain-logloss:0.15885\teval-logloss:0.232907\n",
      "[990]\ttrain-logloss:0.158001\teval-logloss:0.232801\n",
      "[1005]\ttrain-logloss:0.157091\teval-logloss:0.232706\n",
      "[1020]\ttrain-logloss:0.156541\teval-logloss:0.232701\n",
      "[1035]\ttrain-logloss:0.155858\teval-logloss:0.232617\n",
      "[1050]\ttrain-logloss:0.155155\teval-logloss:0.232538\n",
      "[1065]\ttrain-logloss:0.154181\teval-logloss:0.232394\n",
      "[1080]\ttrain-logloss:0.153707\teval-logloss:0.232381\n",
      "[1095]\ttrain-logloss:0.15314\teval-logloss:0.232395\n",
      "[1110]\ttrain-logloss:0.152562\teval-logloss:0.232364\n",
      "[1125]\ttrain-logloss:0.152058\teval-logloss:0.232356\n",
      "[1140]\ttrain-logloss:0.151612\teval-logloss:0.23238\n",
      "[1155]\ttrain-logloss:0.150836\teval-logloss:0.232317\n",
      "[1170]\ttrain-logloss:0.149783\teval-logloss:0.232057\n",
      "[1185]\ttrain-logloss:0.149172\teval-logloss:0.232084\n",
      "[1200]\ttrain-logloss:0.148697\teval-logloss:0.232075\n",
      "[1215]\ttrain-logloss:0.14804\teval-logloss:0.231986\n",
      "[1230]\ttrain-logloss:0.14718\teval-logloss:0.231832\n",
      "[1245]\ttrain-logloss:0.146362\teval-logloss:0.231682\n",
      "[1260]\ttrain-logloss:0.14575\teval-logloss:0.231651\n",
      "[1275]\ttrain-logloss:0.144955\teval-logloss:0.231598\n",
      "[1290]\ttrain-logloss:0.144465\teval-logloss:0.231635\n",
      "[1305]\ttrain-logloss:0.143991\teval-logloss:0.231632\n",
      "[1320]\ttrain-logloss:0.143513\teval-logloss:0.231636\n",
      "[1335]\ttrain-logloss:0.142863\teval-logloss:0.23162\n",
      "[1350]\ttrain-logloss:0.142249\teval-logloss:0.231523\n",
      "[1365]\ttrain-logloss:0.141717\teval-logloss:0.231516\n",
      "[1380]\ttrain-logloss:0.141044\teval-logloss:0.23143\n",
      "[1395]\ttrain-logloss:0.140545\teval-logloss:0.23142\n",
      "[1410]\ttrain-logloss:0.140006\teval-logloss:0.231376\n",
      "[1425]\ttrain-logloss:0.139616\teval-logloss:0.231392\n",
      "[1440]\ttrain-logloss:0.138968\teval-logloss:0.231366\n",
      "[1455]\ttrain-logloss:0.138452\teval-logloss:0.23136\n",
      "[1470]\ttrain-logloss:0.137803\teval-logloss:0.231308\n",
      "[1485]\ttrain-logloss:0.137311\teval-logloss:0.231286\n",
      "[1500]\ttrain-logloss:0.136606\teval-logloss:0.231205\n",
      "[1515]\ttrain-logloss:0.136166\teval-logloss:0.231246\n",
      "[1530]\ttrain-logloss:0.135652\teval-logloss:0.231221\n",
      "[1545]\ttrain-logloss:0.135054\teval-logloss:0.231244\n",
      "[1560]\ttrain-logloss:0.134446\teval-logloss:0.231204\n",
      "[1575]\ttrain-logloss:0.133954\teval-logloss:0.231166\n",
      "[1590]\ttrain-logloss:0.133327\teval-logloss:0.23114\n",
      "[1605]\ttrain-logloss:0.132662\teval-logloss:0.231067\n",
      "[1620]\ttrain-logloss:0.132313\teval-logloss:0.231093\n",
      "[1635]\ttrain-logloss:0.131673\teval-logloss:0.231011\n",
      "[1650]\ttrain-logloss:0.131006\teval-logloss:0.230955\n",
      "[1665]\ttrain-logloss:0.130512\teval-logloss:0.230931\n",
      "[1680]\ttrain-logloss:0.130095\teval-logloss:0.230914\n",
      "[1695]\ttrain-logloss:0.129594\teval-logloss:0.230923\n",
      "[1710]\ttrain-logloss:0.129114\teval-logloss:0.230862\n",
      "[1725]\ttrain-logloss:0.128683\teval-logloss:0.230832\n",
      "[1740]\ttrain-logloss:0.128256\teval-logloss:0.230785\n",
      "[1755]\ttrain-logloss:0.127582\teval-logloss:0.230757\n",
      "[1770]\ttrain-logloss:0.127127\teval-logloss:0.230793\n",
      "[1785]\ttrain-logloss:0.126403\teval-logloss:0.230702\n",
      "[1800]\ttrain-logloss:0.125907\teval-logloss:0.23069\n",
      "[1815]\ttrain-logloss:0.125204\teval-logloss:0.230596\n",
      "[1830]\ttrain-logloss:0.124662\teval-logloss:0.230568\n",
      "[1845]\ttrain-logloss:0.124135\teval-logloss:0.230573\n",
      "[1860]\ttrain-logloss:0.123612\teval-logloss:0.230617\n",
      "[1875]\ttrain-logloss:0.122744\teval-logloss:0.23057\n",
      "[1890]\ttrain-logloss:0.122071\teval-logloss:0.23057\n",
      "[1905]\ttrain-logloss:0.121444\teval-logloss:0.230566\n",
      "[1920]\ttrain-logloss:0.120848\teval-logloss:0.230533\n",
      "[1935]\ttrain-logloss:0.120377\teval-logloss:0.230521\n",
      "[1950]\ttrain-logloss:0.120048\teval-logloss:0.230474\n",
      "[1965]\ttrain-logloss:0.11969\teval-logloss:0.230465\n",
      "[1980]\ttrain-logloss:0.119148\teval-logloss:0.230432\n",
      "[1995]\ttrain-logloss:0.118752\teval-logloss:0.230438\n",
      "[0]\ttrain-logloss:0.633463\teval-logloss:0.633825\n",
      "[15]\ttrain-logloss:0.323199\teval-logloss:0.326594\n",
      "[30]\ttrain-logloss:0.271089\teval-logloss:0.276761\n",
      "[45]\ttrain-logloss:0.256496\teval-logloss:0.263781\n",
      "[60]\ttrain-logloss:0.247163\teval-logloss:0.256725\n",
      "[75]\ttrain-logloss:0.240014\teval-logloss:0.252151\n",
      "[90]\ttrain-logloss:0.234168\teval-logloss:0.248844\n",
      "[105]\ttrain-logloss:0.22991\teval-logloss:0.246721\n",
      "[120]\ttrain-logloss:0.226176\teval-logloss:0.245146\n",
      "[135]\ttrain-logloss:0.222932\teval-logloss:0.243677\n",
      "[150]\ttrain-logloss:0.219949\teval-logloss:0.242568\n",
      "[165]\ttrain-logloss:0.217155\teval-logloss:0.241419\n",
      "[180]\ttrain-logloss:0.214814\teval-logloss:0.240665\n",
      "[195]\ttrain-logloss:0.212288\teval-logloss:0.239806\n",
      "[210]\ttrain-logloss:0.21029\teval-logloss:0.239329\n",
      "[225]\ttrain-logloss:0.208169\teval-logloss:0.238565\n",
      "[240]\ttrain-logloss:0.206268\teval-logloss:0.238103\n",
      "[255]\ttrain-logloss:0.204673\teval-logloss:0.237779\n",
      "[270]\ttrain-logloss:0.203319\teval-logloss:0.237464\n",
      "[285]\ttrain-logloss:0.201978\teval-logloss:0.23716\n",
      "[300]\ttrain-logloss:0.200439\teval-logloss:0.236786\n",
      "[315]\ttrain-logloss:0.199163\teval-logloss:0.236569\n",
      "[330]\ttrain-logloss:0.197827\teval-logloss:0.236338\n",
      "[345]\ttrain-logloss:0.196641\teval-logloss:0.236091\n",
      "[360]\ttrain-logloss:0.195103\teval-logloss:0.235738\n",
      "[375]\ttrain-logloss:0.193808\teval-logloss:0.235473\n",
      "[390]\ttrain-logloss:0.192766\teval-logloss:0.23533\n",
      "[405]\ttrain-logloss:0.191604\teval-logloss:0.235176\n",
      "[420]\ttrain-logloss:0.189954\teval-logloss:0.23485\n",
      "[435]\ttrain-logloss:0.188765\teval-logloss:0.234643\n",
      "[450]\ttrain-logloss:0.187935\teval-logloss:0.234499\n",
      "[465]\ttrain-logloss:0.187112\teval-logloss:0.234424\n",
      "[480]\ttrain-logloss:0.185854\teval-logloss:0.234238\n",
      "[495]\ttrain-logloss:0.184844\teval-logloss:0.234049\n",
      "[510]\ttrain-logloss:0.183983\teval-logloss:0.233985\n",
      "[525]\ttrain-logloss:0.183061\teval-logloss:0.233888\n",
      "[540]\ttrain-logloss:0.182237\teval-logloss:0.233832\n",
      "[555]\ttrain-logloss:0.181522\teval-logloss:0.233744\n",
      "[570]\ttrain-logloss:0.180255\teval-logloss:0.233495\n",
      "[585]\ttrain-logloss:0.179187\teval-logloss:0.233289\n",
      "[600]\ttrain-logloss:0.178436\teval-logloss:0.233247\n",
      "[615]\ttrain-logloss:0.17759\teval-logloss:0.233081\n",
      "[630]\ttrain-logloss:0.176724\teval-logloss:0.233009\n",
      "[645]\ttrain-logloss:0.175799\teval-logloss:0.232869\n",
      "[660]\ttrain-logloss:0.174962\teval-logloss:0.232701\n",
      "[675]\ttrain-logloss:0.174154\teval-logloss:0.232616\n",
      "[690]\ttrain-logloss:0.173522\teval-logloss:0.232602\n",
      "[705]\ttrain-logloss:0.172405\teval-logloss:0.232428\n",
      "[720]\ttrain-logloss:0.17169\teval-logloss:0.232296\n",
      "[735]\ttrain-logloss:0.170689\teval-logloss:0.232201\n",
      "[750]\ttrain-logloss:0.170083\teval-logloss:0.232235\n",
      "[765]\ttrain-logloss:0.169254\teval-logloss:0.232139\n",
      "[780]\ttrain-logloss:0.168616\teval-logloss:0.232113\n",
      "[795]\ttrain-logloss:0.167909\teval-logloss:0.232077\n",
      "[810]\ttrain-logloss:0.167226\teval-logloss:0.232041\n",
      "[825]\ttrain-logloss:0.166639\teval-logloss:0.232015\n",
      "[840]\ttrain-logloss:0.165812\teval-logloss:0.231933\n",
      "[855]\ttrain-logloss:0.165077\teval-logloss:0.231913\n",
      "[870]\ttrain-logloss:0.164075\teval-logloss:0.231811\n",
      "[885]\ttrain-logloss:0.163271\teval-logloss:0.231728\n",
      "[900]\ttrain-logloss:0.162758\teval-logloss:0.231705\n",
      "[915]\ttrain-logloss:0.161998\teval-logloss:0.231654\n",
      "[930]\ttrain-logloss:0.161482\teval-logloss:0.231622\n",
      "[945]\ttrain-logloss:0.160587\teval-logloss:0.231566\n",
      "[960]\ttrain-logloss:0.159822\teval-logloss:0.231494\n",
      "[975]\ttrain-logloss:0.159351\teval-logloss:0.231452\n",
      "[990]\ttrain-logloss:0.158567\teval-logloss:0.231447\n",
      "[1005]\ttrain-logloss:0.157718\teval-logloss:0.231394\n",
      "[1020]\ttrain-logloss:0.156877\teval-logloss:0.231294\n",
      "[1035]\ttrain-logloss:0.156042\teval-logloss:0.231213\n",
      "[1050]\ttrain-logloss:0.155218\teval-logloss:0.231154\n",
      "[1065]\ttrain-logloss:0.154705\teval-logloss:0.231128\n",
      "[1080]\ttrain-logloss:0.153664\teval-logloss:0.230959\n",
      "[1095]\ttrain-logloss:0.152981\teval-logloss:0.23084\n",
      "[1110]\ttrain-logloss:0.152404\teval-logloss:0.230822\n",
      "[1125]\ttrain-logloss:0.151828\teval-logloss:0.23084\n",
      "[1140]\ttrain-logloss:0.151296\teval-logloss:0.230845\n",
      "[1155]\ttrain-logloss:0.150958\teval-logloss:0.230812\n",
      "[1170]\ttrain-logloss:0.15019\teval-logloss:0.230807\n",
      "[1185]\ttrain-logloss:0.149342\teval-logloss:0.230749\n",
      "[1200]\ttrain-logloss:0.148903\teval-logloss:0.230702\n",
      "[1215]\ttrain-logloss:0.147923\teval-logloss:0.230575\n",
      "[1230]\ttrain-logloss:0.147151\teval-logloss:0.230575\n",
      "[1245]\ttrain-logloss:0.146391\teval-logloss:0.230477\n",
      "[1260]\ttrain-logloss:0.145868\teval-logloss:0.230411\n",
      "[1275]\ttrain-logloss:0.145257\teval-logloss:0.230365\n",
      "[1290]\ttrain-logloss:0.14484\teval-logloss:0.230336\n",
      "[1305]\ttrain-logloss:0.14395\teval-logloss:0.230234\n",
      "[1320]\ttrain-logloss:0.14348\teval-logloss:0.230125\n",
      "[1335]\ttrain-logloss:0.142823\teval-logloss:0.230027\n",
      "[1350]\ttrain-logloss:0.142162\teval-logloss:0.230018\n",
      "[1365]\ttrain-logloss:0.141445\teval-logloss:0.229942\n",
      "[1380]\ttrain-logloss:0.140613\teval-logloss:0.229909\n",
      "[1395]\ttrain-logloss:0.140233\teval-logloss:0.229901\n",
      "[1410]\ttrain-logloss:0.139867\teval-logloss:0.229929\n",
      "[1425]\ttrain-logloss:0.139276\teval-logloss:0.229848\n",
      "[1440]\ttrain-logloss:0.138697\teval-logloss:0.229823\n",
      "[1455]\ttrain-logloss:0.138114\teval-logloss:0.229813\n",
      "[1470]\ttrain-logloss:0.137519\teval-logloss:0.22975\n",
      "[1485]\ttrain-logloss:0.136761\teval-logloss:0.229701\n",
      "[1500]\ttrain-logloss:0.13623\teval-logloss:0.229718\n",
      "[1515]\ttrain-logloss:0.135639\teval-logloss:0.229724\n",
      "[1530]\ttrain-logloss:0.134746\teval-logloss:0.229672\n",
      "[1545]\ttrain-logloss:0.134286\teval-logloss:0.229655\n",
      "[1560]\ttrain-logloss:0.133872\teval-logloss:0.22963\n",
      "[1575]\ttrain-logloss:0.133281\teval-logloss:0.229595\n",
      "[1590]\ttrain-logloss:0.132772\teval-logloss:0.229568\n",
      "[1605]\ttrain-logloss:0.132376\teval-logloss:0.229557\n",
      "[1620]\ttrain-logloss:0.131933\teval-logloss:0.229554\n",
      "[1635]\ttrain-logloss:0.130908\teval-logloss:0.22938\n",
      "[1650]\ttrain-logloss:0.130351\teval-logloss:0.229393\n",
      "[1665]\ttrain-logloss:0.129857\teval-logloss:0.229393\n",
      "[1680]\ttrain-logloss:0.129383\teval-logloss:0.229403\n",
      "[1695]\ttrain-logloss:0.12901\teval-logloss:0.229399\n",
      "[1710]\ttrain-logloss:0.128277\teval-logloss:0.229355\n",
      "[1725]\ttrain-logloss:0.127752\teval-logloss:0.229292\n",
      "[1740]\ttrain-logloss:0.127387\teval-logloss:0.229267\n",
      "[1755]\ttrain-logloss:0.126759\teval-logloss:0.229194\n",
      "[1770]\ttrain-logloss:0.12619\teval-logloss:0.229169\n",
      "[1785]\ttrain-logloss:0.125603\teval-logloss:0.229144\n",
      "[1800]\ttrain-logloss:0.125147\teval-logloss:0.229102\n",
      "[1815]\ttrain-logloss:0.124592\teval-logloss:0.229056\n",
      "[1830]\ttrain-logloss:0.124046\teval-logloss:0.229016\n",
      "[1845]\ttrain-logloss:0.123651\teval-logloss:0.228987\n",
      "[1860]\ttrain-logloss:0.123037\teval-logloss:0.228934\n",
      "[1875]\ttrain-logloss:0.122685\teval-logloss:0.228954\n",
      "[1890]\ttrain-logloss:0.122241\teval-logloss:0.228935\n",
      "[1905]\ttrain-logloss:0.121866\teval-logloss:0.228938\n",
      "[1920]\ttrain-logloss:0.121533\teval-logloss:0.228931\n",
      "[1935]\ttrain-logloss:0.121107\teval-logloss:0.228916\n",
      "[1950]\ttrain-logloss:0.120748\teval-logloss:0.228933\n",
      "[1965]\ttrain-logloss:0.1203\teval-logloss:0.22894\n",
      "[1980]\ttrain-logloss:0.119899\teval-logloss:0.22893\n",
      "[1995]\ttrain-logloss:0.119207\teval-logloss:0.228933\n",
      "[0]\ttrain-logloss:0.633546\teval-logloss:0.633483\n",
      "[15]\ttrain-logloss:0.323689\teval-logloss:0.324801\n",
      "[30]\ttrain-logloss:0.271697\teval-logloss:0.27445\n",
      "[45]\ttrain-logloss:0.256918\teval-logloss:0.261118\n",
      "[60]\ttrain-logloss:0.247406\teval-logloss:0.253837\n",
      "[75]\ttrain-logloss:0.240702\teval-logloss:0.249455\n",
      "[90]\ttrain-logloss:0.234971\teval-logloss:0.246018\n",
      "[105]\ttrain-logloss:0.230958\teval-logloss:0.244084\n",
      "[120]\ttrain-logloss:0.22709\teval-logloss:0.242374\n",
      "[135]\ttrain-logloss:0.224093\teval-logloss:0.241322\n",
      "[150]\ttrain-logloss:0.220809\teval-logloss:0.240064\n",
      "[165]\ttrain-logloss:0.21826\teval-logloss:0.239219\n",
      "[180]\ttrain-logloss:0.215713\teval-logloss:0.238321\n",
      "[195]\ttrain-logloss:0.213573\teval-logloss:0.237776\n",
      "[210]\ttrain-logloss:0.211389\teval-logloss:0.237037\n",
      "[225]\ttrain-logloss:0.209112\teval-logloss:0.236306\n",
      "[240]\ttrain-logloss:0.207309\teval-logloss:0.235801\n",
      "[255]\ttrain-logloss:0.205663\teval-logloss:0.235466\n",
      "[270]\ttrain-logloss:0.204214\teval-logloss:0.235159\n",
      "[285]\ttrain-logloss:0.202343\teval-logloss:0.234803\n",
      "[300]\ttrain-logloss:0.200947\teval-logloss:0.234556\n",
      "[315]\ttrain-logloss:0.199792\teval-logloss:0.234343\n",
      "[330]\ttrain-logloss:0.19815\teval-logloss:0.23397\n",
      "[345]\ttrain-logloss:0.196771\teval-logloss:0.233569\n",
      "[360]\ttrain-logloss:0.19544\teval-logloss:0.233285\n",
      "[375]\ttrain-logloss:0.194335\teval-logloss:0.233127\n",
      "[390]\ttrain-logloss:0.193125\teval-logloss:0.232939\n",
      "[405]\ttrain-logloss:0.192303\teval-logloss:0.232798\n",
      "[420]\ttrain-logloss:0.191344\teval-logloss:0.232692\n",
      "[435]\ttrain-logloss:0.190172\teval-logloss:0.232549\n",
      "[450]\ttrain-logloss:0.189248\teval-logloss:0.23242\n",
      "[465]\ttrain-logloss:0.18827\teval-logloss:0.232256\n",
      "[480]\ttrain-logloss:0.187005\teval-logloss:0.232087\n",
      "[495]\ttrain-logloss:0.186131\teval-logloss:0.231994\n",
      "[510]\ttrain-logloss:0.184784\teval-logloss:0.231703\n",
      "[525]\ttrain-logloss:0.18354\teval-logloss:0.231594\n",
      "[540]\ttrain-logloss:0.182833\teval-logloss:0.231554\n",
      "[555]\ttrain-logloss:0.181688\teval-logloss:0.231304\n",
      "[570]\ttrain-logloss:0.180811\teval-logloss:0.23124\n",
      "[585]\ttrain-logloss:0.180037\teval-logloss:0.231209\n",
      "[600]\ttrain-logloss:0.179161\teval-logloss:0.231108\n",
      "[615]\ttrain-logloss:0.178386\teval-logloss:0.231032\n",
      "[630]\ttrain-logloss:0.177478\teval-logloss:0.230877\n",
      "[645]\ttrain-logloss:0.176606\teval-logloss:0.230785\n",
      "[660]\ttrain-logloss:0.175885\teval-logloss:0.23078\n",
      "[675]\ttrain-logloss:0.174885\teval-logloss:0.230637\n",
      "[690]\ttrain-logloss:0.17416\teval-logloss:0.230542\n",
      "[705]\ttrain-logloss:0.17342\teval-logloss:0.230491\n",
      "[720]\ttrain-logloss:0.172703\teval-logloss:0.23042\n",
      "[735]\ttrain-logloss:0.17171\teval-logloss:0.230297\n",
      "[750]\ttrain-logloss:0.171111\teval-logloss:0.230307\n",
      "[765]\ttrain-logloss:0.170121\teval-logloss:0.230301\n",
      "[780]\ttrain-logloss:0.16902\teval-logloss:0.230118\n",
      "[795]\ttrain-logloss:0.168427\teval-logloss:0.230089\n",
      "[810]\ttrain-logloss:0.167675\teval-logloss:0.230019\n",
      "[825]\ttrain-logloss:0.166862\teval-logloss:0.22991\n",
      "[840]\ttrain-logloss:0.166167\teval-logloss:0.22979\n",
      "[855]\ttrain-logloss:0.165068\teval-logloss:0.22962\n",
      "[870]\ttrain-logloss:0.164595\teval-logloss:0.229609\n",
      "[885]\ttrain-logloss:0.163866\teval-logloss:0.229554\n",
      "[900]\ttrain-logloss:0.163108\teval-logloss:0.229467\n",
      "[915]\ttrain-logloss:0.162375\teval-logloss:0.229395\n",
      "[930]\ttrain-logloss:0.16164\teval-logloss:0.229365\n",
      "[945]\ttrain-logloss:0.160784\teval-logloss:0.229203\n",
      "[960]\ttrain-logloss:0.159911\teval-logloss:0.229101\n",
      "[975]\ttrain-logloss:0.159282\teval-logloss:0.229099\n",
      "[990]\ttrain-logloss:0.158573\teval-logloss:0.229034\n",
      "[1005]\ttrain-logloss:0.157901\teval-logloss:0.229\n",
      "[1020]\ttrain-logloss:0.157031\teval-logloss:0.228896\n",
      "[1035]\ttrain-logloss:0.156226\teval-logloss:0.228862\n",
      "[1050]\ttrain-logloss:0.155653\teval-logloss:0.228799\n",
      "[1065]\ttrain-logloss:0.154723\teval-logloss:0.228657\n",
      "[1080]\ttrain-logloss:0.153871\teval-logloss:0.2286\n",
      "[1095]\ttrain-logloss:0.153369\teval-logloss:0.22857\n",
      "[1110]\ttrain-logloss:0.152605\teval-logloss:0.228475\n",
      "[1125]\ttrain-logloss:0.151686\teval-logloss:0.228345\n",
      "[1140]\ttrain-logloss:0.151292\teval-logloss:0.22834\n",
      "[1155]\ttrain-logloss:0.15075\teval-logloss:0.228355\n",
      "[1170]\ttrain-logloss:0.150206\teval-logloss:0.228286\n",
      "[1185]\ttrain-logloss:0.149657\teval-logloss:0.228293\n",
      "[1200]\ttrain-logloss:0.14894\teval-logloss:0.228251\n",
      "[1215]\ttrain-logloss:0.148145\teval-logloss:0.228212\n",
      "[1230]\ttrain-logloss:0.147493\teval-logloss:0.228177\n",
      "[1245]\ttrain-logloss:0.146916\teval-logloss:0.228124\n",
      "[1260]\ttrain-logloss:0.145987\teval-logloss:0.227977\n",
      "[1275]\ttrain-logloss:0.145455\teval-logloss:0.227966\n",
      "[1290]\ttrain-logloss:0.144969\teval-logloss:0.227969\n",
      "[1305]\ttrain-logloss:0.14446\teval-logloss:0.227901\n",
      "[1320]\ttrain-logloss:0.144024\teval-logloss:0.227898\n",
      "[1335]\ttrain-logloss:0.143536\teval-logloss:0.227866\n",
      "[1350]\ttrain-logloss:0.142906\teval-logloss:0.227821\n",
      "[1365]\ttrain-logloss:0.142111\teval-logloss:0.227732\n",
      "[1380]\ttrain-logloss:0.141428\teval-logloss:0.227664\n",
      "[1395]\ttrain-logloss:0.14073\teval-logloss:0.227632\n",
      "[1410]\ttrain-logloss:0.140273\teval-logloss:0.227605\n",
      "[1425]\ttrain-logloss:0.139498\teval-logloss:0.227535\n",
      "[1440]\ttrain-logloss:0.138899\teval-logloss:0.227527\n",
      "[1455]\ttrain-logloss:0.138549\teval-logloss:0.2275\n",
      "[1470]\ttrain-logloss:0.1381\teval-logloss:0.227517\n",
      "[1485]\ttrain-logloss:0.137462\teval-logloss:0.227386\n",
      "[1500]\ttrain-logloss:0.13694\teval-logloss:0.227378\n",
      "[1515]\ttrain-logloss:0.136315\teval-logloss:0.227324\n",
      "[1530]\ttrain-logloss:0.135968\teval-logloss:0.227346\n",
      "[1545]\ttrain-logloss:0.135134\teval-logloss:0.22728\n",
      "[1560]\ttrain-logloss:0.134646\teval-logloss:0.227311\n",
      "[1575]\ttrain-logloss:0.134212\teval-logloss:0.227272\n",
      "[1590]\ttrain-logloss:0.133546\teval-logloss:0.227267\n",
      "[1605]\ttrain-logloss:0.133089\teval-logloss:0.227238\n",
      "[1620]\ttrain-logloss:0.132651\teval-logloss:0.227188\n",
      "[1635]\ttrain-logloss:0.132206\teval-logloss:0.227124\n",
      "[1650]\ttrain-logloss:0.131834\teval-logloss:0.227153\n",
      "[1665]\ttrain-logloss:0.131239\teval-logloss:0.227106\n",
      "[1680]\ttrain-logloss:0.130787\teval-logloss:0.227088\n",
      "[1695]\ttrain-logloss:0.130288\teval-logloss:0.227026\n",
      "[1710]\ttrain-logloss:0.129781\teval-logloss:0.226943\n",
      "[1725]\ttrain-logloss:0.129013\teval-logloss:0.226845\n",
      "[1740]\ttrain-logloss:0.128307\teval-logloss:0.226846\n",
      "[1755]\ttrain-logloss:0.127879\teval-logloss:0.226834\n",
      "[1770]\ttrain-logloss:0.12734\teval-logloss:0.226847\n",
      "[1785]\ttrain-logloss:0.126782\teval-logloss:0.226868\n",
      "[1800]\ttrain-logloss:0.126168\teval-logloss:0.22685\n",
      "[1815]\ttrain-logloss:0.125689\teval-logloss:0.226803\n",
      "[1830]\ttrain-logloss:0.125136\teval-logloss:0.226755\n",
      "[1845]\ttrain-logloss:0.124676\teval-logloss:0.226766\n",
      "[1860]\ttrain-logloss:0.12421\teval-logloss:0.226772\n",
      "[1875]\ttrain-logloss:0.123578\teval-logloss:0.226778\n",
      "[1890]\ttrain-logloss:0.123012\teval-logloss:0.226695\n",
      "[1905]\ttrain-logloss:0.122576\teval-logloss:0.226678\n",
      "[1920]\ttrain-logloss:0.122134\teval-logloss:0.226722\n",
      "[1935]\ttrain-logloss:0.121804\teval-logloss:0.226753\n",
      "[1950]\ttrain-logloss:0.121317\teval-logloss:0.226735\n",
      "[1965]\ttrain-logloss:0.120658\teval-logloss:0.226679\n",
      "[1980]\ttrain-logloss:0.120064\teval-logloss:0.226642\n",
      "[1995]\ttrain-logloss:0.119596\teval-logloss:0.22664\n",
      "[0]\ttrain-logloss:0.633568\teval-logloss:0.633533\n",
      "[15]\ttrain-logloss:0.323622\teval-logloss:0.325116\n",
      "[30]\ttrain-logloss:0.27123\teval-logloss:0.275145\n",
      "[45]\ttrain-logloss:0.256563\teval-logloss:0.262387\n",
      "[60]\ttrain-logloss:0.24687\teval-logloss:0.255108\n",
      "[75]\ttrain-logloss:0.240082\teval-logloss:0.250767\n",
      "[90]\ttrain-logloss:0.234734\teval-logloss:0.247734\n",
      "[105]\ttrain-logloss:0.230136\teval-logloss:0.245324\n",
      "[120]\ttrain-logloss:0.226469\teval-logloss:0.243716\n",
      "[135]\ttrain-logloss:0.223281\teval-logloss:0.242412\n",
      "[150]\ttrain-logloss:0.220427\teval-logloss:0.241371\n",
      "[165]\ttrain-logloss:0.217403\teval-logloss:0.240313\n",
      "[180]\ttrain-logloss:0.215455\teval-logloss:0.239742\n",
      "[195]\ttrain-logloss:0.212953\teval-logloss:0.238781\n",
      "[210]\ttrain-logloss:0.210913\teval-logloss:0.238193\n",
      "[225]\ttrain-logloss:0.208772\teval-logloss:0.237556\n",
      "[240]\ttrain-logloss:0.207113\teval-logloss:0.237039\n",
      "[255]\ttrain-logloss:0.205617\teval-logloss:0.236775\n",
      "[270]\ttrain-logloss:0.203838\teval-logloss:0.236354\n",
      "[285]\ttrain-logloss:0.202424\teval-logloss:0.236106\n",
      "[300]\ttrain-logloss:0.201183\teval-logloss:0.235889\n",
      "[315]\ttrain-logloss:0.199551\teval-logloss:0.235496\n",
      "[330]\ttrain-logloss:0.19828\teval-logloss:0.235352\n",
      "[345]\ttrain-logloss:0.196683\teval-logloss:0.234945\n",
      "[360]\ttrain-logloss:0.195661\teval-logloss:0.234762\n",
      "[375]\ttrain-logloss:0.194486\teval-logloss:0.234642\n",
      "[390]\ttrain-logloss:0.193127\teval-logloss:0.234439\n",
      "[405]\ttrain-logloss:0.192089\teval-logloss:0.234274\n",
      "[420]\ttrain-logloss:0.190919\teval-logloss:0.234001\n",
      "[435]\ttrain-logloss:0.189863\teval-logloss:0.233921\n",
      "[450]\ttrain-logloss:0.188711\teval-logloss:0.233768\n",
      "[465]\ttrain-logloss:0.18764\teval-logloss:0.23351\n",
      "[480]\ttrain-logloss:0.186614\teval-logloss:0.233353\n",
      "[495]\ttrain-logloss:0.185543\teval-logloss:0.233146\n",
      "[510]\ttrain-logloss:0.18447\teval-logloss:0.233063\n",
      "[525]\ttrain-logloss:0.183324\teval-logloss:0.2329\n",
      "[540]\ttrain-logloss:0.182602\teval-logloss:0.232835\n",
      "[555]\ttrain-logloss:0.181966\teval-logloss:0.232799\n",
      "[570]\ttrain-logloss:0.180943\teval-logloss:0.232721\n",
      "[585]\ttrain-logloss:0.179969\teval-logloss:0.232579\n",
      "[600]\ttrain-logloss:0.17904\teval-logloss:0.232476\n",
      "[615]\ttrain-logloss:0.178125\teval-logloss:0.232305\n",
      "[630]\ttrain-logloss:0.177321\teval-logloss:0.232236\n",
      "[645]\ttrain-logloss:0.176392\teval-logloss:0.232149\n",
      "[660]\ttrain-logloss:0.175695\teval-logloss:0.232125\n",
      "[675]\ttrain-logloss:0.174911\teval-logloss:0.232073\n",
      "[690]\ttrain-logloss:0.174161\teval-logloss:0.23199\n",
      "[705]\ttrain-logloss:0.173219\teval-logloss:0.231865\n",
      "[720]\ttrain-logloss:0.172424\teval-logloss:0.231761\n",
      "[735]\ttrain-logloss:0.171449\teval-logloss:0.231559\n",
      "[750]\ttrain-logloss:0.170571\teval-logloss:0.231538\n",
      "[765]\ttrain-logloss:0.169999\teval-logloss:0.23156\n",
      "[780]\ttrain-logloss:0.169367\teval-logloss:0.231512\n",
      "[795]\ttrain-logloss:0.168496\teval-logloss:0.231446\n",
      "[810]\ttrain-logloss:0.167646\teval-logloss:0.231361\n",
      "[825]\ttrain-logloss:0.167032\teval-logloss:0.231331\n",
      "[840]\ttrain-logloss:0.166093\teval-logloss:0.231151\n",
      "[855]\ttrain-logloss:0.165175\teval-logloss:0.231083\n",
      "[870]\ttrain-logloss:0.16412\teval-logloss:0.23094\n",
      "[885]\ttrain-logloss:0.16338\teval-logloss:0.230862\n",
      "[900]\ttrain-logloss:0.162679\teval-logloss:0.230778\n",
      "[915]\ttrain-logloss:0.162121\teval-logloss:0.230756\n",
      "[930]\ttrain-logloss:0.161392\teval-logloss:0.230642\n",
      "[945]\ttrain-logloss:0.160431\teval-logloss:0.230522\n",
      "[960]\ttrain-logloss:0.159951\teval-logloss:0.230505\n",
      "[975]\ttrain-logloss:0.158899\teval-logloss:0.230351\n",
      "[990]\ttrain-logloss:0.157992\teval-logloss:0.230284\n",
      "[1005]\ttrain-logloss:0.157292\teval-logloss:0.230217\n",
      "[1020]\ttrain-logloss:0.156466\teval-logloss:0.230148\n",
      "[1035]\ttrain-logloss:0.155839\teval-logloss:0.230112\n",
      "[1050]\ttrain-logloss:0.154804\teval-logloss:0.230034\n",
      "[1065]\ttrain-logloss:0.154204\teval-logloss:0.230037\n",
      "[1080]\ttrain-logloss:0.152944\teval-logloss:0.229762\n",
      "[1095]\ttrain-logloss:0.152394\teval-logloss:0.229752\n",
      "[1110]\ttrain-logloss:0.15175\teval-logloss:0.229686\n",
      "[1125]\ttrain-logloss:0.151382\teval-logloss:0.229694\n",
      "[1140]\ttrain-logloss:0.15085\teval-logloss:0.229685\n",
      "[1155]\ttrain-logloss:0.150086\teval-logloss:0.229637\n",
      "[1170]\ttrain-logloss:0.149682\teval-logloss:0.229637\n",
      "[1185]\ttrain-logloss:0.148904\teval-logloss:0.229533\n",
      "[1200]\ttrain-logloss:0.148163\teval-logloss:0.229433\n",
      "[1215]\ttrain-logloss:0.147568\teval-logloss:0.229463\n",
      "[1230]\ttrain-logloss:0.147047\teval-logloss:0.229464\n",
      "[1245]\ttrain-logloss:0.146541\teval-logloss:0.22945\n",
      "[1260]\ttrain-logloss:0.145511\teval-logloss:0.229339\n",
      "[1275]\ttrain-logloss:0.145049\teval-logloss:0.2293\n",
      "[1290]\ttrain-logloss:0.144569\teval-logloss:0.229235\n",
      "[1305]\ttrain-logloss:0.143836\teval-logloss:0.22919\n",
      "[1320]\ttrain-logloss:0.143131\teval-logloss:0.229071\n",
      "[1335]\ttrain-logloss:0.142525\teval-logloss:0.229025\n",
      "[1350]\ttrain-logloss:0.141983\teval-logloss:0.22899\n",
      "[1365]\ttrain-logloss:0.141303\teval-logloss:0.228933\n",
      "[1380]\ttrain-logloss:0.140808\teval-logloss:0.228933\n",
      "[1395]\ttrain-logloss:0.140304\teval-logloss:0.22893\n",
      "[1410]\ttrain-logloss:0.139791\teval-logloss:0.228915\n",
      "[1425]\ttrain-logloss:0.139153\teval-logloss:0.228824\n",
      "[1440]\ttrain-logloss:0.138668\teval-logloss:0.228801\n",
      "[1455]\ttrain-logloss:0.138062\teval-logloss:0.228766\n",
      "[1470]\ttrain-logloss:0.13746\teval-logloss:0.228739\n",
      "[1485]\ttrain-logloss:0.136484\teval-logloss:0.228639\n",
      "[1500]\ttrain-logloss:0.135898\teval-logloss:0.228573\n",
      "[1515]\ttrain-logloss:0.135455\teval-logloss:0.228587\n",
      "[1530]\ttrain-logloss:0.135021\teval-logloss:0.228581\n",
      "[1545]\ttrain-logloss:0.134464\teval-logloss:0.228561\n",
      "[1560]\ttrain-logloss:0.133915\teval-logloss:0.228546\n",
      "[1575]\ttrain-logloss:0.133456\teval-logloss:0.228496\n",
      "[1590]\ttrain-logloss:0.133029\teval-logloss:0.228486\n",
      "[1605]\ttrain-logloss:0.1325\teval-logloss:0.228462\n",
      "[1620]\ttrain-logloss:0.132032\teval-logloss:0.228468\n",
      "[1635]\ttrain-logloss:0.131189\teval-logloss:0.228433\n",
      "[1650]\ttrain-logloss:0.130712\teval-logloss:0.228391\n",
      "[1665]\ttrain-logloss:0.130079\teval-logloss:0.228342\n",
      "[1680]\ttrain-logloss:0.129537\teval-logloss:0.228304\n",
      "[1695]\ttrain-logloss:0.129145\teval-logloss:0.228313\n",
      "[1710]\ttrain-logloss:0.128652\teval-logloss:0.22826\n",
      "[1725]\ttrain-logloss:0.128187\teval-logloss:0.228235\n",
      "[1740]\ttrain-logloss:0.127686\teval-logloss:0.228174\n",
      "[1755]\ttrain-logloss:0.127118\teval-logloss:0.228148\n",
      "[1770]\ttrain-logloss:0.126701\teval-logloss:0.228127\n",
      "[1785]\ttrain-logloss:0.126298\teval-logloss:0.228117\n",
      "[1800]\ttrain-logloss:0.125807\teval-logloss:0.228101\n",
      "[1815]\ttrain-logloss:0.125469\teval-logloss:0.22815\n",
      "[1830]\ttrain-logloss:0.124954\teval-logloss:0.228114\n",
      "[1845]\ttrain-logloss:0.124211\teval-logloss:0.228013\n",
      "[1860]\ttrain-logloss:0.123714\teval-logloss:0.228013\n",
      "[1875]\ttrain-logloss:0.123261\teval-logloss:0.228032\n",
      "[1890]\ttrain-logloss:0.122888\teval-logloss:0.227996\n",
      "[1905]\ttrain-logloss:0.122424\teval-logloss:0.228019\n",
      "[1920]\ttrain-logloss:0.121855\teval-logloss:0.22801\n",
      "[1935]\ttrain-logloss:0.121008\teval-logloss:0.227877\n",
      "[1950]\ttrain-logloss:0.120444\teval-logloss:0.227853\n",
      "[1965]\ttrain-logloss:0.120063\teval-logloss:0.227861\n",
      "[1980]\ttrain-logloss:0.119371\teval-logloss:0.227787\n",
      "[1995]\ttrain-logloss:0.119127\teval-logloss:0.227799\n",
      "XGB: 0.229 +- 0.001\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 2000\n",
    "\n",
    "#LGBM\n",
    "params = {\n",
    "    #'task': 'train',\n",
    "    #'boosting_type': 'gbdt',\n",
    "    #'objective': 'regression',\n",
    "    #'metric': {'l2', 'auc'},\n",
    "    #'num_leaves': 31,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    #'subsample': 0.8,\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'objective': 'binary',\n",
    "    'nthread': -1,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 5,\n",
    "    #'max_depth': 6\n",
    "    #'num_class': 3\n",
    "    \n",
    "}\n",
    "\n",
    "pred_train = np.zeros(len(y_train))\n",
    "xgbs = []\n",
    "sc,sc_mean = [],[]\n",
    "\n",
    "for itr, ite in folds:\n",
    "    ypred = []\n",
    "    for i in range(1):\n",
    "               \n",
    "        param['seed'] = i+1\n",
    "        \n",
    "        #xgboost\n",
    "        \n",
    "        Xdatatrain = xgb.DMatrix(data=X_train.ix[itr, :].values,\n",
    "                                     label=y_train.ix[itr].values)\n",
    "        Xdataval = xgb.DMatrix(data=X_train.ix[ite, :].values,\n",
    "                                     label=y_train.ix[ite].values)\n",
    "\n",
    "        plst = list(param.items())\n",
    "        watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]\n",
    "        bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n",
    "\n",
    "        \n",
    "        #rc = ensemble.ExtraTreesClassifier(n_estimators=1300, criterion='gini', max_depth=None, n_jobs=-1)\n",
    "        #pred_train[ite] = bst.predict(Xdataval)\n",
    "        #neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "        #neigh.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = bst.predict(Xdataval)\n",
    "        #ypred = neigh.predict_proba(X_train.ix[ite, :])\n",
    "        xgbs.append(bst)\n",
    "        '''\n",
    "        \n",
    "        # train\n",
    "        lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "        lgb.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = lgb.predict_proba(X_train.ix[ite, :])[:, 1]\n",
    "\n",
    "        \n",
    "        model.fit(X_train.ix[itr, :].values, y_train_cat[itr],\n",
    "            epochs=60,\n",
    "            batch_size=1000)\n",
    "        ypred = model.predict(X_train.ix[ite, :].values)\n",
    "        '''\n",
    "    #ypred = sum(ypred) / len(ypred) 0.401408 0.392476\n",
    "    pred_train[ite] = ypred\n",
    "\n",
    "    \n",
    "    sc.append(log_loss(y_train.ix[ite, :], pred_train[ite]))\n",
    "\n",
    "    \n",
    "print('XGB: {:.3f} +- {:.3f}'.format(np.mean(sc), np.std(sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    a = 0.165 / 0.37\n",
    "    b = (1 - 0.165) / (1 - 0.37) \n",
    "    return  a * x / (a * x + b * (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = foo(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(pred_train)\n",
    "pred_train.columns = ['y']\n",
    "pred_train.to_csv(\"stacking/xgb_17.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=300, nthread=-1, num_leaves=31,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
       "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5, subsample=1,\n",
       "        subsample_for_bin=50000, subsample_freq=1, uniform_drop=False,\n",
       "        xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "lgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.ix[1000001:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred2 = lgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00778551,  0.58706412,  0.45319938,  0.00166404])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.85291907e-04,   2.61291438e-01,   6.26312391e-01,\n",
       "         1.66797416e-03])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.51530930e-01,   3.07114939e-04,   1.03535362e-03,\n",
       "         9.95933188e-02])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.67587699e-03,   2.31711933e-04,   3.72899384e-01,\n",
       "         3.89707027e-01])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345795"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.concatenate([test_pred1, test_pred2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.78551300e-03,   5.87064116e-01,   4.53199376e-01, ...,\n",
       "         2.31711933e-04,   3.72899384e-01,   3.89707027e-01])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-20e877713fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_train' is not defined"
     ]
    }
   ],
   "source": [
    "del pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatrain = xgb.DMatrix(data=X_train.ix[:, :].values,\n",
    "                                     label=y_train.ix[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdataval = xgb.DMatrix(data=X_train.ix[:10, :].values,\n",
    "                                     label=y_train.ix[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del Xdatatest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatest2 = xgb.DMatrix(data=X_test.ix[1000001:, :].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.633506\teval-logloss:0.646774\n",
      "[15]\ttrain-logloss:0.323969\teval-logloss:0.388133\n",
      "[30]\ttrain-logloss:0.271702\teval-logloss:0.343325\n",
      "[45]\ttrain-logloss:0.257076\teval-logloss:0.341127\n",
      "[60]\ttrain-logloss:0.248104\teval-logloss:0.316478\n",
      "[75]\ttrain-logloss:0.241793\teval-logloss:0.306781\n",
      "[90]\ttrain-logloss:0.236545\teval-logloss:0.294224\n",
      "[105]\ttrain-logloss:0.232073\teval-logloss:0.288613\n",
      "[120]\ttrain-logloss:0.228825\teval-logloss:0.282442\n",
      "[135]\ttrain-logloss:0.225883\teval-logloss:0.283732\n",
      "[150]\ttrain-logloss:0.222672\teval-logloss:0.279839\n",
      "[165]\ttrain-logloss:0.220304\teval-logloss:0.271811\n",
      "[180]\ttrain-logloss:0.218097\teval-logloss:0.271271\n",
      "[195]\ttrain-logloss:0.215673\teval-logloss:0.269905\n",
      "[210]\ttrain-logloss:0.213894\teval-logloss:0.270819\n",
      "[225]\ttrain-logloss:0.211979\teval-logloss:0.273126\n",
      "[240]\ttrain-logloss:0.210103\teval-logloss:0.267782\n",
      "[255]\ttrain-logloss:0.208528\teval-logloss:0.267423\n",
      "[270]\ttrain-logloss:0.207038\teval-logloss:0.269102\n",
      "[285]\ttrain-logloss:0.205572\teval-logloss:0.270577\n",
      "[300]\ttrain-logloss:0.204371\teval-logloss:0.267361\n",
      "[315]\ttrain-logloss:0.202777\teval-logloss:0.261271\n",
      "[330]\ttrain-logloss:0.201445\teval-logloss:0.259142\n",
      "[345]\ttrain-logloss:0.199901\teval-logloss:0.250026\n",
      "[360]\ttrain-logloss:0.19867\teval-logloss:0.249264\n",
      "[375]\ttrain-logloss:0.197549\teval-logloss:0.240708\n",
      "[390]\ttrain-logloss:0.196382\teval-logloss:0.240785\n",
      "[405]\ttrain-logloss:0.195247\teval-logloss:0.240169\n",
      "[420]\ttrain-logloss:0.194284\teval-logloss:0.239235\n",
      "[435]\ttrain-logloss:0.193526\teval-logloss:0.237363\n",
      "[450]\ttrain-logloss:0.192495\teval-logloss:0.238759\n",
      "[465]\ttrain-logloss:0.191718\teval-logloss:0.237641\n",
      "[480]\ttrain-logloss:0.190985\teval-logloss:0.237063\n",
      "[495]\ttrain-logloss:0.190056\teval-logloss:0.23735\n",
      "[510]\ttrain-logloss:0.189194\teval-logloss:0.237971\n",
      "[525]\ttrain-logloss:0.188237\teval-logloss:0.239135\n",
      "[540]\ttrain-logloss:0.187406\teval-logloss:0.235735\n",
      "[555]\ttrain-logloss:0.186695\teval-logloss:0.23455\n",
      "[570]\ttrain-logloss:0.185304\teval-logloss:0.234803\n",
      "[585]\ttrain-logloss:0.184262\teval-logloss:0.237602\n",
      "[600]\ttrain-logloss:0.183569\teval-logloss:0.237253\n",
      "[615]\ttrain-logloss:0.182823\teval-logloss:0.236509\n",
      "[630]\ttrain-logloss:0.181981\teval-logloss:0.237083\n",
      "[645]\ttrain-logloss:0.181358\teval-logloss:0.236003\n",
      "[660]\ttrain-logloss:0.180737\teval-logloss:0.234916\n",
      "[675]\ttrain-logloss:0.180074\teval-logloss:0.230396\n",
      "[690]\ttrain-logloss:0.17935\teval-logloss:0.232672\n",
      "[705]\ttrain-logloss:0.178409\teval-logloss:0.234427\n",
      "[720]\ttrain-logloss:0.177643\teval-logloss:0.228954\n",
      "[735]\ttrain-logloss:0.177142\teval-logloss:0.22548\n",
      "[750]\ttrain-logloss:0.176497\teval-logloss:0.225134\n",
      "[765]\ttrain-logloss:0.175731\teval-logloss:0.224354\n",
      "[780]\ttrain-logloss:0.174998\teval-logloss:0.224698\n",
      "[795]\ttrain-logloss:0.174198\teval-logloss:0.223869\n",
      "[810]\ttrain-logloss:0.173173\teval-logloss:0.229316\n",
      "[825]\ttrain-logloss:0.172442\teval-logloss:0.229843\n",
      "[840]\ttrain-logloss:0.17192\teval-logloss:0.226134\n",
      "[855]\ttrain-logloss:0.171253\teval-logloss:0.226123\n",
      "[870]\ttrain-logloss:0.170603\teval-logloss:0.226297\n",
      "[885]\ttrain-logloss:0.170178\teval-logloss:0.226306\n",
      "[900]\ttrain-logloss:0.169571\teval-logloss:0.221959\n",
      "[915]\ttrain-logloss:0.169005\teval-logloss:0.221173\n",
      "[930]\ttrain-logloss:0.168424\teval-logloss:0.222485\n",
      "[945]\ttrain-logloss:0.167708\teval-logloss:0.222546\n",
      "[960]\ttrain-logloss:0.166747\teval-logloss:0.222536\n",
      "[975]\ttrain-logloss:0.166074\teval-logloss:0.222261\n",
      "[990]\ttrain-logloss:0.165399\teval-logloss:0.222305\n",
      "[1005]\ttrain-logloss:0.164709\teval-logloss:0.221686\n",
      "[1020]\ttrain-logloss:0.164162\teval-logloss:0.220124\n",
      "[1035]\ttrain-logloss:0.163462\teval-logloss:0.219203\n",
      "[1050]\ttrain-logloss:0.162654\teval-logloss:0.217525\n",
      "[1065]\ttrain-logloss:0.162241\teval-logloss:0.21614\n",
      "[1080]\ttrain-logloss:0.161564\teval-logloss:0.214256\n",
      "[1095]\ttrain-logloss:0.160884\teval-logloss:0.21139\n",
      "[1110]\ttrain-logloss:0.160356\teval-logloss:0.211389\n",
      "[1125]\ttrain-logloss:0.15986\teval-logloss:0.206657\n",
      "[1140]\ttrain-logloss:0.159321\teval-logloss:0.206579\n",
      "[1155]\ttrain-logloss:0.158897\teval-logloss:0.206587\n",
      "[1170]\ttrain-logloss:0.158453\teval-logloss:0.206663\n",
      "[1185]\ttrain-logloss:0.157872\teval-logloss:0.204609\n",
      "[1200]\ttrain-logloss:0.157216\teval-logloss:0.202777\n",
      "[1215]\ttrain-logloss:0.156551\teval-logloss:0.204005\n",
      "[1230]\ttrain-logloss:0.156055\teval-logloss:0.204041\n",
      "[1245]\ttrain-logloss:0.155631\teval-logloss:0.202561\n",
      "[1260]\ttrain-logloss:0.155124\teval-logloss:0.200276\n",
      "[1275]\ttrain-logloss:0.154304\teval-logloss:0.199875\n",
      "[1290]\ttrain-logloss:0.153745\teval-logloss:0.202103\n",
      "[1305]\ttrain-logloss:0.153227\teval-logloss:0.202038\n",
      "[1320]\ttrain-logloss:0.152727\teval-logloss:0.201489\n",
      "[1335]\ttrain-logloss:0.151832\teval-logloss:0.201855\n",
      "[1350]\ttrain-logloss:0.151226\teval-logloss:0.202211\n",
      "[1365]\ttrain-logloss:0.150557\teval-logloss:0.197629\n",
      "[1380]\ttrain-logloss:0.150026\teval-logloss:0.195791\n",
      "[1395]\ttrain-logloss:0.149625\teval-logloss:0.196072\n",
      "[1410]\ttrain-logloss:0.14925\teval-logloss:0.192879\n",
      "[1425]\ttrain-logloss:0.148646\teval-logloss:0.193572\n",
      "[1440]\ttrain-logloss:0.148339\teval-logloss:0.193567\n",
      "[1455]\ttrain-logloss:0.147717\teval-logloss:0.19465\n",
      "[1470]\ttrain-logloss:0.146948\teval-logloss:0.195416\n",
      "[1485]\ttrain-logloss:0.146366\teval-logloss:0.194434\n",
      "[1500]\ttrain-logloss:0.14602\teval-logloss:0.193012\n",
      "[1515]\ttrain-logloss:0.145627\teval-logloss:0.193242\n",
      "[1530]\ttrain-logloss:0.145162\teval-logloss:0.193025\n",
      "[1545]\ttrain-logloss:0.144701\teval-logloss:0.188226\n",
      "[1560]\ttrain-logloss:0.144097\teval-logloss:0.188131\n",
      "[1575]\ttrain-logloss:0.143432\teval-logloss:0.184562\n",
      "[1590]\ttrain-logloss:0.14287\teval-logloss:0.18492\n",
      "[1605]\ttrain-logloss:0.14238\teval-logloss:0.181315\n",
      "[1620]\ttrain-logloss:0.141964\teval-logloss:0.181304\n",
      "[1635]\ttrain-logloss:0.141399\teval-logloss:0.180933\n",
      "[1650]\ttrain-logloss:0.140897\teval-logloss:0.180716\n",
      "[1665]\ttrain-logloss:0.140414\teval-logloss:0.180889\n",
      "[1680]\ttrain-logloss:0.13998\teval-logloss:0.181614\n",
      "[1695]\ttrain-logloss:0.139452\teval-logloss:0.181003\n",
      "[1710]\ttrain-logloss:0.139077\teval-logloss:0.180468\n",
      "[1725]\ttrain-logloss:0.138619\teval-logloss:0.180347\n",
      "[1740]\ttrain-logloss:0.138285\teval-logloss:0.179627\n",
      "[1755]\ttrain-logloss:0.137748\teval-logloss:0.17569\n",
      "[1770]\ttrain-logloss:0.13744\teval-logloss:0.175583\n",
      "[1785]\ttrain-logloss:0.137085\teval-logloss:0.170743\n",
      "[1800]\ttrain-logloss:0.136571\teval-logloss:0.169562\n",
      "[1815]\ttrain-logloss:0.136105\teval-logloss:0.169764\n",
      "[1830]\ttrain-logloss:0.135462\teval-logloss:0.16524\n",
      "[1845]\ttrain-logloss:0.135028\teval-logloss:0.162854\n",
      "[1860]\ttrain-logloss:0.134359\teval-logloss:0.16272\n",
      "[1875]\ttrain-logloss:0.133653\teval-logloss:0.16152\n",
      "[1890]\ttrain-logloss:0.133198\teval-logloss:0.156493\n",
      "[1905]\ttrain-logloss:0.132658\teval-logloss:0.156476\n",
      "[1920]\ttrain-logloss:0.1323\teval-logloss:0.156168\n",
      "[1935]\ttrain-logloss:0.13199\teval-logloss:0.158266\n",
      "[1950]\ttrain-logloss:0.13176\teval-logloss:0.158097\n",
      "[1965]\ttrain-logloss:0.131321\teval-logloss:0.15726\n",
      "[1980]\ttrain-logloss:0.130993\teval-logloss:0.15721\n",
      "[1995]\ttrain-logloss:0.130602\teval-logloss:0.15699\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred2 = bst.predict(Xdatatest2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.93649067e-03,   1.69867009e-01,   5.44634938e-01,\n",
       "         2.05250995e-04], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.29527755e-03,   5.45756638e-01,   6.37812853e-01,\n",
       "         4.23383579e-04], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.concatenate([test_pred1, test_pred2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = foo(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit['is_duplicate'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv(\"stacking/xgb_17_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.286948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.248740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.999420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.101225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.332465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.026198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.040524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.048661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.016387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.496126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.245812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.392182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.008467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.073976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.010129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.092037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345766</th>\n",
       "      <td>2345766</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345767</th>\n",
       "      <td>2345767</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345768</th>\n",
       "      <td>2345768</td>\n",
       "      <td>0.018591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345769</th>\n",
       "      <td>2345769</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345770</th>\n",
       "      <td>2345770</td>\n",
       "      <td>0.059360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345771</th>\n",
       "      <td>2345771</td>\n",
       "      <td>0.048759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345772</th>\n",
       "      <td>2345772</td>\n",
       "      <td>0.160039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345773</th>\n",
       "      <td>2345773</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345774</th>\n",
       "      <td>2345774</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345775</th>\n",
       "      <td>2345775</td>\n",
       "      <td>0.297678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345776</th>\n",
       "      <td>2345776</td>\n",
       "      <td>0.005604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345777</th>\n",
       "      <td>2345777</td>\n",
       "      <td>0.005870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345778</th>\n",
       "      <td>2345778</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345779</th>\n",
       "      <td>2345779</td>\n",
       "      <td>0.002926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345780</th>\n",
       "      <td>2345780</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345781</th>\n",
       "      <td>2345781</td>\n",
       "      <td>0.114455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345782</th>\n",
       "      <td>2345782</td>\n",
       "      <td>0.127073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345783</th>\n",
       "      <td>2345783</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345784</th>\n",
       "      <td>2345784</td>\n",
       "      <td>0.451728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345785</th>\n",
       "      <td>2345785</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345786</th>\n",
       "      <td>2345786</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345787</th>\n",
       "      <td>2345787</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345788</th>\n",
       "      <td>2345788</td>\n",
       "      <td>0.003053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345789</th>\n",
       "      <td>2345789</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345790</th>\n",
       "      <td>2345790</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>0.169705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>0.233597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "0              0      0.001666\n",
       "1              1      0.064414\n",
       "2              2      0.286948\n",
       "3              3      0.000069\n",
       "4              4      0.248740\n",
       "5              5      0.002444\n",
       "6              6      0.999420\n",
       "7              7      0.101225\n",
       "8              8      0.332465\n",
       "9              9      0.000641\n",
       "10            10      0.026198\n",
       "11            11      0.000029\n",
       "12            12      0.000012\n",
       "13            13      0.040524\n",
       "14            14      0.048661\n",
       "15            15      0.016387\n",
       "16            16      0.000019\n",
       "17            17      0.496126\n",
       "18            18      0.245812\n",
       "19            19      0.392182\n",
       "20            20      0.000029\n",
       "21            21      0.008467\n",
       "22            22      0.002201\n",
       "23            23      0.002685\n",
       "24            24      0.000052\n",
       "25            25      0.073976\n",
       "26            26      0.000012\n",
       "27            27      0.010129\n",
       "28            28      0.092037\n",
       "29            29      0.000088\n",
       "...          ...           ...\n",
       "2345766  2345766      0.000003\n",
       "2345767  2345767      0.000010\n",
       "2345768  2345768      0.018591\n",
       "2345769  2345769      0.000003\n",
       "2345770  2345770      0.059360\n",
       "2345771  2345771      0.048759\n",
       "2345772  2345772      0.160039\n",
       "2345773  2345773      0.000001\n",
       "2345774  2345774      0.000080\n",
       "2345775  2345775      0.297678\n",
       "2345776  2345776      0.005604\n",
       "2345777  2345777      0.005870\n",
       "2345778  2345778      0.000062\n",
       "2345779  2345779      0.002926\n",
       "2345780  2345780      0.000102\n",
       "2345781  2345781      0.114455\n",
       "2345782  2345782      0.127073\n",
       "2345783  2345783      0.000026\n",
       "2345784  2345784      0.451728\n",
       "2345785  2345785      0.000005\n",
       "2345786  2345786      0.000012\n",
       "2345787  2345787      0.000004\n",
       "2345788  2345788      0.003053\n",
       "2345789  2345789      0.000002\n",
       "2345790  2345790      0.000040\n",
       "2345791  2345791      0.000006\n",
       "2345792  2345792      0.000041\n",
       "2345793  2345793      0.000010\n",
       "2345794  2345794      0.169705\n",
       "2345795  2345795      0.233597\n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.323567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.218058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.095342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.007831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.956379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.098221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.363882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.423677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.034839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.033894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.392933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.150615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.284470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.018111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.004705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.061033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.009628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.099425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345766</th>\n",
       "      <td>2345766</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345767</th>\n",
       "      <td>2345767</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345768</th>\n",
       "      <td>2345768</td>\n",
       "      <td>0.023880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345769</th>\n",
       "      <td>2345769</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345770</th>\n",
       "      <td>2345770</td>\n",
       "      <td>0.063847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345771</th>\n",
       "      <td>2345771</td>\n",
       "      <td>0.446460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345772</th>\n",
       "      <td>2345772</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345773</th>\n",
       "      <td>2345773</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345774</th>\n",
       "      <td>2345774</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345775</th>\n",
       "      <td>2345775</td>\n",
       "      <td>0.276473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345776</th>\n",
       "      <td>2345776</td>\n",
       "      <td>0.032203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345777</th>\n",
       "      <td>2345777</td>\n",
       "      <td>0.009648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345778</th>\n",
       "      <td>2345778</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345779</th>\n",
       "      <td>2345779</td>\n",
       "      <td>0.009260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345780</th>\n",
       "      <td>2345780</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345781</th>\n",
       "      <td>2345781</td>\n",
       "      <td>0.058332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345782</th>\n",
       "      <td>2345782</td>\n",
       "      <td>0.088220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345783</th>\n",
       "      <td>2345783</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345784</th>\n",
       "      <td>2345784</td>\n",
       "      <td>0.418718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345785</th>\n",
       "      <td>2345785</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345786</th>\n",
       "      <td>2345786</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345787</th>\n",
       "      <td>2345787</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345788</th>\n",
       "      <td>2345788</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345789</th>\n",
       "      <td>2345789</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345790</th>\n",
       "      <td>2345790</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>0.166718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>0.176853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "0              0      0.002633\n",
       "1              1      0.323567\n",
       "2              2      0.218058\n",
       "3              3      0.000561\n",
       "4              4      0.095342\n",
       "5              5      0.007831\n",
       "6              6      0.956379\n",
       "7              7      0.098221\n",
       "8              8      0.363882\n",
       "9              9      0.002275\n",
       "10            10      0.423677\n",
       "11            11      0.000240\n",
       "12            12      0.000097\n",
       "13            13      0.034839\n",
       "14            14      0.033894\n",
       "15            15      0.020784\n",
       "16            16      0.000108\n",
       "17            17      0.392933\n",
       "18            18      0.150615\n",
       "19            19      0.284470\n",
       "20            20      0.000149\n",
       "21            21      0.018111\n",
       "22            22      0.004705\n",
       "23            23      0.004349\n",
       "24            24      0.000205\n",
       "25            25      0.061033\n",
       "26            26      0.000158\n",
       "27            27      0.009628\n",
       "28            28      0.099425\n",
       "29            29      0.000419\n",
       "...          ...           ...\n",
       "2345766  2345766      0.000039\n",
       "2345767  2345767      0.000291\n",
       "2345768  2345768      0.023880\n",
       "2345769  2345769      0.000088\n",
       "2345770  2345770      0.063847\n",
       "2345771  2345771      0.446460\n",
       "2345772  2345772      0.089966\n",
       "2345773  2345773      0.000060\n",
       "2345774  2345774      0.001341\n",
       "2345775  2345775      0.276473\n",
       "2345776  2345776      0.032203\n",
       "2345777  2345777      0.009648\n",
       "2345778  2345778      0.000300\n",
       "2345779  2345779      0.009260\n",
       "2345780  2345780      0.000238\n",
       "2345781  2345781      0.058332\n",
       "2345782  2345782      0.088220\n",
       "2345783  2345783      0.000379\n",
       "2345784  2345784      0.418718\n",
       "2345785  2345785      0.000115\n",
       "2345786  2345786      0.000045\n",
       "2345787  2345787      0.000076\n",
       "2345788  2345788      0.011994\n",
       "2345789  2345789      0.000081\n",
       "2345790  2345790      0.000093\n",
       "2345791  2345791      0.000088\n",
       "2345792  2345792      0.000564\n",
       "2345793  2345793      0.000078\n",
       "2345794  2345794      0.166718\n",
       "2345795  2345795      0.176853\n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
