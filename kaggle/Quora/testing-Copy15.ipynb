{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "import sklearn\n",
    "from sklearn import pipeline, preprocessing, feature_extraction\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "y_train = pd.DataFrame(X_train['is_duplicate'])\n",
    "y_train.columns = ['y']\n",
    "del X_train['is_duplicate']\n",
    "\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "folds = []\n",
    "for itr, ite in skf.split(X_train, y_train.y):\n",
    "    folds += [[itr, ite]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train_inter.csv\")\n",
    "\n",
    "X_train['question1'] = X_train['question1'].apply(lambda x: str(x))\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "X_train['question1'] = X_train['question1'].apply(lambda x: x.lower().split())\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: x.lower().split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"data/test_inter.csv\")\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(lambda x: str(x))\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: str(x))\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(lambda x: x.lower().split())\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = map(lambda x: ' '.join(x), X_train['question1'])\n",
    "X1 = map(lambda x: ' '.join(x), X_train['question2'])\n",
    "Y = map(lambda x: ' '.join(x), X_test['question1'])\n",
    "Y1 = map(lambda x: ' '.join(x), X_test['question2'])\n",
    "\n",
    "hw = HashingVectorizer(n_features=200).fit(X_train['question1'] + X_train['question2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(hw.transform(X).todense())\n",
    "X1 = pd.DataFrame(hw.transform(X1).todense())\n",
    "Y = pd.DataFrame(hw.transform(Y).todense())\n",
    "Y1 = pd.DataFrame(hw.transform(Y1).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = feature_extraction.text.TfidfTransformer()\n",
    "tfidf.fit(X+X1)\n",
    "\n",
    "X = pd.DataFrame(tfidf.transform(X).todense())\n",
    "X1 = pd.DataFrame(tfidf.transform(X1).todense())\n",
    "Y = pd.DataFrame(tfidf.transform(Y).todense())\n",
    "Y1 = pd.DataFrame(tfidf.transform(Y1).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X], axis=1, join_axes=[X_train.index])\n",
    "del X\n",
    "X_train = pd.concat([X_train, X1], axis=1, join_axes=[X_train.index])\n",
    "del X1\n",
    "X_test = pd.concat([X_test, Y], axis=1, join_axes=[X_test.index])\n",
    "del Y\n",
    "X_test = pd.concat([X_test, Y1], axis=1, join_axes=[X_test.index])\n",
    "del Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, (koh-i-no...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1   1     3     4  [what, is, the, story, of, kohinoor, (koh-i-no...   \n",
       "\n",
       "                                           question2  word_match  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...    0.727273   \n",
       "1  [what, would, happen, if, the, indian, governm...    0.307692   \n",
       "\n",
       "   tfidf_word_match    0    1    2 ...   190  191       192  193  194  195  \\\n",
       "0          0.772164  0.0  0.0  0.0 ...   0.0  0.0  0.325385  0.0  0.0  0.0   \n",
       "1          0.361758  0.0  0.0  0.0 ...   0.0  0.0  0.000000  0.0  0.0  0.0   \n",
       "\n",
       "   196  197  198  199  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[2 rows x 407 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train['question1']\n",
    "del X_train['question2']\n",
    "del X_train['qid1']\n",
    "del X_train['qid2']\n",
    "del X_train['id']\n",
    "\n",
    "del X_test['question1']\n",
    "del X_test['question2']\n",
    "del X_test['test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tmp = abs(X_train.ix[:, 2:202] * X_train.ix[:, -200:])\n",
    "#X_train = pd.concat([X_train, tmp], axis=1, join_axes=[X_train.index])\n",
    "tmp = abs(X_train.ix[:, 2:202] - X_train.ix[:, -200:])\n",
    "X_train = pd.concat([X_train, tmp], axis=1, join_axes=[X_train.index])\n",
    "\n",
    "#tmp = abs(X_test.ix[:, 2:202] * X_test.ix[:, -200:])\n",
    "#X_test = pd.concat([X_test, tmp], axis=1, join_axes=[X_test.index])\n",
    "tmp = abs(X_test.ix[:, 2:202] - X_test.ix[:, -200:])\n",
    "X_test = pd.concat([X_test, tmp], axis=1, join_axes=[X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(\"data/train_inter.csv\")\n",
    "q_train = pd.read_csv(\"data/freq_train.csv\")\n",
    "X_train = pd.concat([X_train, q_train], axis=1)\n",
    "\n",
    "f_train = pd.read_csv(\"data/train_features.csv\", encoding = \"ISO-8859-1\")\n",
    "f_train = f_train.ix[:, 2:]\n",
    "X_train = pd.concat([X_train, f_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.081614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.023324</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>-0.091902</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>0.337301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.195119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.588090</td>\n",
       "      <td>1.012091</td>\n",
       "      <td>0.455910</td>\n",
       "      <td>0.592655</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>0.094704</td>\n",
       "      <td>0.284010</td>\n",
       "      <td>-0.034444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match    0    1    2    3    4    5    6    7  \\\n",
       "0    0.727273          0.772164  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1    0.307692          0.361758  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "     ...      cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "0    ...                5.081614               1.0          94.023324   \n",
       "1    ...               14.195119               1.0         177.588090   \n",
       "\n",
       "   euclidean_distance  minkowski_distance  braycurtis_distance  skew_q1vec  \\\n",
       "0            0.371408            0.168999             0.186557    0.031817   \n",
       "1            1.012091            0.455910             0.592655    0.008735   \n",
       "\n",
       "   skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "0   -0.091902   0.050416   0.337301  \n",
       "1    0.094704   0.284010  -0.034444  \n",
       "\n",
       "[2 rows x 632 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del f_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_test = pd.read_csv(\"data/freq_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, q_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_test = pd.read_csv(\"data/test_features.csv\", encoding = \"ISO-8859-1\")\n",
    "f_test = f_test.ix[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, f_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.156312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.006720</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164.254264</td>\n",
       "      <td>0.889327</td>\n",
       "      <td>0.407153</td>\n",
       "      <td>0.483565</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>0.039938</td>\n",
       "      <td>-0.144866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.164904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.501658</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.512012</td>\n",
       "      <td>0.466698</td>\n",
       "      <td>0.210239</td>\n",
       "      <td>0.245248</td>\n",
       "      <td>-0.017419</td>\n",
       "      <td>-0.046821</td>\n",
       "      <td>0.207580</td>\n",
       "      <td>-0.042937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 632 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match    0    1    2    3    4         5    6    7  \\\n",
       "0    0.266667          0.274019  0.0  0.0  0.0  0.0  0.0 -0.156312  0.0  0.0   \n",
       "1    0.500000          0.480962  0.0  0.0  0.0  0.0  0.0 -0.164904  0.0  0.0   \n",
       "\n",
       "     ...      cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "0    ...               12.006720               1.0         164.254264   \n",
       "1    ...                6.501658               1.0         115.512012   \n",
       "\n",
       "   euclidean_distance  minkowski_distance  braycurtis_distance  skew_q1vec  \\\n",
       "0            0.889327            0.407153             0.483565    0.045990   \n",
       "1            0.466698            0.210239             0.245248   -0.017419   \n",
       "\n",
       "   skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "0    0.009958   0.039938  -0.144866  \n",
       "1   -0.046821   0.207580  -0.042937  \n",
       "\n",
       "[2 rows x 632 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.642997\teval-logloss:0.64345\n",
      "[15]\ttrain-logloss:0.37954\teval-logloss:0.383378\n",
      "[30]\ttrain-logloss:0.332223\teval-logloss:0.338569\n",
      "[45]\ttrain-logloss:0.316031\teval-logloss:0.324481\n",
      "[60]\ttrain-logloss:0.305652\teval-logloss:0.316564\n",
      "[75]\ttrain-logloss:0.298584\teval-logloss:0.311831\n",
      "[90]\ttrain-logloss:0.292458\teval-logloss:0.308071\n",
      "[105]\ttrain-logloss:0.288224\teval-logloss:0.305941\n",
      "[120]\ttrain-logloss:0.283713\teval-logloss:0.303657\n",
      "[135]\ttrain-logloss:0.27987\teval-logloss:0.301569\n",
      "[150]\ttrain-logloss:0.276814\teval-logloss:0.300182\n",
      "[165]\ttrain-logloss:0.273626\teval-logloss:0.298764\n",
      "[180]\ttrain-logloss:0.27081\teval-logloss:0.297738\n",
      "[195]\ttrain-logloss:0.268143\teval-logloss:0.296692\n",
      "[210]\ttrain-logloss:0.265937\teval-logloss:0.295938\n",
      "[225]\ttrain-logloss:0.263986\teval-logloss:0.295282\n",
      "[240]\ttrain-logloss:0.262043\teval-logloss:0.294575\n",
      "[255]\ttrain-logloss:0.260151\teval-logloss:0.293854\n",
      "[270]\ttrain-logloss:0.257907\teval-logloss:0.293062\n",
      "[285]\ttrain-logloss:0.25597\teval-logloss:0.292425\n",
      "[300]\ttrain-logloss:0.254305\teval-logloss:0.292049\n",
      "[315]\ttrain-logloss:0.252773\teval-logloss:0.29167\n",
      "[330]\ttrain-logloss:0.251331\teval-logloss:0.291347\n",
      "[345]\ttrain-logloss:0.249575\teval-logloss:0.290861\n",
      "[360]\ttrain-logloss:0.248232\teval-logloss:0.290572\n",
      "[375]\ttrain-logloss:0.246237\teval-logloss:0.289849\n",
      "[390]\ttrain-logloss:0.244947\teval-logloss:0.28962\n",
      "[405]\ttrain-logloss:0.243269\teval-logloss:0.289112\n",
      "[420]\ttrain-logloss:0.242119\teval-logloss:0.288854\n",
      "[435]\ttrain-logloss:0.241222\teval-logloss:0.288734\n",
      "[450]\ttrain-logloss:0.240071\teval-logloss:0.288449\n",
      "[465]\ttrain-logloss:0.238368\teval-logloss:0.288014\n",
      "[480]\ttrain-logloss:0.236735\teval-logloss:0.287621\n",
      "[495]\ttrain-logloss:0.235929\teval-logloss:0.287497\n",
      "[510]\ttrain-logloss:0.234585\teval-logloss:0.287221\n",
      "[525]\ttrain-logloss:0.233007\teval-logloss:0.28662\n",
      "[540]\ttrain-logloss:0.231691\teval-logloss:0.286253\n",
      "[555]\ttrain-logloss:0.230487\teval-logloss:0.28604\n",
      "[570]\ttrain-logloss:0.2296\teval-logloss:0.28587\n",
      "[585]\ttrain-logloss:0.228525\teval-logloss:0.285689\n",
      "[600]\ttrain-logloss:0.227687\teval-logloss:0.285542\n",
      "[615]\ttrain-logloss:0.22684\teval-logloss:0.285445\n",
      "[630]\ttrain-logloss:0.225986\teval-logloss:0.285366\n",
      "[645]\ttrain-logloss:0.224734\teval-logloss:0.284979\n",
      "[660]\ttrain-logloss:0.223419\teval-logloss:0.284625\n",
      "[675]\ttrain-logloss:0.222272\teval-logloss:0.284499\n",
      "[690]\ttrain-logloss:0.221352\teval-logloss:0.284284\n",
      "[705]\ttrain-logloss:0.220417\teval-logloss:0.284111\n",
      "[720]\ttrain-logloss:0.219393\teval-logloss:0.283914\n",
      "[735]\ttrain-logloss:0.218318\teval-logloss:0.283716\n",
      "[750]\ttrain-logloss:0.217456\teval-logloss:0.283564\n",
      "[765]\ttrain-logloss:0.216334\teval-logloss:0.283344\n",
      "[780]\ttrain-logloss:0.215533\teval-logloss:0.28323\n",
      "[795]\ttrain-logloss:0.214992\teval-logloss:0.283136\n",
      "[810]\ttrain-logloss:0.214145\teval-logloss:0.282983\n",
      "[825]\ttrain-logloss:0.213447\teval-logloss:0.282866\n",
      "[840]\ttrain-logloss:0.212211\teval-logloss:0.282456\n",
      "[855]\ttrain-logloss:0.211035\teval-logloss:0.282231\n",
      "[870]\ttrain-logloss:0.210195\teval-logloss:0.282109\n",
      "[885]\ttrain-logloss:0.209387\teval-logloss:0.282021\n",
      "[900]\ttrain-logloss:0.208177\teval-logloss:0.281666\n",
      "[915]\ttrain-logloss:0.20738\teval-logloss:0.281598\n",
      "[930]\ttrain-logloss:0.206513\teval-logloss:0.281371\n",
      "[945]\ttrain-logloss:0.20584\teval-logloss:0.281314\n",
      "[960]\ttrain-logloss:0.205239\teval-logloss:0.281222\n",
      "[975]\ttrain-logloss:0.20456\teval-logloss:0.281116\n",
      "[990]\ttrain-logloss:0.203843\teval-logloss:0.281043\n",
      "[1005]\ttrain-logloss:0.203009\teval-logloss:0.280985\n",
      "[1020]\ttrain-logloss:0.20246\teval-logloss:0.280927\n",
      "[1035]\ttrain-logloss:0.201852\teval-logloss:0.280903\n",
      "[1050]\ttrain-logloss:0.201016\teval-logloss:0.28075\n",
      "[1065]\ttrain-logloss:0.200059\teval-logloss:0.280553\n",
      "[1080]\ttrain-logloss:0.198886\teval-logloss:0.28039\n",
      "[1095]\ttrain-logloss:0.198387\teval-logloss:0.280343\n",
      "[1110]\ttrain-logloss:0.197619\teval-logloss:0.280245\n",
      "[1125]\ttrain-logloss:0.196528\teval-logloss:0.280001\n",
      "[1140]\ttrain-logloss:0.195803\teval-logloss:0.279898\n",
      "[1155]\ttrain-logloss:0.195185\teval-logloss:0.27978\n",
      "[1170]\ttrain-logloss:0.194459\teval-logloss:0.279703\n",
      "[1185]\ttrain-logloss:0.193925\teval-logloss:0.279624\n",
      "[1200]\ttrain-logloss:0.193284\teval-logloss:0.279521\n",
      "[1215]\ttrain-logloss:0.192548\teval-logloss:0.279469\n",
      "[1230]\ttrain-logloss:0.191878\teval-logloss:0.279424\n",
      "[1245]\ttrain-logloss:0.191259\teval-logloss:0.279387\n",
      "[1260]\ttrain-logloss:0.190453\teval-logloss:0.279262\n",
      "[1275]\ttrain-logloss:0.189556\teval-logloss:0.279141\n",
      "[1290]\ttrain-logloss:0.188975\teval-logloss:0.27908\n",
      "[1305]\ttrain-logloss:0.188354\teval-logloss:0.27898\n",
      "[1320]\ttrain-logloss:0.18741\teval-logloss:0.278796\n",
      "[1335]\ttrain-logloss:0.186821\teval-logloss:0.278675\n",
      "[1350]\ttrain-logloss:0.186094\teval-logloss:0.278571\n",
      "[1365]\ttrain-logloss:0.185627\teval-logloss:0.278499\n",
      "[1380]\ttrain-logloss:0.18513\teval-logloss:0.278393\n",
      "[1395]\ttrain-logloss:0.184644\teval-logloss:0.278337\n",
      "[1410]\ttrain-logloss:0.18401\teval-logloss:0.278267\n",
      "[1425]\ttrain-logloss:0.183429\teval-logloss:0.278182\n",
      "[1440]\ttrain-logloss:0.183028\teval-logloss:0.278166\n",
      "[1455]\ttrain-logloss:0.182275\teval-logloss:0.278076\n",
      "[1470]\ttrain-logloss:0.181546\teval-logloss:0.277923\n",
      "[1485]\ttrain-logloss:0.180347\teval-logloss:0.277726\n",
      "[1500]\ttrain-logloss:0.179147\teval-logloss:0.27753\n",
      "[1515]\ttrain-logloss:0.178406\teval-logloss:0.277419\n",
      "[1530]\ttrain-logloss:0.177753\teval-logloss:0.277328\n",
      "[1545]\ttrain-logloss:0.17733\teval-logloss:0.277309\n",
      "[1560]\ttrain-logloss:0.176335\teval-logloss:0.277135\n",
      "[1575]\ttrain-logloss:0.175653\teval-logloss:0.276982\n",
      "[1590]\ttrain-logloss:0.174877\teval-logloss:0.276794\n",
      "[1605]\ttrain-logloss:0.174071\teval-logloss:0.276713\n",
      "[1620]\ttrain-logloss:0.173646\teval-logloss:0.276672\n",
      "[1635]\ttrain-logloss:0.173055\teval-logloss:0.276619\n",
      "[1650]\ttrain-logloss:0.172205\teval-logloss:0.276457\n",
      "[1665]\ttrain-logloss:0.171663\teval-logloss:0.276461\n",
      "[1680]\ttrain-logloss:0.170956\teval-logloss:0.27636\n",
      "[1695]\ttrain-logloss:0.170467\teval-logloss:0.276288\n",
      "[1710]\ttrain-logloss:0.169767\teval-logloss:0.276181\n",
      "[1725]\ttrain-logloss:0.169114\teval-logloss:0.276122\n",
      "[1740]\ttrain-logloss:0.16847\teval-logloss:0.276102\n",
      "[1755]\ttrain-logloss:0.168052\teval-logloss:0.276059\n",
      "[1770]\ttrain-logloss:0.167128\teval-logloss:0.275867\n",
      "[1785]\ttrain-logloss:0.166699\teval-logloss:0.275889\n",
      "[1800]\ttrain-logloss:0.166384\teval-logloss:0.275862\n",
      "[1815]\ttrain-logloss:0.166017\teval-logloss:0.275857\n",
      "[1830]\ttrain-logloss:0.165426\teval-logloss:0.27574\n",
      "[1845]\ttrain-logloss:0.164989\teval-logloss:0.275718\n",
      "[1860]\ttrain-logloss:0.164236\teval-logloss:0.275627\n",
      "[1875]\ttrain-logloss:0.163603\teval-logloss:0.275509\n",
      "[1890]\ttrain-logloss:0.163182\teval-logloss:0.275451\n",
      "[1905]\ttrain-logloss:0.162708\teval-logloss:0.27543\n",
      "[1920]\ttrain-logloss:0.162283\teval-logloss:0.275339\n",
      "[1935]\ttrain-logloss:0.161357\teval-logloss:0.275171\n",
      "[1950]\ttrain-logloss:0.160953\teval-logloss:0.275127\n",
      "[1965]\ttrain-logloss:0.160436\teval-logloss:0.275051\n",
      "[1980]\ttrain-logloss:0.159782\teval-logloss:0.274964\n",
      "[1995]\ttrain-logloss:0.159054\teval-logloss:0.274792\n",
      "[0]\ttrain-logloss:0.643138\teval-logloss:0.643175\n",
      "[15]\ttrain-logloss:0.379356\teval-logloss:0.381734\n",
      "[30]\ttrain-logloss:0.33217\teval-logloss:0.337104\n",
      "[45]\ttrain-logloss:0.316835\teval-logloss:0.323972\n",
      "[60]\ttrain-logloss:0.307045\teval-logloss:0.316598\n",
      "[75]\ttrain-logloss:0.299716\teval-logloss:0.311992\n",
      "[90]\ttrain-logloss:0.293517\teval-logloss:0.308282\n",
      "[105]\ttrain-logloss:0.288341\teval-logloss:0.305293\n",
      "[120]\ttrain-logloss:0.284158\teval-logloss:0.303217\n",
      "[135]\ttrain-logloss:0.280699\teval-logloss:0.301591\n",
      "[150]\ttrain-logloss:0.276936\teval-logloss:0.299828\n",
      "[165]\ttrain-logloss:0.274085\teval-logloss:0.298565\n",
      "[180]\ttrain-logloss:0.270968\teval-logloss:0.297301\n",
      "[195]\ttrain-logloss:0.268015\teval-logloss:0.29607\n",
      "[210]\ttrain-logloss:0.265708\teval-logloss:0.295375\n",
      "[225]\ttrain-logloss:0.263357\teval-logloss:0.294485\n",
      "[240]\ttrain-logloss:0.260771\teval-logloss:0.293491\n",
      "[255]\ttrain-logloss:0.258563\teval-logloss:0.292769\n",
      "[270]\ttrain-logloss:0.256742\teval-logloss:0.292285\n",
      "[285]\ttrain-logloss:0.254831\teval-logloss:0.291625\n",
      "[300]\ttrain-logloss:0.252887\teval-logloss:0.290936\n",
      "[315]\ttrain-logloss:0.25133\teval-logloss:0.290476\n",
      "[330]\ttrain-logloss:0.249453\teval-logloss:0.289837\n",
      "[345]\ttrain-logloss:0.247882\teval-logloss:0.289376\n",
      "[360]\ttrain-logloss:0.246319\teval-logloss:0.28892\n",
      "[375]\ttrain-logloss:0.24505\teval-logloss:0.288489\n",
      "[390]\ttrain-logloss:0.243183\teval-logloss:0.287934\n",
      "[405]\ttrain-logloss:0.241849\teval-logloss:0.287689\n",
      "[420]\ttrain-logloss:0.240357\teval-logloss:0.287236\n",
      "[435]\ttrain-logloss:0.239027\teval-logloss:0.286995\n",
      "[450]\ttrain-logloss:0.237317\teval-logloss:0.286367\n",
      "[465]\ttrain-logloss:0.236243\teval-logloss:0.286212\n",
      "[480]\ttrain-logloss:0.234571\teval-logloss:0.285692\n",
      "[495]\ttrain-logloss:0.23358\teval-logloss:0.285538\n",
      "[510]\ttrain-logloss:0.232547\teval-logloss:0.285319\n",
      "[525]\ttrain-logloss:0.231127\teval-logloss:0.284889\n",
      "[540]\ttrain-logloss:0.229889\teval-logloss:0.284575\n",
      "[555]\ttrain-logloss:0.228743\teval-logloss:0.284293\n",
      "[570]\ttrain-logloss:0.227604\teval-logloss:0.284012\n",
      "[585]\ttrain-logloss:0.226524\teval-logloss:0.283725\n",
      "[600]\ttrain-logloss:0.225267\teval-logloss:0.283328\n",
      "[615]\ttrain-logloss:0.224486\teval-logloss:0.28321\n",
      "[630]\ttrain-logloss:0.223515\teval-logloss:0.28303\n",
      "[645]\ttrain-logloss:0.222639\teval-logloss:0.282863\n",
      "[660]\ttrain-logloss:0.221721\teval-logloss:0.282673\n",
      "[675]\ttrain-logloss:0.220769\teval-logloss:0.282516\n",
      "[690]\ttrain-logloss:0.219926\teval-logloss:0.282398\n",
      "[705]\ttrain-logloss:0.218737\teval-logloss:0.282154\n",
      "[720]\ttrain-logloss:0.217405\teval-logloss:0.281842\n",
      "[735]\ttrain-logloss:0.216727\teval-logloss:0.281776\n",
      "[750]\ttrain-logloss:0.215991\teval-logloss:0.281669\n",
      "[765]\ttrain-logloss:0.214963\teval-logloss:0.281489\n",
      "[780]\ttrain-logloss:0.214274\teval-logloss:0.281413\n",
      "[795]\ttrain-logloss:0.21335\teval-logloss:0.281247\n",
      "[810]\ttrain-logloss:0.212514\teval-logloss:0.28108\n",
      "[825]\ttrain-logloss:0.211727\teval-logloss:0.280938\n",
      "[840]\ttrain-logloss:0.210508\teval-logloss:0.280626\n",
      "[855]\ttrain-logloss:0.209413\teval-logloss:0.280423\n",
      "[870]\ttrain-logloss:0.208131\teval-logloss:0.280017\n",
      "[885]\ttrain-logloss:0.207095\teval-logloss:0.279787\n",
      "[900]\ttrain-logloss:0.20637\teval-logloss:0.279699\n",
      "[915]\ttrain-logloss:0.205472\teval-logloss:0.279407\n",
      "[930]\ttrain-logloss:0.20479\teval-logloss:0.279375\n",
      "[945]\ttrain-logloss:0.204167\teval-logloss:0.279324\n",
      "[960]\ttrain-logloss:0.203438\teval-logloss:0.279264\n",
      "[975]\ttrain-logloss:0.202214\teval-logloss:0.278988\n",
      "[990]\ttrain-logloss:0.201382\teval-logloss:0.278831\n",
      "[1005]\ttrain-logloss:0.200471\teval-logloss:0.278655\n",
      "[1020]\ttrain-logloss:0.199824\teval-logloss:0.278574\n",
      "[1035]\ttrain-logloss:0.198933\teval-logloss:0.278372\n",
      "[1050]\ttrain-logloss:0.197864\teval-logloss:0.278141\n",
      "[1065]\ttrain-logloss:0.197252\teval-logloss:0.278087\n",
      "[1080]\ttrain-logloss:0.196587\teval-logloss:0.277989\n",
      "[1095]\ttrain-logloss:0.195663\teval-logloss:0.277774\n",
      "[1110]\ttrain-logloss:0.194993\teval-logloss:0.277704\n",
      "[1125]\ttrain-logloss:0.194444\teval-logloss:0.27765\n",
      "[1140]\ttrain-logloss:0.193927\teval-logloss:0.277648\n",
      "[1155]\ttrain-logloss:0.192649\teval-logloss:0.277389\n",
      "[1170]\ttrain-logloss:0.191942\teval-logloss:0.277341\n",
      "[1185]\ttrain-logloss:0.191267\teval-logloss:0.277235\n",
      "[1200]\ttrain-logloss:0.190778\teval-logloss:0.27722\n",
      "[1215]\ttrain-logloss:0.189927\teval-logloss:0.277087\n",
      "[1230]\ttrain-logloss:0.189347\teval-logloss:0.277037\n",
      "[1245]\ttrain-logloss:0.188868\teval-logloss:0.276996\n",
      "[1260]\ttrain-logloss:0.18835\teval-logloss:0.276928\n",
      "[1275]\ttrain-logloss:0.187394\teval-logloss:0.276755\n",
      "[1290]\ttrain-logloss:0.186162\teval-logloss:0.276468\n",
      "[1305]\ttrain-logloss:0.185617\teval-logloss:0.276403\n",
      "[1320]\ttrain-logloss:0.18453\teval-logloss:0.276188\n",
      "[1335]\ttrain-logloss:0.18385\teval-logloss:0.276098\n",
      "[1350]\ttrain-logloss:0.183255\teval-logloss:0.276072\n",
      "[1365]\ttrain-logloss:0.182675\teval-logloss:0.276038\n",
      "[1380]\ttrain-logloss:0.182028\teval-logloss:0.275954\n",
      "[1395]\ttrain-logloss:0.180996\teval-logloss:0.275795\n",
      "[1410]\ttrain-logloss:0.180444\teval-logloss:0.2757\n",
      "[1425]\ttrain-logloss:0.179983\teval-logloss:0.275636\n",
      "[1440]\ttrain-logloss:0.179436\teval-logloss:0.275516\n",
      "[1455]\ttrain-logloss:0.178799\teval-logloss:0.275488\n",
      "[1470]\ttrain-logloss:0.178391\teval-logloss:0.275437\n",
      "[1485]\ttrain-logloss:0.177928\teval-logloss:0.275437\n",
      "[1500]\ttrain-logloss:0.177364\teval-logloss:0.275376\n",
      "[1515]\ttrain-logloss:0.176709\teval-logloss:0.275254\n",
      "[1530]\ttrain-logloss:0.176127\teval-logloss:0.275234\n",
      "[1545]\ttrain-logloss:0.175464\teval-logloss:0.275135\n",
      "[1560]\ttrain-logloss:0.174788\teval-logloss:0.275069\n",
      "[1575]\ttrain-logloss:0.174267\teval-logloss:0.275016\n",
      "[1590]\ttrain-logloss:0.173789\teval-logloss:0.275016\n",
      "[1605]\ttrain-logloss:0.173331\teval-logloss:0.274975\n",
      "[1620]\ttrain-logloss:0.172823\teval-logloss:0.27496\n",
      "[1635]\ttrain-logloss:0.172098\teval-logloss:0.274881\n",
      "[1650]\ttrain-logloss:0.171756\teval-logloss:0.274878\n",
      "[1665]\ttrain-logloss:0.171013\teval-logloss:0.274774\n",
      "[1680]\ttrain-logloss:0.170141\teval-logloss:0.274682\n",
      "[1695]\ttrain-logloss:0.169606\teval-logloss:0.274629\n",
      "[1710]\ttrain-logloss:0.169225\teval-logloss:0.274596\n",
      "[1725]\ttrain-logloss:0.168811\teval-logloss:0.27454\n",
      "[1740]\ttrain-logloss:0.168164\teval-logloss:0.274414\n",
      "[1755]\ttrain-logloss:0.167301\teval-logloss:0.274209\n",
      "[1770]\ttrain-logloss:0.166838\teval-logloss:0.274178\n",
      "[1785]\ttrain-logloss:0.166447\teval-logloss:0.274112\n",
      "[1800]\ttrain-logloss:0.166089\teval-logloss:0.274072\n",
      "[1815]\ttrain-logloss:0.165089\teval-logloss:0.273813\n",
      "[1830]\ttrain-logloss:0.164576\teval-logloss:0.273767\n",
      "[1845]\ttrain-logloss:0.163839\teval-logloss:0.273679\n",
      "[1860]\ttrain-logloss:0.163428\teval-logloss:0.273618\n",
      "[1875]\ttrain-logloss:0.162752\teval-logloss:0.273548\n",
      "[1890]\ttrain-logloss:0.162127\teval-logloss:0.273456\n",
      "[1905]\ttrain-logloss:0.161538\teval-logloss:0.27339\n",
      "[1920]\ttrain-logloss:0.16108\teval-logloss:0.273316\n",
      "[1935]\ttrain-logloss:0.159999\teval-logloss:0.27319\n",
      "[1950]\ttrain-logloss:0.159552\teval-logloss:0.273149\n",
      "[1965]\ttrain-logloss:0.159131\teval-logloss:0.273113\n",
      "[1980]\ttrain-logloss:0.158651\teval-logloss:0.273114\n",
      "[1995]\ttrain-logloss:0.158074\teval-logloss:0.27304\n",
      "[0]\ttrain-logloss:0.642944\teval-logloss:0.643409\n",
      "[15]\ttrain-logloss:0.379156\teval-logloss:0.384099\n",
      "[30]\ttrain-logloss:0.331813\teval-logloss:0.339475\n",
      "[45]\ttrain-logloss:0.316171\teval-logloss:0.325983\n",
      "[60]\ttrain-logloss:0.306355\teval-logloss:0.31884\n",
      "[75]\ttrain-logloss:0.299016\teval-logloss:0.314014\n",
      "[90]\ttrain-logloss:0.293559\teval-logloss:0.310672\n",
      "[105]\ttrain-logloss:0.28845\teval-logloss:0.307935\n",
      "[120]\ttrain-logloss:0.284162\teval-logloss:0.30562\n",
      "[135]\ttrain-logloss:0.280257\teval-logloss:0.303601\n",
      "[150]\ttrain-logloss:0.276866\teval-logloss:0.301966\n",
      "[165]\ttrain-logloss:0.273515\teval-logloss:0.300523\n",
      "[180]\ttrain-logloss:0.271132\teval-logloss:0.299415\n",
      "[195]\ttrain-logloss:0.26837\teval-logloss:0.29815\n",
      "[210]\ttrain-logloss:0.266184\teval-logloss:0.297232\n",
      "[225]\ttrain-logloss:0.26388\teval-logloss:0.296424\n",
      "[240]\ttrain-logloss:0.26084\teval-logloss:0.295072\n",
      "[255]\ttrain-logloss:0.259085\teval-logloss:0.294498\n",
      "[270]\ttrain-logloss:0.257069\teval-logloss:0.293819\n",
      "[285]\ttrain-logloss:0.255472\teval-logloss:0.293251\n",
      "[300]\ttrain-logloss:0.253204\teval-logloss:0.29225\n",
      "[315]\ttrain-logloss:0.251463\teval-logloss:0.291715\n",
      "[330]\ttrain-logloss:0.250251\teval-logloss:0.291425\n",
      "[345]\ttrain-logloss:0.24859\teval-logloss:0.290875\n",
      "[360]\ttrain-logloss:0.246992\teval-logloss:0.290472\n",
      "[375]\ttrain-logloss:0.244765\teval-logloss:0.289569\n",
      "[390]\ttrain-logloss:0.243613\teval-logloss:0.289367\n",
      "[405]\ttrain-logloss:0.241535\teval-logloss:0.288838\n",
      "[420]\ttrain-logloss:0.240136\teval-logloss:0.28851\n",
      "[435]\ttrain-logloss:0.239136\teval-logloss:0.288303\n",
      "[450]\ttrain-logloss:0.238099\teval-logloss:0.288037\n",
      "[465]\ttrain-logloss:0.236657\teval-logloss:0.287627\n",
      "[480]\ttrain-logloss:0.235386\teval-logloss:0.287221\n",
      "[495]\ttrain-logloss:0.233551\teval-logloss:0.286717\n",
      "[510]\ttrain-logloss:0.23231\teval-logloss:0.286464\n",
      "[525]\ttrain-logloss:0.231346\teval-logloss:0.286326\n",
      "[540]\ttrain-logloss:0.230136\teval-logloss:0.285974\n",
      "[555]\ttrain-logloss:0.228998\teval-logloss:0.28574\n",
      "[570]\ttrain-logloss:0.228044\teval-logloss:0.28561\n",
      "[585]\ttrain-logloss:0.227286\teval-logloss:0.285454\n",
      "[600]\ttrain-logloss:0.226373\teval-logloss:0.285339\n",
      "[615]\ttrain-logloss:0.225271\teval-logloss:0.285153\n",
      "[630]\ttrain-logloss:0.223581\teval-logloss:0.284653\n",
      "[645]\ttrain-logloss:0.222652\teval-logloss:0.284488\n",
      "[660]\ttrain-logloss:0.221806\teval-logloss:0.284326\n",
      "[675]\ttrain-logloss:0.220698\teval-logloss:0.28409\n",
      "[690]\ttrain-logloss:0.219847\teval-logloss:0.284\n",
      "[705]\ttrain-logloss:0.218582\teval-logloss:0.283708\n",
      "[720]\ttrain-logloss:0.217397\teval-logloss:0.283546\n",
      "[735]\ttrain-logloss:0.21664\teval-logloss:0.283437\n",
      "[750]\ttrain-logloss:0.215785\teval-logloss:0.283232\n",
      "[765]\ttrain-logloss:0.214789\teval-logloss:0.282965\n",
      "[780]\ttrain-logloss:0.21404\teval-logloss:0.282845\n",
      "[795]\ttrain-logloss:0.213213\teval-logloss:0.282715\n",
      "[810]\ttrain-logloss:0.212276\teval-logloss:0.282614\n",
      "[825]\ttrain-logloss:0.211365\teval-logloss:0.282553\n",
      "[840]\ttrain-logloss:0.210763\teval-logloss:0.28243\n",
      "[855]\ttrain-logloss:0.209843\teval-logloss:0.282284\n",
      "[870]\ttrain-logloss:0.20899\teval-logloss:0.282181\n",
      "[885]\ttrain-logloss:0.20825\teval-logloss:0.282063\n",
      "[900]\ttrain-logloss:0.207661\teval-logloss:0.282022\n",
      "[915]\ttrain-logloss:0.206602\teval-logloss:0.281794\n",
      "[930]\ttrain-logloss:0.205445\teval-logloss:0.281513\n",
      "[945]\ttrain-logloss:0.204526\teval-logloss:0.281392\n",
      "[960]\ttrain-logloss:0.203891\teval-logloss:0.281332\n",
      "[975]\ttrain-logloss:0.202854\teval-logloss:0.281148\n",
      "[990]\ttrain-logloss:0.202054\teval-logloss:0.281023\n",
      "[1005]\ttrain-logloss:0.201375\teval-logloss:0.280916\n",
      "[1020]\ttrain-logloss:0.200347\teval-logloss:0.280755\n",
      "[1035]\ttrain-logloss:0.199545\teval-logloss:0.280688\n",
      "[1050]\ttrain-logloss:0.198824\teval-logloss:0.280562\n",
      "[1065]\ttrain-logloss:0.19778\teval-logloss:0.280347\n",
      "[1080]\ttrain-logloss:0.197091\teval-logloss:0.280246\n",
      "[1095]\ttrain-logloss:0.196406\teval-logloss:0.280049\n",
      "[1110]\ttrain-logloss:0.195676\teval-logloss:0.279928\n",
      "[1125]\ttrain-logloss:0.194668\teval-logloss:0.279697\n",
      "[1140]\ttrain-logloss:0.193734\teval-logloss:0.279518\n",
      "[1155]\ttrain-logloss:0.193072\teval-logloss:0.279441\n",
      "[1170]\ttrain-logloss:0.192298\teval-logloss:0.279315\n",
      "[1185]\ttrain-logloss:0.191275\teval-logloss:0.279158\n",
      "[1200]\ttrain-logloss:0.190787\teval-logloss:0.279102\n",
      "[1215]\ttrain-logloss:0.189939\teval-logloss:0.278738\n",
      "[1230]\ttrain-logloss:0.189321\teval-logloss:0.278663\n",
      "[1245]\ttrain-logloss:0.188605\teval-logloss:0.278585\n",
      "[1260]\ttrain-logloss:0.187909\teval-logloss:0.278513\n",
      "[1275]\ttrain-logloss:0.186919\teval-logloss:0.27827\n",
      "[1290]\ttrain-logloss:0.186415\teval-logloss:0.278215\n",
      "[1305]\ttrain-logloss:0.185814\teval-logloss:0.278197\n",
      "[1320]\ttrain-logloss:0.185297\teval-logloss:0.278173\n",
      "[1335]\ttrain-logloss:0.18465\teval-logloss:0.278058\n",
      "[1350]\ttrain-logloss:0.184196\teval-logloss:0.278038\n",
      "[1365]\ttrain-logloss:0.183504\teval-logloss:0.277944\n",
      "[1380]\ttrain-logloss:0.182868\teval-logloss:0.277859\n",
      "[1395]\ttrain-logloss:0.182287\teval-logloss:0.277741\n",
      "[1410]\ttrain-logloss:0.181696\teval-logloss:0.277678\n",
      "[1425]\ttrain-logloss:0.181006\teval-logloss:0.277607\n",
      "[1440]\ttrain-logloss:0.180032\teval-logloss:0.277395\n",
      "[1455]\ttrain-logloss:0.179355\teval-logloss:0.27729\n",
      "[1470]\ttrain-logloss:0.178494\teval-logloss:0.277182\n",
      "[1485]\ttrain-logloss:0.177698\teval-logloss:0.277087\n",
      "[1500]\ttrain-logloss:0.177124\teval-logloss:0.277055\n",
      "[1515]\ttrain-logloss:0.176687\teval-logloss:0.277058\n",
      "[1530]\ttrain-logloss:0.17615\teval-logloss:0.276981\n",
      "[1545]\ttrain-logloss:0.175571\teval-logloss:0.276889\n",
      "[1560]\ttrain-logloss:0.174792\teval-logloss:0.276696\n",
      "[1575]\ttrain-logloss:0.173982\teval-logloss:0.276513\n",
      "[1590]\ttrain-logloss:0.173409\teval-logloss:0.276446\n",
      "[1605]\ttrain-logloss:0.172772\teval-logloss:0.276338\n",
      "[1620]\ttrain-logloss:0.172084\teval-logloss:0.276236\n",
      "[1635]\ttrain-logloss:0.171446\teval-logloss:0.276165\n",
      "[1650]\ttrain-logloss:0.170685\teval-logloss:0.276041\n",
      "[1665]\ttrain-logloss:0.170175\teval-logloss:0.276003\n",
      "[1680]\ttrain-logloss:0.169722\teval-logloss:0.275993\n",
      "[1695]\ttrain-logloss:0.169331\teval-logloss:0.276005\n",
      "[1710]\ttrain-logloss:0.168937\teval-logloss:0.275994\n",
      "[1725]\ttrain-logloss:0.168456\teval-logloss:0.275956\n",
      "[1740]\ttrain-logloss:0.167815\teval-logloss:0.275864\n",
      "[1755]\ttrain-logloss:0.167251\teval-logloss:0.275806\n",
      "[1770]\ttrain-logloss:0.166554\teval-logloss:0.275755\n",
      "[1785]\ttrain-logloss:0.165809\teval-logloss:0.275684\n",
      "[1800]\ttrain-logloss:0.165056\teval-logloss:0.275563\n",
      "[1815]\ttrain-logloss:0.164289\teval-logloss:0.275466\n",
      "[1830]\ttrain-logloss:0.163772\teval-logloss:0.275409\n",
      "[1845]\ttrain-logloss:0.163422\teval-logloss:0.275393\n",
      "[1860]\ttrain-logloss:0.162748\teval-logloss:0.275341\n",
      "[1875]\ttrain-logloss:0.16217\teval-logloss:0.275297\n",
      "[1890]\ttrain-logloss:0.161681\teval-logloss:0.275273\n",
      "[1905]\ttrain-logloss:0.161207\teval-logloss:0.275217\n",
      "[1920]\ttrain-logloss:0.160483\teval-logloss:0.275133\n",
      "[1935]\ttrain-logloss:0.159874\teval-logloss:0.275059\n",
      "[1950]\ttrain-logloss:0.159393\teval-logloss:0.275033\n",
      "[1965]\ttrain-logloss:0.158931\teval-logloss:0.275036\n",
      "[1980]\ttrain-logloss:0.158476\teval-logloss:0.274966\n",
      "[1995]\ttrain-logloss:0.158044\teval-logloss:0.274915\n",
      "[0]\ttrain-logloss:0.643114\teval-logloss:0.643028\n",
      "[15]\ttrain-logloss:0.379683\teval-logloss:0.380099\n",
      "[30]\ttrain-logloss:0.332542\teval-logloss:0.334991\n",
      "[45]\ttrain-logloss:0.317255\teval-logloss:0.321427\n",
      "[60]\ttrain-logloss:0.307599\teval-logloss:0.314032\n",
      "[75]\ttrain-logloss:0.299828\teval-logloss:0.308813\n",
      "[90]\ttrain-logloss:0.294222\teval-logloss:0.305626\n",
      "[105]\ttrain-logloss:0.289216\teval-logloss:0.302646\n",
      "[120]\ttrain-logloss:0.284695\teval-logloss:0.300283\n",
      "[135]\ttrain-logloss:0.281237\teval-logloss:0.298623\n",
      "[150]\ttrain-logloss:0.277683\teval-logloss:0.296864\n",
      "[165]\ttrain-logloss:0.274788\teval-logloss:0.295684\n",
      "[180]\ttrain-logloss:0.272088\teval-logloss:0.294674\n",
      "[195]\ttrain-logloss:0.269552\teval-logloss:0.293622\n",
      "[210]\ttrain-logloss:0.267147\teval-logloss:0.292678\n",
      "[225]\ttrain-logloss:0.264165\teval-logloss:0.291353\n",
      "[240]\ttrain-logloss:0.262371\teval-logloss:0.290892\n",
      "[255]\ttrain-logloss:0.260238\teval-logloss:0.290198\n",
      "[270]\ttrain-logloss:0.258223\teval-logloss:0.289406\n",
      "[285]\ttrain-logloss:0.256155\teval-logloss:0.288739\n",
      "[300]\ttrain-logloss:0.254247\teval-logloss:0.288117\n",
      "[315]\ttrain-logloss:0.25279\teval-logloss:0.287674\n",
      "[330]\ttrain-logloss:0.251097\teval-logloss:0.287056\n",
      "[345]\ttrain-logloss:0.249702\teval-logloss:0.286729\n",
      "[360]\ttrain-logloss:0.248194\teval-logloss:0.286358\n",
      "[375]\ttrain-logloss:0.246814\teval-logloss:0.286057\n",
      "[390]\ttrain-logloss:0.245255\teval-logloss:0.285576\n",
      "[405]\ttrain-logloss:0.24363\teval-logloss:0.285086\n",
      "[420]\ttrain-logloss:0.242498\teval-logloss:0.284851\n",
      "[435]\ttrain-logloss:0.2413\teval-logloss:0.284616\n",
      "[450]\ttrain-logloss:0.24023\teval-logloss:0.284392\n",
      "[465]\ttrain-logloss:0.23916\teval-logloss:0.284146\n",
      "[480]\ttrain-logloss:0.23788\teval-logloss:0.283818\n",
      "[495]\ttrain-logloss:0.236301\teval-logloss:0.283342\n",
      "[510]\ttrain-logloss:0.234991\teval-logloss:0.283017\n",
      "[525]\ttrain-logloss:0.233641\teval-logloss:0.282707\n",
      "[540]\ttrain-logloss:0.232346\teval-logloss:0.282406\n",
      "[555]\ttrain-logloss:0.230946\teval-logloss:0.282075\n",
      "[570]\ttrain-logloss:0.22988\teval-logloss:0.281943\n",
      "[585]\ttrain-logloss:0.228854\teval-logloss:0.281725\n",
      "[600]\ttrain-logloss:0.227681\teval-logloss:0.281494\n",
      "[615]\ttrain-logloss:0.226663\teval-logloss:0.281266\n",
      "[630]\ttrain-logloss:0.225695\teval-logloss:0.281138\n",
      "[645]\ttrain-logloss:0.224924\teval-logloss:0.281046\n",
      "[660]\ttrain-logloss:0.224053\teval-logloss:0.280894\n",
      "[675]\ttrain-logloss:0.223347\teval-logloss:0.280838\n",
      "[690]\ttrain-logloss:0.221666\teval-logloss:0.280453\n",
      "[705]\ttrain-logloss:0.220681\teval-logloss:0.280234\n",
      "[720]\ttrain-logloss:0.219974\teval-logloss:0.280155\n",
      "[735]\ttrain-logloss:0.218856\teval-logloss:0.2799\n",
      "[750]\ttrain-logloss:0.217907\teval-logloss:0.279672\n",
      "[765]\ttrain-logloss:0.21698\teval-logloss:0.279437\n",
      "[780]\ttrain-logloss:0.216125\teval-logloss:0.279292\n",
      "[795]\ttrain-logloss:0.215339\teval-logloss:0.279203\n",
      "[810]\ttrain-logloss:0.21418\teval-logloss:0.278976\n",
      "[825]\ttrain-logloss:0.21348\teval-logloss:0.278958\n",
      "[840]\ttrain-logloss:0.212286\teval-logloss:0.278718\n",
      "[855]\ttrain-logloss:0.211762\teval-logloss:0.278647\n",
      "[870]\ttrain-logloss:0.210715\teval-logloss:0.278425\n",
      "[885]\ttrain-logloss:0.209591\teval-logloss:0.278198\n",
      "[900]\ttrain-logloss:0.20883\teval-logloss:0.278107\n",
      "[915]\ttrain-logloss:0.20774\teval-logloss:0.277898\n",
      "[930]\ttrain-logloss:0.206877\teval-logloss:0.277754\n",
      "[945]\ttrain-logloss:0.206159\teval-logloss:0.277668\n",
      "[960]\ttrain-logloss:0.205492\teval-logloss:0.27756\n",
      "[975]\ttrain-logloss:0.204277\teval-logloss:0.277318\n",
      "[990]\ttrain-logloss:0.203673\teval-logloss:0.277263\n",
      "[1005]\ttrain-logloss:0.203018\teval-logloss:0.277174\n",
      "[1020]\ttrain-logloss:0.202558\teval-logloss:0.277117\n",
      "[1035]\ttrain-logloss:0.201337\teval-logloss:0.276831\n",
      "[1050]\ttrain-logloss:0.200097\teval-logloss:0.276514\n",
      "[1065]\ttrain-logloss:0.199536\teval-logloss:0.276426\n",
      "[1080]\ttrain-logloss:0.198963\teval-logloss:0.276365\n",
      "[1095]\ttrain-logloss:0.198417\teval-logloss:0.27631\n",
      "[1110]\ttrain-logloss:0.197796\teval-logloss:0.276205\n",
      "[1125]\ttrain-logloss:0.196954\teval-logloss:0.276016\n",
      "[1140]\ttrain-logloss:0.195851\teval-logloss:0.275882\n",
      "[1155]\ttrain-logloss:0.194557\teval-logloss:0.275587\n",
      "[1170]\ttrain-logloss:0.193785\teval-logloss:0.275525\n",
      "[1185]\ttrain-logloss:0.192756\teval-logloss:0.275401\n",
      "[1200]\ttrain-logloss:0.192067\teval-logloss:0.275264\n",
      "[1215]\ttrain-logloss:0.191545\teval-logloss:0.275174\n",
      "[1230]\ttrain-logloss:0.191048\teval-logloss:0.275112\n",
      "[1245]\ttrain-logloss:0.190452\teval-logloss:0.275085\n",
      "[1260]\ttrain-logloss:0.189803\teval-logloss:0.275025\n",
      "[1275]\ttrain-logloss:0.189065\teval-logloss:0.274933\n",
      "[1290]\ttrain-logloss:0.188306\teval-logloss:0.274842\n",
      "[1305]\ttrain-logloss:0.187589\teval-logloss:0.274734\n",
      "[1320]\ttrain-logloss:0.186557\teval-logloss:0.274592\n",
      "[1335]\ttrain-logloss:0.185706\teval-logloss:0.274443\n",
      "[1350]\ttrain-logloss:0.184836\teval-logloss:0.274275\n",
      "[1365]\ttrain-logloss:0.184107\teval-logloss:0.274161\n",
      "[1380]\ttrain-logloss:0.183668\teval-logloss:0.274107\n",
      "[1395]\ttrain-logloss:0.182956\teval-logloss:0.274009\n",
      "[1410]\ttrain-logloss:0.182231\teval-logloss:0.273886\n",
      "[1425]\ttrain-logloss:0.181674\teval-logloss:0.273841\n",
      "[1440]\ttrain-logloss:0.180848\teval-logloss:0.273688\n",
      "[1455]\ttrain-logloss:0.180163\teval-logloss:0.273607\n",
      "[1470]\ttrain-logloss:0.179438\teval-logloss:0.273507\n",
      "[1485]\ttrain-logloss:0.178766\teval-logloss:0.273369\n",
      "[1500]\ttrain-logloss:0.178215\teval-logloss:0.273363\n",
      "[1515]\ttrain-logloss:0.177711\teval-logloss:0.27337\n",
      "[1530]\ttrain-logloss:0.177161\teval-logloss:0.273316\n",
      "[1545]\ttrain-logloss:0.176371\teval-logloss:0.273258\n",
      "[1560]\ttrain-logloss:0.175699\teval-logloss:0.273174\n",
      "[1575]\ttrain-logloss:0.175151\teval-logloss:0.27308\n",
      "[1590]\ttrain-logloss:0.174635\teval-logloss:0.273045\n",
      "[1605]\ttrain-logloss:0.174004\teval-logloss:0.272989\n",
      "[1620]\ttrain-logloss:0.173728\teval-logloss:0.272981\n",
      "[1635]\ttrain-logloss:0.172962\teval-logloss:0.272885\n",
      "[1650]\ttrain-logloss:0.172372\teval-logloss:0.272795\n",
      "[1665]\ttrain-logloss:0.171353\teval-logloss:0.272622\n",
      "[1680]\ttrain-logloss:0.170554\teval-logloss:0.27245\n",
      "[1695]\ttrain-logloss:0.169995\teval-logloss:0.272399\n",
      "[1710]\ttrain-logloss:0.16886\teval-logloss:0.272148\n",
      "[1725]\ttrain-logloss:0.16812\teval-logloss:0.272093\n",
      "[1740]\ttrain-logloss:0.167581\teval-logloss:0.271978\n",
      "[1755]\ttrain-logloss:0.167108\teval-logloss:0.271881\n",
      "[1770]\ttrain-logloss:0.166748\teval-logloss:0.271838\n",
      "[1785]\ttrain-logloss:0.166003\teval-logloss:0.271792\n",
      "[1800]\ttrain-logloss:0.16541\teval-logloss:0.271711\n",
      "[1815]\ttrain-logloss:0.164822\teval-logloss:0.27168\n",
      "[1830]\ttrain-logloss:0.164382\teval-logloss:0.271615\n",
      "[1845]\ttrain-logloss:0.163637\teval-logloss:0.271564\n",
      "[1860]\ttrain-logloss:0.16331\teval-logloss:0.271528\n",
      "[1875]\ttrain-logloss:0.162615\teval-logloss:0.27143\n",
      "[1890]\ttrain-logloss:0.161877\teval-logloss:0.271355\n",
      "[1905]\ttrain-logloss:0.161368\teval-logloss:0.271317\n",
      "[1920]\ttrain-logloss:0.16048\teval-logloss:0.271151\n",
      "[1935]\ttrain-logloss:0.159723\teval-logloss:0.271003\n",
      "[1950]\ttrain-logloss:0.159193\teval-logloss:0.270968\n",
      "[1965]\ttrain-logloss:0.158872\teval-logloss:0.270944\n",
      "[1980]\ttrain-logloss:0.158123\teval-logloss:0.270867\n",
      "[1995]\ttrain-logloss:0.157627\teval-logloss:0.270805\n",
      "[0]\ttrain-logloss:0.642917\teval-logloss:0.643107\n",
      "[15]\ttrain-logloss:0.379959\teval-logloss:0.383575\n",
      "[30]\ttrain-logloss:0.3324\teval-logloss:0.338912\n",
      "[45]\ttrain-logloss:0.316787\teval-logloss:0.325364\n",
      "[60]\ttrain-logloss:0.306906\teval-logloss:0.318051\n",
      "[75]\ttrain-logloss:0.299848\teval-logloss:0.313103\n",
      "[90]\ttrain-logloss:0.293526\teval-logloss:0.308994\n",
      "[105]\ttrain-logloss:0.288929\teval-logloss:0.306502\n",
      "[120]\ttrain-logloss:0.285097\teval-logloss:0.304586\n",
      "[135]\ttrain-logloss:0.280954\teval-logloss:0.302415\n",
      "[150]\ttrain-logloss:0.277276\teval-logloss:0.300747\n",
      "[165]\ttrain-logloss:0.274417\teval-logloss:0.299475\n",
      "[180]\ttrain-logloss:0.271528\teval-logloss:0.298292\n",
      "[195]\ttrain-logloss:0.268801\teval-logloss:0.297144\n",
      "[210]\ttrain-logloss:0.266455\teval-logloss:0.296241\n",
      "[225]\ttrain-logloss:0.264016\teval-logloss:0.295291\n",
      "[240]\ttrain-logloss:0.262088\teval-logloss:0.294633\n",
      "[255]\ttrain-logloss:0.260109\teval-logloss:0.29396\n",
      "[270]\ttrain-logloss:0.257897\teval-logloss:0.293282\n",
      "[285]\ttrain-logloss:0.256019\teval-logloss:0.292608\n",
      "[300]\ttrain-logloss:0.254166\teval-logloss:0.292114\n",
      "[315]\ttrain-logloss:0.252333\teval-logloss:0.291496\n",
      "[330]\ttrain-logloss:0.250661\teval-logloss:0.290959\n",
      "[345]\ttrain-logloss:0.249482\teval-logloss:0.290625\n",
      "[360]\ttrain-logloss:0.247878\teval-logloss:0.290271\n",
      "[375]\ttrain-logloss:0.246318\teval-logloss:0.289862\n",
      "[390]\ttrain-logloss:0.244795\teval-logloss:0.289417\n",
      "[405]\ttrain-logloss:0.243473\teval-logloss:0.288993\n",
      "[420]\ttrain-logloss:0.242335\teval-logloss:0.288658\n",
      "[435]\ttrain-logloss:0.241111\teval-logloss:0.2884\n",
      "[450]\ttrain-logloss:0.240149\teval-logloss:0.288188\n",
      "[465]\ttrain-logloss:0.238444\teval-logloss:0.28767\n",
      "[480]\ttrain-logloss:0.237239\teval-logloss:0.287395\n",
      "[495]\ttrain-logloss:0.235901\teval-logloss:0.28701\n",
      "[510]\ttrain-logloss:0.234773\teval-logloss:0.286671\n",
      "[525]\ttrain-logloss:0.233519\teval-logloss:0.286397\n",
      "[540]\ttrain-logloss:0.23224\teval-logloss:0.286069\n",
      "[555]\ttrain-logloss:0.231341\teval-logloss:0.28591\n",
      "[570]\ttrain-logloss:0.230394\teval-logloss:0.285654\n",
      "[585]\ttrain-logloss:0.229622\teval-logloss:0.28557\n",
      "[600]\ttrain-logloss:0.228557\teval-logloss:0.285412\n",
      "[615]\ttrain-logloss:0.22757\teval-logloss:0.285256\n",
      "[630]\ttrain-logloss:0.226128\teval-logloss:0.284873\n",
      "[645]\ttrain-logloss:0.22484\teval-logloss:0.284495\n",
      "[660]\ttrain-logloss:0.224035\teval-logloss:0.284361\n",
      "[675]\ttrain-logloss:0.223114\teval-logloss:0.284156\n",
      "[690]\ttrain-logloss:0.221701\teval-logloss:0.283773\n",
      "[705]\ttrain-logloss:0.220251\teval-logloss:0.283439\n",
      "[720]\ttrain-logloss:0.219606\teval-logloss:0.283366\n",
      "[735]\ttrain-logloss:0.218093\teval-logloss:0.283015\n",
      "[750]\ttrain-logloss:0.217148\teval-logloss:0.282892\n",
      "[765]\ttrain-logloss:0.216268\teval-logloss:0.282778\n",
      "[780]\ttrain-logloss:0.215188\teval-logloss:0.282559\n",
      "[795]\ttrain-logloss:0.214423\teval-logloss:0.282418\n",
      "[810]\ttrain-logloss:0.213719\teval-logloss:0.282291\n",
      "[825]\ttrain-logloss:0.213037\teval-logloss:0.282197\n",
      "[840]\ttrain-logloss:0.212137\teval-logloss:0.281962\n",
      "[855]\ttrain-logloss:0.211099\teval-logloss:0.281795\n",
      "[870]\ttrain-logloss:0.209635\teval-logloss:0.281305\n",
      "[885]\ttrain-logloss:0.208767\teval-logloss:0.281191\n",
      "[900]\ttrain-logloss:0.207931\teval-logloss:0.281107\n",
      "[915]\ttrain-logloss:0.207311\teval-logloss:0.280981\n",
      "[930]\ttrain-logloss:0.206603\teval-logloss:0.280945\n",
      "[945]\ttrain-logloss:0.205473\teval-logloss:0.280689\n",
      "[960]\ttrain-logloss:0.204774\teval-logloss:0.280597\n",
      "[975]\ttrain-logloss:0.204037\teval-logloss:0.280498\n",
      "[990]\ttrain-logloss:0.20335\teval-logloss:0.280424\n",
      "[1005]\ttrain-logloss:0.202522\teval-logloss:0.280353\n",
      "[1020]\ttrain-logloss:0.201867\teval-logloss:0.280262\n",
      "[1035]\ttrain-logloss:0.200967\teval-logloss:0.280101\n",
      "[1050]\ttrain-logloss:0.200424\teval-logloss:0.280048\n",
      "[1065]\ttrain-logloss:0.199302\teval-logloss:0.279838\n",
      "[1080]\ttrain-logloss:0.19861\teval-logloss:0.279768\n",
      "[1095]\ttrain-logloss:0.197783\teval-logloss:0.279592\n",
      "[1110]\ttrain-logloss:0.197003\teval-logloss:0.279461\n",
      "[1125]\ttrain-logloss:0.195769\teval-logloss:0.279159\n",
      "[1140]\ttrain-logloss:0.195126\teval-logloss:0.279112\n",
      "[1155]\ttrain-logloss:0.19392\teval-logloss:0.278884\n",
      "[1170]\ttrain-logloss:0.19296\teval-logloss:0.278735\n",
      "[1185]\ttrain-logloss:0.191879\teval-logloss:0.278497\n",
      "[1200]\ttrain-logloss:0.19132\teval-logloss:0.278416\n",
      "[1215]\ttrain-logloss:0.190709\teval-logloss:0.278393\n",
      "[1230]\ttrain-logloss:0.190123\teval-logloss:0.278341\n",
      "[1245]\ttrain-logloss:0.189608\teval-logloss:0.278262\n",
      "[1260]\ttrain-logloss:0.188928\teval-logloss:0.278199\n",
      "[1275]\ttrain-logloss:0.188382\teval-logloss:0.278112\n",
      "[1290]\ttrain-logloss:0.18732\teval-logloss:0.277807\n",
      "[1305]\ttrain-logloss:0.186707\teval-logloss:0.277719\n",
      "[1320]\ttrain-logloss:0.186016\teval-logloss:0.277606\n",
      "[1335]\ttrain-logloss:0.184914\teval-logloss:0.277306\n",
      "[1350]\ttrain-logloss:0.184336\teval-logloss:0.277246\n",
      "[1365]\ttrain-logloss:0.183473\teval-logloss:0.277049\n",
      "[1380]\ttrain-logloss:0.18278\teval-logloss:0.276952\n",
      "[1395]\ttrain-logloss:0.182228\teval-logloss:0.276912\n",
      "[1410]\ttrain-logloss:0.181262\teval-logloss:0.27669\n",
      "[1425]\ttrain-logloss:0.180671\teval-logloss:0.276621\n",
      "[1440]\ttrain-logloss:0.18014\teval-logloss:0.276582\n",
      "[1455]\ttrain-logloss:0.179482\teval-logloss:0.276493\n",
      "[1470]\ttrain-logloss:0.178509\teval-logloss:0.276399\n",
      "[1485]\ttrain-logloss:0.177644\teval-logloss:0.276267\n",
      "[1500]\ttrain-logloss:0.176872\teval-logloss:0.276197\n",
      "[1515]\ttrain-logloss:0.176312\teval-logloss:0.276118\n",
      "[1530]\ttrain-logloss:0.175827\teval-logloss:0.276064\n",
      "[1545]\ttrain-logloss:0.175216\teval-logloss:0.27598\n",
      "[1560]\ttrain-logloss:0.174553\teval-logloss:0.275889\n",
      "[1575]\ttrain-logloss:0.174022\teval-logloss:0.275822\n",
      "[1590]\ttrain-logloss:0.17363\teval-logloss:0.275787\n",
      "[1605]\ttrain-logloss:0.172864\teval-logloss:0.275731\n",
      "[1620]\ttrain-logloss:0.172181\teval-logloss:0.27569\n",
      "[1635]\ttrain-logloss:0.171717\teval-logloss:0.275689\n",
      "[1650]\ttrain-logloss:0.171186\teval-logloss:0.275624\n",
      "[1665]\ttrain-logloss:0.1707\teval-logloss:0.275615\n",
      "[1680]\ttrain-logloss:0.170241\teval-logloss:0.275539\n",
      "[1695]\ttrain-logloss:0.169484\teval-logloss:0.275463\n",
      "[1710]\ttrain-logloss:0.168798\teval-logloss:0.275323\n",
      "[1725]\ttrain-logloss:0.168116\teval-logloss:0.275249\n",
      "[1740]\ttrain-logloss:0.167738\teval-logloss:0.275192\n",
      "[1755]\ttrain-logloss:0.167138\teval-logloss:0.27512\n",
      "[1770]\ttrain-logloss:0.166337\teval-logloss:0.275002\n",
      "[1785]\ttrain-logloss:0.165684\teval-logloss:0.274848\n",
      "[1800]\ttrain-logloss:0.165273\teval-logloss:0.274842\n",
      "[1815]\ttrain-logloss:0.164651\teval-logloss:0.274773\n",
      "[1830]\ttrain-logloss:0.163917\teval-logloss:0.27466\n",
      "[1845]\ttrain-logloss:0.163383\teval-logloss:0.274631\n",
      "[1860]\ttrain-logloss:0.162689\teval-logloss:0.274541\n",
      "[1875]\ttrain-logloss:0.162353\teval-logloss:0.274538\n",
      "[1890]\ttrain-logloss:0.161855\teval-logloss:0.274494\n",
      "[1905]\ttrain-logloss:0.161129\teval-logloss:0.274358\n",
      "[1920]\ttrain-logloss:0.1604\teval-logloss:0.274275\n",
      "[1935]\ttrain-logloss:0.159449\teval-logloss:0.274167\n",
      "[1950]\ttrain-logloss:0.158964\teval-logloss:0.27417\n",
      "[1965]\ttrain-logloss:0.158355\teval-logloss:0.274102\n",
      "[1980]\ttrain-logloss:0.158002\teval-logloss:0.274098\n",
      "[1995]\ttrain-logloss:0.157544\teval-logloss:0.274059\n",
      "XGB: 0.274 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 2000\n",
    "\n",
    "#LGBM\n",
    "params = {\n",
    "    #'task': 'train',\n",
    "    #'boosting_type': 'gbdt',\n",
    "    #'objective': 'regression',\n",
    "    #'metric': {'l2', 'auc'},\n",
    "    #'num_leaves': 31,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    #'subsample': 0.8,\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'objective': 'binary',\n",
    "    'nthread': -1,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 5,\n",
    "    #'max_depth': 6\n",
    "    #'num_class': 3\n",
    "    \n",
    "}\n",
    "\n",
    "pred_train = np.zeros(len(y_train))\n",
    "xgbs = []\n",
    "sc,sc_mean = [],[]\n",
    "\n",
    "for itr, ite in folds:\n",
    "    ypred = []\n",
    "    for i in range(1):\n",
    "               \n",
    "        param['seed'] = i+1\n",
    "        \n",
    "        #xgboost\n",
    "        \n",
    "        Xdatatrain = xgb.DMatrix(data=X_train.ix[itr, :].values,\n",
    "                                     label=y_train.ix[itr].values)\n",
    "        Xdataval = xgb.DMatrix(data=X_train.ix[ite, :].values,\n",
    "                                     label=y_train.ix[ite].values)\n",
    "\n",
    "        plst = list(param.items())\n",
    "        watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]\n",
    "        bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n",
    "\n",
    "        \n",
    "        #rc = ensemble.ExtraTreesClassifier(n_estimators=1300, criterion='gini', max_depth=None, n_jobs=-1)\n",
    "        #pred_train[ite] = bst.predict(Xdataval)\n",
    "        #neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "        #neigh.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = bst.predict(Xdataval)\n",
    "        #ypred = neigh.predict_proba(X_train.ix[ite, :])\n",
    "        xgbs.append(bst)\n",
    "        '''\n",
    "        \n",
    "        # train\n",
    "        lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "        lgb.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = lgb.predict_proba(X_train.ix[ite, :])[:, 1]\n",
    "\n",
    "        \n",
    "        model.fit(X_train.ix[itr, :].values, y_train_cat[itr],\n",
    "            epochs=60,\n",
    "            batch_size=1000)\n",
    "        ypred = model.predict(X_train.ix[ite, :].values)\n",
    "        '''\n",
    "    #ypred = sum(ypred) / len(ypred) 0.401408 0.392476\n",
    "    pred_train[ite] = ypred\n",
    "    \n",
    "    \n",
    "    sc.append(log_loss(y_train.ix[ite, :], pred_train[ite]))\n",
    "\n",
    "    \n",
    "print('XGB: {:.3f} +- {:.3f}'.format(np.mean(sc), np.std(sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    a = 0.165 / 0.37\n",
    "    b = (1 - 0.165) / (1 - 0.37) \n",
    "    return  a * x / (a * x + b * (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = foo(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(pred_train)\n",
    "pred_train.columns = ['y']\n",
    "pred_train.to_csv(\"stacking/xgb_15.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=5,\n",
       "        min_split_gain=0, n_estimators=300, nthread=-1, num_leaves=31,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
       "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5, subsample=1,\n",
       "        subsample_for_bin=50000, subsample_freq=1, uniform_drop=False,\n",
       "        xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "lgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.ix[1000001:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred2 = lgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00778551,  0.58706412,  0.45319938,  0.00166404])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.85291907e-04,   2.61291438e-01,   6.26312391e-01,\n",
       "         1.66797416e-03])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.51530930e-01,   3.07114939e-04,   1.03535362e-03,\n",
       "         9.95933188e-02])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.67587699e-03,   2.31711933e-04,   3.72899384e-01,\n",
       "         3.89707027e-01])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred2[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345795"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.concatenate([test_pred1, test_pred2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.78551300e-03,   5.87064116e-01,   4.53199376e-01, ...,\n",
       "         2.31711933e-04,   3.72899384e-01,   3.89707027e-01])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-20e877713fff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_train' is not defined"
     ]
    }
   ],
   "source": [
    "del pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatrain = xgb.DMatrix(data=X_train.ix[:, :].values,\n",
    "                                     label=y_train.ix[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdataval = xgb.DMatrix(data=X_train.ix[:10, :].values,\n",
    "                                     label=y_train.ix[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatest2 = xgb.DMatrix(data=X_test.ix[1000001:, :].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.643077\teval-logloss:0.634047\n",
      "[15]\ttrain-logloss:0.37953\teval-logloss:0.419373\n",
      "[30]\ttrain-logloss:0.3323\teval-logloss:0.390615\n",
      "[45]\ttrain-logloss:0.317464\teval-logloss:0.393716\n",
      "[60]\ttrain-logloss:0.308375\teval-logloss:0.389183\n",
      "[75]\ttrain-logloss:0.300855\teval-logloss:0.401466\n",
      "[90]\ttrain-logloss:0.295579\teval-logloss:0.383456\n",
      "[105]\ttrain-logloss:0.291515\teval-logloss:0.386859\n",
      "[120]\ttrain-logloss:0.287283\teval-logloss:0.385894\n",
      "[135]\ttrain-logloss:0.283842\teval-logloss:0.378404\n",
      "[150]\ttrain-logloss:0.280634\teval-logloss:0.377714\n",
      "[165]\ttrain-logloss:0.278092\teval-logloss:0.373746\n",
      "[180]\ttrain-logloss:0.275286\teval-logloss:0.37967\n",
      "[195]\ttrain-logloss:0.27285\teval-logloss:0.373462\n",
      "[210]\ttrain-logloss:0.269792\teval-logloss:0.372048\n",
      "[225]\ttrain-logloss:0.267772\teval-logloss:0.378358\n",
      "[240]\ttrain-logloss:0.265629\teval-logloss:0.377458\n",
      "[255]\ttrain-logloss:0.263883\teval-logloss:0.373124\n",
      "[270]\ttrain-logloss:0.261896\teval-logloss:0.365807\n",
      "[285]\ttrain-logloss:0.260195\teval-logloss:0.366634\n",
      "[300]\ttrain-logloss:0.258799\teval-logloss:0.365421\n",
      "[315]\ttrain-logloss:0.257172\teval-logloss:0.365364\n",
      "[330]\ttrain-logloss:0.255705\teval-logloss:0.365352\n",
      "[345]\ttrain-logloss:0.254138\teval-logloss:0.362832\n",
      "[360]\ttrain-logloss:0.25248\teval-logloss:0.360137\n",
      "[375]\ttrain-logloss:0.250828\teval-logloss:0.358757\n",
      "[390]\ttrain-logloss:0.249567\teval-logloss:0.352565\n",
      "[405]\ttrain-logloss:0.248205\teval-logloss:0.351027\n",
      "[420]\ttrain-logloss:0.246917\teval-logloss:0.350229\n",
      "[435]\ttrain-logloss:0.245038\teval-logloss:0.348259\n",
      "[450]\ttrain-logloss:0.243875\teval-logloss:0.347731\n",
      "[465]\ttrain-logloss:0.242842\teval-logloss:0.348295\n",
      "[480]\ttrain-logloss:0.240862\teval-logloss:0.347121\n",
      "[495]\ttrain-logloss:0.239747\teval-logloss:0.338738\n",
      "[510]\ttrain-logloss:0.238861\teval-logloss:0.332499\n",
      "[525]\ttrain-logloss:0.237963\teval-logloss:0.331857\n",
      "[540]\ttrain-logloss:0.236656\teval-logloss:0.331686\n",
      "[555]\ttrain-logloss:0.235613\teval-logloss:0.332135\n",
      "[570]\ttrain-logloss:0.234651\teval-logloss:0.327677\n",
      "[585]\ttrain-logloss:0.233812\teval-logloss:0.328417\n",
      "[600]\ttrain-logloss:0.233042\teval-logloss:0.323132\n",
      "[615]\ttrain-logloss:0.232273\teval-logloss:0.320469\n",
      "[630]\ttrain-logloss:0.231336\teval-logloss:0.319088\n",
      "[645]\ttrain-logloss:0.22957\teval-logloss:0.314842\n",
      "[660]\ttrain-logloss:0.228837\teval-logloss:0.315233\n",
      "[675]\ttrain-logloss:0.227838\teval-logloss:0.313321\n",
      "[690]\ttrain-logloss:0.227092\teval-logloss:0.312093\n",
      "[705]\ttrain-logloss:0.226209\teval-logloss:0.308809\n",
      "[720]\ttrain-logloss:0.225435\teval-logloss:0.310526\n",
      "[735]\ttrain-logloss:0.224577\teval-logloss:0.309132\n",
      "[750]\ttrain-logloss:0.223977\teval-logloss:0.308669\n",
      "[765]\ttrain-logloss:0.223183\teval-logloss:0.303193\n",
      "[780]\ttrain-logloss:0.222304\teval-logloss:0.303211\n",
      "[795]\ttrain-logloss:0.220804\teval-logloss:0.300789\n",
      "[810]\ttrain-logloss:0.219699\teval-logloss:0.300701\n",
      "[825]\ttrain-logloss:0.218979\teval-logloss:0.30127\n",
      "[840]\ttrain-logloss:0.217835\teval-logloss:0.302409\n",
      "[855]\ttrain-logloss:0.217215\teval-logloss:0.301069\n",
      "[870]\ttrain-logloss:0.216309\teval-logloss:0.299727\n",
      "[885]\ttrain-logloss:0.215507\teval-logloss:0.2995\n",
      "[900]\ttrain-logloss:0.214951\teval-logloss:0.299696\n",
      "[915]\ttrain-logloss:0.214464\teval-logloss:0.295021\n",
      "[930]\ttrain-logloss:0.213862\teval-logloss:0.295421\n",
      "[945]\ttrain-logloss:0.213005\teval-logloss:0.291281\n",
      "[960]\ttrain-logloss:0.212468\teval-logloss:0.291182\n",
      "[975]\ttrain-logloss:0.211701\teval-logloss:0.285552\n",
      "[990]\ttrain-logloss:0.211139\teval-logloss:0.288242\n",
      "[1005]\ttrain-logloss:0.210498\teval-logloss:0.28216\n",
      "[1020]\ttrain-logloss:0.209747\teval-logloss:0.283624\n",
      "[1035]\ttrain-logloss:0.208942\teval-logloss:0.283978\n",
      "[1050]\ttrain-logloss:0.208275\teval-logloss:0.280152\n",
      "[1065]\ttrain-logloss:0.207596\teval-logloss:0.28013\n",
      "[1080]\ttrain-logloss:0.206708\teval-logloss:0.279169\n",
      "[1095]\ttrain-logloss:0.206109\teval-logloss:0.279669\n",
      "[1110]\ttrain-logloss:0.205687\teval-logloss:0.281187\n",
      "[1125]\ttrain-logloss:0.204803\teval-logloss:0.276322\n",
      "[1140]\ttrain-logloss:0.204125\teval-logloss:0.27638\n",
      "[1155]\ttrain-logloss:0.20314\teval-logloss:0.276449\n",
      "[1170]\ttrain-logloss:0.20246\teval-logloss:0.275971\n",
      "[1185]\ttrain-logloss:0.201526\teval-logloss:0.276363\n",
      "[1200]\ttrain-logloss:0.201007\teval-logloss:0.268038\n",
      "[1215]\ttrain-logloss:0.200197\teval-logloss:0.268019\n",
      "[1230]\ttrain-logloss:0.199362\teval-logloss:0.266254\n",
      "[1245]\ttrain-logloss:0.198795\teval-logloss:0.266204\n",
      "[1260]\ttrain-logloss:0.198331\teval-logloss:0.266218\n",
      "[1275]\ttrain-logloss:0.197799\teval-logloss:0.267106\n",
      "[1290]\ttrain-logloss:0.197156\teval-logloss:0.260693\n",
      "[1305]\ttrain-logloss:0.196372\teval-logloss:0.260756\n",
      "[1320]\ttrain-logloss:0.195706\teval-logloss:0.260876\n",
      "[1335]\ttrain-logloss:0.194955\teval-logloss:0.260478\n",
      "[1350]\ttrain-logloss:0.194517\teval-logloss:0.251144\n",
      "[1365]\ttrain-logloss:0.193766\teval-logloss:0.251409\n",
      "[1380]\ttrain-logloss:0.193122\teval-logloss:0.250239\n",
      "[1395]\ttrain-logloss:0.192377\teval-logloss:0.250372\n",
      "[1410]\ttrain-logloss:0.191874\teval-logloss:0.250348\n",
      "[1425]\ttrain-logloss:0.190903\teval-logloss:0.249078\n",
      "[1440]\ttrain-logloss:0.190275\teval-logloss:0.246422\n",
      "[1455]\ttrain-logloss:0.189617\teval-logloss:0.236908\n",
      "[1470]\ttrain-logloss:0.188937\teval-logloss:0.234221\n",
      "[1485]\ttrain-logloss:0.188531\teval-logloss:0.229355\n",
      "[1500]\ttrain-logloss:0.188145\teval-logloss:0.226303\n",
      "[1515]\ttrain-logloss:0.187424\teval-logloss:0.226211\n",
      "[1530]\ttrain-logloss:0.187034\teval-logloss:0.224351\n",
      "[1545]\ttrain-logloss:0.186588\teval-logloss:0.223132\n",
      "[1560]\ttrain-logloss:0.186032\teval-logloss:0.223906\n",
      "[1575]\ttrain-logloss:0.185301\teval-logloss:0.223283\n",
      "[1590]\ttrain-logloss:0.184793\teval-logloss:0.225324\n",
      "[1605]\ttrain-logloss:0.184078\teval-logloss:0.227347\n",
      "[1620]\ttrain-logloss:0.18357\teval-logloss:0.226247\n",
      "[1635]\ttrain-logloss:0.183181\teval-logloss:0.226503\n",
      "[1650]\ttrain-logloss:0.182395\teval-logloss:0.225204\n",
      "[1665]\ttrain-logloss:0.18187\teval-logloss:0.225353\n",
      "[1680]\ttrain-logloss:0.181336\teval-logloss:0.225042\n",
      "[1695]\ttrain-logloss:0.180639\teval-logloss:0.224251\n",
      "[1710]\ttrain-logloss:0.180166\teval-logloss:0.224698\n",
      "[1725]\ttrain-logloss:0.179802\teval-logloss:0.224691\n",
      "[1740]\ttrain-logloss:0.179237\teval-logloss:0.224697\n",
      "[1755]\ttrain-logloss:0.178809\teval-logloss:0.223145\n",
      "[1770]\ttrain-logloss:0.178194\teval-logloss:0.224709\n",
      "[1785]\ttrain-logloss:0.177833\teval-logloss:0.224839\n",
      "[1800]\ttrain-logloss:0.177404\teval-logloss:0.224987\n",
      "[1815]\ttrain-logloss:0.176948\teval-logloss:0.225003\n",
      "[1830]\ttrain-logloss:0.176285\teval-logloss:0.225714\n",
      "[1845]\ttrain-logloss:0.17574\teval-logloss:0.225692\n",
      "[1860]\ttrain-logloss:0.175116\teval-logloss:0.229365\n",
      "[1875]\ttrain-logloss:0.174555\teval-logloss:0.228762\n",
      "[1890]\ttrain-logloss:0.173965\teval-logloss:0.229005\n",
      "[1905]\ttrain-logloss:0.173596\teval-logloss:0.229987\n",
      "[1920]\ttrain-logloss:0.173024\teval-logloss:0.233853\n",
      "[1935]\ttrain-logloss:0.172642\teval-logloss:0.23327\n",
      "[1950]\ttrain-logloss:0.172042\teval-logloss:0.23288\n",
      "[1965]\ttrain-logloss:0.171314\teval-logloss:0.233106\n",
      "[1980]\ttrain-logloss:0.170941\teval-logloss:0.232141\n",
      "[1995]\ttrain-logloss:0.170629\teval-logloss:0.231335\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred2 = bst.predict(Xdatatest2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.29527755e-03,   5.45756638e-01,   6.37812853e-01,\n",
       "         4.23383579e-04], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000001"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.29527755e-03,   5.45756638e-01,   6.37812853e-01,\n",
       "         4.23383579e-04], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred1[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = np.concatenate([test_pred1, test_pred2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = foo(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit['is_duplicate'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv(\"stacking/xgb_15_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.323567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.218058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.095342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.007831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.956379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.098221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.363882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.423677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.034839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.033894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.392933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.150615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.284470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.018111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.004705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.004349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.061033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.009628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.099425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345766</th>\n",
       "      <td>2345766</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345767</th>\n",
       "      <td>2345767</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345768</th>\n",
       "      <td>2345768</td>\n",
       "      <td>0.023880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345769</th>\n",
       "      <td>2345769</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345770</th>\n",
       "      <td>2345770</td>\n",
       "      <td>0.063847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345771</th>\n",
       "      <td>2345771</td>\n",
       "      <td>0.446460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345772</th>\n",
       "      <td>2345772</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345773</th>\n",
       "      <td>2345773</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345774</th>\n",
       "      <td>2345774</td>\n",
       "      <td>0.001341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345775</th>\n",
       "      <td>2345775</td>\n",
       "      <td>0.276473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345776</th>\n",
       "      <td>2345776</td>\n",
       "      <td>0.032203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345777</th>\n",
       "      <td>2345777</td>\n",
       "      <td>0.009648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345778</th>\n",
       "      <td>2345778</td>\n",
       "      <td>0.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345779</th>\n",
       "      <td>2345779</td>\n",
       "      <td>0.009260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345780</th>\n",
       "      <td>2345780</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345781</th>\n",
       "      <td>2345781</td>\n",
       "      <td>0.058332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345782</th>\n",
       "      <td>2345782</td>\n",
       "      <td>0.088220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345783</th>\n",
       "      <td>2345783</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345784</th>\n",
       "      <td>2345784</td>\n",
       "      <td>0.418718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345785</th>\n",
       "      <td>2345785</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345786</th>\n",
       "      <td>2345786</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345787</th>\n",
       "      <td>2345787</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345788</th>\n",
       "      <td>2345788</td>\n",
       "      <td>0.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345789</th>\n",
       "      <td>2345789</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345790</th>\n",
       "      <td>2345790</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>0.166718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>0.176853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "0              0      0.002633\n",
       "1              1      0.323567\n",
       "2              2      0.218058\n",
       "3              3      0.000561\n",
       "4              4      0.095342\n",
       "5              5      0.007831\n",
       "6              6      0.956379\n",
       "7              7      0.098221\n",
       "8              8      0.363882\n",
       "9              9      0.002275\n",
       "10            10      0.423677\n",
       "11            11      0.000240\n",
       "12            12      0.000097\n",
       "13            13      0.034839\n",
       "14            14      0.033894\n",
       "15            15      0.020784\n",
       "16            16      0.000108\n",
       "17            17      0.392933\n",
       "18            18      0.150615\n",
       "19            19      0.284470\n",
       "20            20      0.000149\n",
       "21            21      0.018111\n",
       "22            22      0.004705\n",
       "23            23      0.004349\n",
       "24            24      0.000205\n",
       "25            25      0.061033\n",
       "26            26      0.000158\n",
       "27            27      0.009628\n",
       "28            28      0.099425\n",
       "29            29      0.000419\n",
       "...          ...           ...\n",
       "2345766  2345766      0.000039\n",
       "2345767  2345767      0.000291\n",
       "2345768  2345768      0.023880\n",
       "2345769  2345769      0.000088\n",
       "2345770  2345770      0.063847\n",
       "2345771  2345771      0.446460\n",
       "2345772  2345772      0.089966\n",
       "2345773  2345773      0.000060\n",
       "2345774  2345774      0.001341\n",
       "2345775  2345775      0.276473\n",
       "2345776  2345776      0.032203\n",
       "2345777  2345777      0.009648\n",
       "2345778  2345778      0.000300\n",
       "2345779  2345779      0.009260\n",
       "2345780  2345780      0.000238\n",
       "2345781  2345781      0.058332\n",
       "2345782  2345782      0.088220\n",
       "2345783  2345783      0.000379\n",
       "2345784  2345784      0.418718\n",
       "2345785  2345785      0.000115\n",
       "2345786  2345786      0.000045\n",
       "2345787  2345787      0.000076\n",
       "2345788  2345788      0.011994\n",
       "2345789  2345789      0.000081\n",
       "2345790  2345790      0.000093\n",
       "2345791  2345791      0.000088\n",
       "2345792  2345792      0.000564\n",
       "2345793  2345793      0.000078\n",
       "2345794  2345794      0.166718\n",
       "2345795  2345795      0.176853\n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
