{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "import sklearn\n",
    "from sklearn import pipeline, preprocessing, feature_extraction\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgbm\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/train.csv\")\n",
    "X_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "y_train = pd.DataFrame(X_train['is_duplicate'])\n",
    "y_train.columns = ['y']\n",
    "del X_train['is_duplicate']\n",
    "\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=0)\n",
    "folds = []\n",
    "for itr, ite in skf.split(X_train, y_train.y):\n",
    "    folds += [[itr, ite]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(\"data/train_inter.csv\")\n",
    "X_test = pd.read_csv(\"data/test_inter.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#q_train = pd.read_csv(\"data/freq_train.csv\")\n",
    "q_test = pd.read_csv(\"data/freq_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train = pd.concat([X_train, q_train], axis=1)\n",
    "X_test = pd.concat([X_test, q_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train['question1'] = X_train['question1'].apply(lambda x: str(x))\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "\n",
    "X_train['question1'] = X_train['question1'].apply(lambda x: x.lower().split())\n",
    "X_train['question2'] = X_train['question2'].apply(lambda x: x.lower().split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['question1'] = X_test['question1'].apply(lambda x: str(x))\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: str(x))\n",
    "\n",
    "X_test['question1'] = X_test['question1'].apply(lambda x: x.lower().split())\n",
    "X_test['question2'] = X_test['question2'].apply(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../tmp/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_vec(x):\n",
    "    result = word2vec.word_vec('yes') - word2vec.word_vec('yes')\n",
    "    co = 0\n",
    "    for i in x:\n",
    "        if i in word2vec.vocab:\n",
    "            result += word2vec.word_vec(i)\n",
    "            co += 1\n",
    "    return result / co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm3(x, y):\n",
    "    arr = []\n",
    "    for i in x.index:\n",
    "        arr += [abs(x.ix[i] - y.ix[i])]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def norm2(x, y):\n",
    "    arr = []\n",
    "    for i in x.index:\n",
    "        if i % 50000 == 0:\n",
    "            print(i)\n",
    "        arr += [scipy.spatial.distance.cosine(x.ix[i], y.ix[i])]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "def norm1(x, y):\n",
    "    arr = []\n",
    "    for i in x.index:\n",
    "        if i % 50000 == 0:\n",
    "            print(i)\n",
    "        arr += [LA.norm(x.ix[i] - y.ix[i])]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1 = X_train['question1'].apply(lambda x: to_vec(x))\n",
    "tmp2 = X_train['question2'].apply(lambda x: to_vec(x))\n",
    "tmp1 = pd.DataFrame(list(tmp1))\n",
    "tmp2 = pd.DataFrame(list(tmp2))\n",
    "#X_train = pd.concat([X_train, pd.DataFrame(X_train['question1'].apply(lambda x: to_vec(x))),\n",
    "#                  pd.DataFrame(X_train['question2'].apply(lambda x: to_vec(x)))], axis=1)\n",
    "from numpy import linalg as LA\n",
    "#del tmp1\n",
    "#del tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, tmp1],axis=1)\n",
    "X_train = pd.concat([X_train, tmp2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1.fillna(tmp1.mean(), inplace=True)\n",
    "tmp2.fillna(tmp2.mean(), inplace=True)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n",
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "n1 = norm1(tmp1, tmp2)\n",
    "n2 = norm2(tmp1, tmp2)\n",
    "#n3 = norm3(tmp1, tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = pd.DataFrame(n1)\n",
    "n1.columns = ['n1']\n",
    "n2 = pd.DataFrame(n2)\n",
    "n2.columns = ['n2']\n",
    "#n3 = pd.DataFrame(n3)\n",
    "#n3.columns = ['n3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, n1],axis=1)\n",
    "X_train = pd.concat([X_train, n2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train['question1']\n",
    "del X_train['question2']\n",
    "del X_train['qid1']\n",
    "del X_train['qid2']\n",
    "del X_train['id']\n",
    "\n",
    "#del X_test['question1']\n",
    "#del X_test['question2']\n",
    "#del X_test['test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train['n1']\n",
    "del X_train['n2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, n1],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, n2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>-0.027870</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.049194</td>\n",
       "      <td>-0.016388</td>\n",
       "      <td>-0.050432</td>\n",
       "      <td>-0.004822</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080499</td>\n",
       "      <td>-0.015268</td>\n",
       "      <td>-0.058472</td>\n",
       "      <td>-0.016852</td>\n",
       "      <td>0.026965</td>\n",
       "      <td>0.056458</td>\n",
       "      <td>0.058258</td>\n",
       "      <td>-0.04502</td>\n",
       "      <td>0.238747</td>\n",
       "      <td>0.024187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>1.454500e-06</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>0.100639</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.066895</td>\n",
       "      <td>0.045807</td>\n",
       "      <td>-0.060059</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050604</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.007458</td>\n",
       "      <td>-0.011377</td>\n",
       "      <td>-0.032227</td>\n",
       "      <td>0.067801</td>\n",
       "      <td>-0.09425</td>\n",
       "      <td>1.115507</td>\n",
       "      <td>0.455235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match            q1            q2         0  \\\n",
       "0    0.727273          0.772164  1.818125e-07  3.636250e-07 -0.027870   \n",
       "1    0.307692          0.361758  1.454500e-06  5.454375e-07  0.100639   \n",
       "\n",
       "          1         2         3         4         5    ...          292  \\\n",
       "0  0.026484  0.049194 -0.016388 -0.050432 -0.004822    ...    -0.080499   \n",
       "1  0.012527  0.066895  0.045807 -0.060059  0.051575    ...    -0.050604   \n",
       "\n",
       "        293       294       295       296       297       298      299  \\\n",
       "0 -0.015268 -0.058472 -0.016852  0.026965  0.056458  0.058258 -0.04502   \n",
       "1  0.013800  0.014710  0.007458 -0.011377 -0.032227  0.067801 -0.09425   \n",
       "\n",
       "         n1        n2  \n",
       "0  0.238747  0.024187  \n",
       "1  1.115507  0.455235  \n",
       "\n",
       "[2 rows x 606 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['n1'] - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/word2_vec_train.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"data/word2_vec_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[how, does, the, surface, pro, himself, 4, com...</td>\n",
       "      <td>[why, did, microsoft, choose, core, m3, and, n...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[should, i, have, a, hair, transplant, at, age...</td>\n",
       "      <td>[how, much, cost, does, hair, transplant, requ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  [how, does, the, surface, pro, himself, 4, com...   \n",
       "1        1  [should, i, have, a, hair, transplant, at, age...   \n",
       "\n",
       "                                           question2  word_match  \\\n",
       "0  [why, did, microsoft, choose, core, m3, and, n...    0.266667   \n",
       "1  [how, much, cost, does, hair, transplant, requ...    0.500000   \n",
       "\n",
       "   tfidf_word_match            q1            q2  \n",
       "0          0.274019  1.818125e-07  1.818125e-07  \n",
       "1          0.480962  3.636250e-07  3.636250e-07  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del n2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp1 = X_test['question1'].apply(lambda x: to_vec(x))\n",
    "tmp1 = pd.DataFrame(list(tmp1))\n",
    "\n",
    "#X_train = pd.concat([X_train, pd.DataFrame(X_train['question1'].apply(lambda x: to_vec(x))),\n",
    "#                  pd.DataFrame(X_train['question2'].apply(lambda x: to_vec(x)))], axis=1)\n",
    "#from numpy import linalg as LA\n",
    "#del tmp1\n",
    "#del tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, tmp1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-d2b8d682a43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtmp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tmp1' is not defined"
     ]
    }
   ],
   "source": [
    "del tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp2 = X_test['question2'].apply(lambda x: to_vec(x))\n",
    "tmp2 = pd.DataFrame(list(tmp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, tmp2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp1.fillna(tmp1.mean(), inplace=True)\n",
    "tmp2.fillna(tmp2.mean(), inplace=True)\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = norm1(tmp1, tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n2 = norm2(tmp1, tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = pd.DataFrame(n1)\n",
    "n1.columns = ['n1']\n",
    "n2 = pd.DataFrame(n2)\n",
    "n2.columns = ['n2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n1.to_csv(\"data/n1.csv\", index=None)\n",
    "n2.to_csv(\"data/n2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n1 = pd.read_csv(\"data/n1.csv\")\n",
    "n2 = pd.read_csv(\"data/n2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test['question1']\n",
    "del X_test['question2']\n",
    "del X_test['test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.concat([X_test, n1],axis=1)\n",
    "X_test = pd.concat([X_test, n2],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['n1'] = n1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['n2'] = n2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>0.069040</td>\n",
       "      <td>0.052856</td>\n",
       "      <td>0.065356</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>-0.067700</td>\n",
       "      <td>0.034937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090914</td>\n",
       "      <td>0.028786</td>\n",
       "      <td>-0.034929</td>\n",
       "      <td>-0.051687</td>\n",
       "      <td>0.034475</td>\n",
       "      <td>-0.023356</td>\n",
       "      <td>0.061010</td>\n",
       "      <td>-0.048594</td>\n",
       "      <td>0.939924</td>\n",
       "      <td>0.350222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>-0.016091</td>\n",
       "      <td>0.089301</td>\n",
       "      <td>0.072576</td>\n",
       "      <td>0.121937</td>\n",
       "      <td>-0.076483</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151204</td>\n",
       "      <td>0.042806</td>\n",
       "      <td>0.024628</td>\n",
       "      <td>0.166341</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.009206</td>\n",
       "      <td>0.027445</td>\n",
       "      <td>-0.027832</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.162770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.468893</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>0.100991</td>\n",
       "      <td>0.120350</td>\n",
       "      <td>-0.052940</td>\n",
       "      <td>0.021027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088867</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>0.035522</td>\n",
       "      <td>-0.014801</td>\n",
       "      <td>0.108215</td>\n",
       "      <td>-0.110840</td>\n",
       "      <td>-0.020203</td>\n",
       "      <td>-0.074707</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>0.216529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 606 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match            q1            q2         0  \\\n",
       "0    0.266667          0.274019  1.818125e-07  1.818125e-07  0.069040   \n",
       "1    0.500000          0.480962  3.636250e-07  3.636250e-07 -0.016091   \n",
       "2    0.444444          0.468893  1.818125e-07  1.818125e-07  0.015533   \n",
       "\n",
       "          1         2         3         4         5    ...          292  \\\n",
       "0  0.052856  0.065356  0.028613 -0.067700  0.034937    ...    -0.090914   \n",
       "1  0.089301  0.072576  0.121937 -0.076483  0.025495    ...    -0.151204   \n",
       "2  0.035801  0.100991  0.120350 -0.052940  0.021027    ...    -0.088867   \n",
       "\n",
       "        293       294       295       296       297       298       299  \\\n",
       "0  0.028786 -0.034929 -0.051687  0.034475 -0.023356  0.061010 -0.048594   \n",
       "1  0.042806  0.024628  0.166341  0.136393  0.009206  0.027445 -0.027832   \n",
       "2 -0.055176  0.035522 -0.014801  0.108215 -0.110840 -0.020203 -0.074707   \n",
       "\n",
       "         n1        n2  \n",
       "0  0.939924  0.350222  \n",
       "1  0.794613  0.162770  \n",
       "2  0.964996  0.216529  \n",
       "\n",
       "[3 rows x 606 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X_test['n1']\n",
    "del X_test['n2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.668771881958455e-07\n",
      "9.009205147102744e-07\n"
     ]
    }
   ],
   "source": [
    "print(X_test.q1.mean())\n",
    "print(X_train.q1.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB: 0.316 +- 0.002\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 1100\n",
    "\n",
    "#LGBM\n",
    "params = {\n",
    "    #'task': 'train',\n",
    "    #'boosting_type': 'gbdt',\n",
    "    #'objective': 'regression',\n",
    "    #'metric': {'l2', 'auc'},\n",
    "    #'num_leaves': 31,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    #'subsample': 0.7,\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'objective': 'binary',\n",
    "    'nthread': -1,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 50,\n",
    "    #'max_depth': 6\n",
    "    #'num_class': 3\n",
    "    \n",
    "}\n",
    "\n",
    "pred_train = np.zeros(len(y_train))\n",
    "xgbs = []\n",
    "sc,sc_mean = [],[]\n",
    "\n",
    "for itr, ite in folds:\n",
    "    ypred = []\n",
    "    for i in range(1):\n",
    "               \n",
    "        param['seed'] = i+1\n",
    "        \n",
    "        #xgboost\n",
    "        '''\n",
    "        Xdatatrain = xgb.DMatrix(data=X_train.ix[itr, :].values,\n",
    "                                     label=y_train.ix[itr].values)\n",
    "        Xdataval = xgb.DMatrix(data=X_train.ix[ite, :].values,\n",
    "                                     label=y_train.ix[ite].values)\n",
    "\n",
    "        plst = list(param.items())\n",
    "        watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]\n",
    "        bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n",
    "        \n",
    "        \n",
    "        #rc = ensemble.ExtraTreesClassifier(n_estimators=1300, criterion='gini', max_depth=None, n_jobs=-1)\n",
    "        #pred_train[ite] = bst.predict(Xdataval)\n",
    "        #neigh = KNeighborsClassifier(n_neighbors=2)\n",
    "        #neigh.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = bst.predict(Xdataval)\n",
    "        #ypred = neigh.predict_proba(X_train.ix[ite, :])\n",
    "        xgbs.append(bst)\n",
    "        \n",
    "        '''\n",
    "        # train\n",
    "        lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "        lgb.fit(X_train.ix[itr, :], y_train.ix[itr])\n",
    "        ypred = lgb.predict_proba(X_train.ix[ite, :])[:, 1]\n",
    "\n",
    "        '''\n",
    "        model.fit(X_train.ix[itr, :].values, y_train_cat[itr],\n",
    "            epochs=60,\n",
    "            batch_size=1000)\n",
    "        ypred = model.predict(X_train.ix[ite, :].values)\n",
    "        '''\n",
    "    #ypred = sum(ypred) / len(ypred) 0.401408 0.392476\n",
    "    pred_train[ite] = ypred\n",
    "    \n",
    "    \n",
    "    sc.append(log_loss(y_train.ix[ite, :], pred_train[ite]))\n",
    "\n",
    "    \n",
    "print('XGB: {:.3f} +- {:.3f}'.format(np.mean(sc), np.std(sc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    a = 0.165 / 0.37\n",
    "    b = (1 - 0.165) / (1 - 0.37) \n",
    "    return  a * x / (a * x + b * (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = foo(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = pd.DataFrame(pred_train)\n",
    "pred_train.columns = ['y']\n",
    "pred_train.to_csv(\"stacking/lgb_11.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_word_match</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.772164</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>-0.027870</td>\n",
       "      <td>0.026484</td>\n",
       "      <td>0.049194</td>\n",
       "      <td>-0.016388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016907</td>\n",
       "      <td>0.010545</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.361758</td>\n",
       "      <td>1.454500e-06</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>1.454500e-06</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>0.100639</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.066895</td>\n",
       "      <td>0.045807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069434</td>\n",
       "      <td>0.075851</td>\n",
       "      <td>0.025278</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>0.081116</td>\n",
       "      <td>0.031461</td>\n",
       "      <td>0.081628</td>\n",
       "      <td>0.049377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.355191</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>0.085183</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.063221</td>\n",
       "      <td>0.074796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.044193</td>\n",
       "      <td>0.045397</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.061699</td>\n",
       "      <td>0.042852</td>\n",
       "      <td>0.050974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>-0.039524</td>\n",
       "      <td>0.013211</td>\n",
       "      <td>0.029839</td>\n",
       "      <td>0.106757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029460</td>\n",
       "      <td>0.107410</td>\n",
       "      <td>0.081034</td>\n",
       "      <td>0.028898</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.071940</td>\n",
       "      <td>0.036799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>-0.017532</td>\n",
       "      <td>0.095093</td>\n",
       "      <td>-0.013397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.079898</td>\n",
       "      <td>0.041982</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.126322</td>\n",
       "      <td>0.063192</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.510771</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>-0.033618</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.075024</td>\n",
       "      <td>0.056055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>0.119550</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.079837</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.030248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>-0.066569</td>\n",
       "      <td>-0.052165</td>\n",
       "      <td>0.080892</td>\n",
       "      <td>0.247070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.104233</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.121867</td>\n",
       "      <td>0.141271</td>\n",
       "      <td>0.042704</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>0.059708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.645836</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>-0.009277</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.077466</td>\n",
       "      <td>0.131738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.028385</td>\n",
       "      <td>0.039738</td>\n",
       "      <td>0.046163</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.396755</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>3.636250e-07</td>\n",
       "      <td>5.454375e-07</td>\n",
       "      <td>0.161621</td>\n",
       "      <td>-0.017310</td>\n",
       "      <td>0.104663</td>\n",
       "      <td>0.198584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.503203</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>1.818125e-07</td>\n",
       "      <td>0.025894</td>\n",
       "      <td>-0.015422</td>\n",
       "      <td>0.044515</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019911</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>0.007516</td>\n",
       "      <td>0.048482</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.022736</td>\n",
       "      <td>0.063766</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_word_match            q1            q2            q1  \\\n",
       "0    0.727273          0.772164  1.818125e-07  3.636250e-07  1.818125e-07   \n",
       "1    0.307692          0.361758  1.454500e-06  5.454375e-07  1.454500e-06   \n",
       "2    0.363636          0.355191  3.636250e-07  1.818125e-07  3.636250e-07   \n",
       "3    0.000000          0.000000  1.818125e-07  1.818125e-07  1.818125e-07   \n",
       "4    0.000000          0.000000  5.454375e-07  1.818125e-07  5.454375e-07   \n",
       "5    0.470588          0.510771  1.818125e-07  1.818125e-07  1.818125e-07   \n",
       "6    0.000000          0.000000  1.818125e-07  1.818125e-07  1.818125e-07   \n",
       "7    0.500000          0.645836  1.818125e-07  1.818125e-07  1.818125e-07   \n",
       "8    0.500000          0.396755  3.636250e-07  5.454375e-07  3.636250e-07   \n",
       "9    0.363636          0.503203  1.818125e-07  1.818125e-07  1.818125e-07   \n",
       "\n",
       "             q2         0         1         2         3 ...        290  \\\n",
       "0  3.636250e-07 -0.027870  0.026484  0.049194 -0.016388 ...   0.016907   \n",
       "1  5.454375e-07  0.100639  0.012527  0.066895  0.045807 ...   0.069434   \n",
       "2  1.818125e-07  0.085183  0.021555  0.063221  0.074796 ...   0.000543   \n",
       "3  1.818125e-07 -0.039524  0.013211  0.029839  0.106757 ...   0.029460   \n",
       "4  1.818125e-07 -0.012436 -0.017532  0.095093 -0.013397 ...   0.105225   \n",
       "5  1.818125e-07 -0.033618  0.046802  0.075024  0.056055 ...   0.025364   \n",
       "6  1.818125e-07 -0.066569 -0.052165  0.080892  0.247070 ...   0.106481   \n",
       "7  1.818125e-07 -0.009277  0.000977  0.077466  0.131738 ...   0.021360   \n",
       "8  5.454375e-07  0.161621 -0.017310  0.104663  0.198584 ...   0.000000   \n",
       "9  1.818125e-07  0.025894 -0.015422  0.044515  0.148438 ...   0.019911   \n",
       "\n",
       "        291       292       293       294       295       296       297  298  \\\n",
       "0  0.010545  0.001210  0.000673  0.019775  0.018149  0.013629  0.001577  NaN   \n",
       "1  0.075851  0.025278  0.016992  0.081116  0.031461  0.081628  0.049377  NaN   \n",
       "2  0.044193  0.045397  0.022413  0.024248  0.061699  0.042852  0.050974  NaN   \n",
       "3  0.107410  0.081034  0.028898  0.074945  0.010297  0.071940  0.036799  NaN   \n",
       "4  0.079898  0.041982  0.004852  0.126322  0.063192  0.013041  0.011490  NaN   \n",
       "5  0.119550  0.021383  0.047138  0.018265  0.079837  0.006089  0.030248  NaN   \n",
       "6  0.104233  0.004899  0.121867  0.141271  0.042704  0.092214  0.059708  NaN   \n",
       "7  0.014730  0.015104  0.045239  0.028385  0.039738  0.046163  0.012903  NaN   \n",
       "8  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  NaN   \n",
       "9  0.022830  0.007516  0.048482  0.014336  0.022736  0.063766  0.002675  NaN   \n",
       "\n",
       "   299  \n",
       "0  NaN  \n",
       "1  NaN  \n",
       "2  NaN  \n",
       "3  NaN  \n",
       "4  NaN  \n",
       "5  NaN  \n",
       "6  NaN  \n",
       "7  NaN  \n",
       "8  NaN  \n",
       "9  NaN  \n",
       "\n",
       "[10 rows x 910 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#LGBM\n",
    "params = {\n",
    "    #'task': 'train',\n",
    "    #'boosting_type': 'gbdt',\n",
    "    #'objective': 'regression',\n",
    "    #'metric': {'l2', 'auc'},\n",
    "    #'num_leaves': 31,\n",
    "    #'feature_fraction': 0.9,\n",
    "    #'bagging_fraction': 0.8,\n",
    "    #'bagging_freq': 5,\n",
    "    #'subsample': 0.7,\n",
    "    #'colsample_bytree': 0.7,\n",
    "    'objective': 'binary',\n",
    "    'nthread': -1,\n",
    "    'learning_rate': 0.1,\n",
    "    'min_child_weight': 50,\n",
    "    #'max_depth': 6\n",
    "    #'num_class': 3\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/fao3864/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1, drop_rate=0.1,\n",
       "        is_unbalance=False, learning_rate=0.1, max_bin=255, max_depth=-1,\n",
       "        max_drop=50, min_child_samples=10, min_child_weight=50,\n",
       "        min_split_gain=0, n_estimators=300, nthread=-1, num_leaves=31,\n",
       "        objective='binary', reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
       "        seed=0, sigmoid=1.0, silent=True, skip_drop=0.5, subsample=1,\n",
       "        subsample_for_bin=50000, subsample_freq=1, uniform_drop=False,\n",
       "        xgboost_dart_mode=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = lgbm.sklearn.LGBMClassifier(n_estimators=300, seed=0, **params)\n",
    "lgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = lgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['max_depth'] = 7\n",
    "# param['booster'] = 'dart'\n",
    "#param['booster'] = 'gblinear'\n",
    "param['eta'] = 0.1\n",
    "#param['subsample'] = 1.0\n",
    "# param[\"scale_pos_weight\"] = 0.5\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['nthread'] = 8\n",
    "#param['num_class'] =3\n",
    "#param['alpha'] = 0.00\n",
    "#param['lambda_bias'] = 0.1\n",
    "# param['lambda'] = 0\n",
    "#param['min_child_weight'] = 100\n",
    "\n",
    "# if param['booster'] == 'gblinear': param['eta'] *= 1e-4\n",
    "numround = 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatrain = xgb.DMatrix(data=X_train.ix[:, :].values,\n",
    "                                     label=y_train.ix[:].values)\n",
    "Xdataval = xgb.DMatrix(data=X_train.values,\n",
    "                                     label=y_train.values)\n",
    "Xdatatest = xgb.DMatrix(data=X_test.values)\n",
    "\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]\n",
    "#bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n",
    "\n",
    "\n",
    "#test_pred = bst.predict(Xdatatest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatrain = xgb.DMatrix(data=X_train.ix[:, :].values,\n",
    "                                     label=y_train.ix[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdataval = xgb.DMatrix(data=X_train.ix[:10, :].values,\n",
    "                                     label=y_train.ix[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatest = xgb.DMatrix(data=X_test.ix[:, :].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdataval, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.645145\teval-logloss:0.653016\n",
      "[15]\ttrain-logloss:0.394068\teval-logloss:0.437614\n",
      "[30]\ttrain-logloss:0.350926\teval-logloss:0.400341\n",
      "[45]\ttrain-logloss:0.337777\teval-logloss:0.401014\n",
      "[60]\ttrain-logloss:0.330209\teval-logloss:0.387795\n",
      "[75]\ttrain-logloss:0.324804\teval-logloss:0.387937\n",
      "[90]\ttrain-logloss:0.320158\teval-logloss:0.383231\n",
      "[105]\ttrain-logloss:0.316191\teval-logloss:0.384437\n",
      "[120]\ttrain-logloss:0.313145\teval-logloss:0.380075\n",
      "[135]\ttrain-logloss:0.309691\teval-logloss:0.37662\n",
      "[150]\ttrain-logloss:0.306753\teval-logloss:0.375377\n",
      "[165]\ttrain-logloss:0.304356\teval-logloss:0.370649\n",
      "[180]\ttrain-logloss:0.301772\teval-logloss:0.358448\n",
      "[195]\ttrain-logloss:0.299199\teval-logloss:0.355894\n",
      "[210]\ttrain-logloss:0.296768\teval-logloss:0.359679\n",
      "[225]\ttrain-logloss:0.294945\teval-logloss:0.36081\n",
      "[240]\ttrain-logloss:0.293169\teval-logloss:0.354961\n",
      "[255]\ttrain-logloss:0.291001\teval-logloss:0.353774\n",
      "[270]\ttrain-logloss:0.289022\teval-logloss:0.350644\n",
      "[285]\ttrain-logloss:0.28755\teval-logloss:0.352917\n",
      "[300]\ttrain-logloss:0.286161\teval-logloss:0.351736\n",
      "[315]\ttrain-logloss:0.284429\teval-logloss:0.349438\n",
      "[330]\ttrain-logloss:0.283082\teval-logloss:0.34978\n",
      "[345]\ttrain-logloss:0.281551\teval-logloss:0.350639\n",
      "[360]\ttrain-logloss:0.279948\teval-logloss:0.350009\n",
      "[375]\ttrain-logloss:0.278797\teval-logloss:0.351069\n",
      "[390]\ttrain-logloss:0.277506\teval-logloss:0.354179\n",
      "[405]\ttrain-logloss:0.276328\teval-logloss:0.356217\n",
      "[420]\ttrain-logloss:0.274944\teval-logloss:0.360346\n",
      "[435]\ttrain-logloss:0.274015\teval-logloss:0.360905\n",
      "[450]\ttrain-logloss:0.272901\teval-logloss:0.363455\n",
      "[465]\ttrain-logloss:0.27179\teval-logloss:0.363703\n",
      "[480]\ttrain-logloss:0.27054\teval-logloss:0.363673\n",
      "[495]\ttrain-logloss:0.269566\teval-logloss:0.363492\n",
      "[510]\ttrain-logloss:0.268339\teval-logloss:0.3648\n",
      "[525]\ttrain-logloss:0.267074\teval-logloss:0.364635\n",
      "[540]\ttrain-logloss:0.266118\teval-logloss:0.364979\n",
      "[555]\ttrain-logloss:0.265019\teval-logloss:0.365508\n",
      "[570]\ttrain-logloss:0.264019\teval-logloss:0.365675\n",
      "[585]\ttrain-logloss:0.263113\teval-logloss:0.361374\n",
      "[600]\ttrain-logloss:0.262227\teval-logloss:0.360358\n",
      "[615]\ttrain-logloss:0.261126\teval-logloss:0.360029\n",
      "[630]\ttrain-logloss:0.260425\teval-logloss:0.360689\n",
      "[645]\ttrain-logloss:0.259521\teval-logloss:0.360522\n",
      "[660]\ttrain-logloss:0.258714\teval-logloss:0.360593\n",
      "[675]\ttrain-logloss:0.25813\teval-logloss:0.362535\n",
      "[690]\ttrain-logloss:0.257454\teval-logloss:0.351794\n",
      "[705]\ttrain-logloss:0.256593\teval-logloss:0.349721\n",
      "[720]\ttrain-logloss:0.255872\teval-logloss:0.348809\n",
      "[735]\ttrain-logloss:0.255034\teval-logloss:0.3455\n",
      "[750]\ttrain-logloss:0.254343\teval-logloss:0.350379\n",
      "[765]\ttrain-logloss:0.253106\teval-logloss:0.348266\n",
      "[780]\ttrain-logloss:0.252488\teval-logloss:0.346922\n",
      "[795]\ttrain-logloss:0.2517\teval-logloss:0.34771\n",
      "[810]\ttrain-logloss:0.250973\teval-logloss:0.347606\n",
      "[825]\ttrain-logloss:0.249978\teval-logloss:0.350049\n",
      "[840]\ttrain-logloss:0.249186\teval-logloss:0.350022\n",
      "[855]\ttrain-logloss:0.248262\teval-logloss:0.346379\n",
      "[870]\ttrain-logloss:0.247651\teval-logloss:0.337738\n",
      "[885]\ttrain-logloss:0.247041\teval-logloss:0.332844\n",
      "[900]\ttrain-logloss:0.246346\teval-logloss:0.33344\n",
      "[915]\ttrain-logloss:0.245768\teval-logloss:0.333726\n",
      "[930]\ttrain-logloss:0.245053\teval-logloss:0.334799\n",
      "[945]\ttrain-logloss:0.244298\teval-logloss:0.337805\n",
      "[960]\ttrain-logloss:0.243598\teval-logloss:0.336201\n",
      "[975]\ttrain-logloss:0.242704\teval-logloss:0.334117\n",
      "[990]\ttrain-logloss:0.242\teval-logloss:0.333677\n",
      "[1005]\ttrain-logloss:0.241401\teval-logloss:0.333047\n",
      "[1020]\ttrain-logloss:0.240747\teval-logloss:0.332927\n",
      "[1035]\ttrain-logloss:0.240129\teval-logloss:0.332791\n",
      "[1050]\ttrain-logloss:0.239437\teval-logloss:0.33323\n",
      "[1065]\ttrain-logloss:0.238698\teval-logloss:0.333298\n",
      "[1080]\ttrain-logloss:0.23805\teval-logloss:0.336566\n",
      "[1095]\ttrain-logloss:0.237068\teval-logloss:0.337215\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(plst, Xdatatrain, numround, evals=watchlist, verbose_eval=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = bst.predict(Xdatatest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = foo(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit['is_duplicate'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit.to_csv(\"stacking/lgb_11_test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.235243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.166915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.457306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.964534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.138894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.414888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.004965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.527287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.059948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.018945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.022571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.432894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.271257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.156550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.007867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.091632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.013556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.033910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345766</th>\n",
       "      <td>2345766</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345767</th>\n",
       "      <td>2345767</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345768</th>\n",
       "      <td>2345768</td>\n",
       "      <td>0.178849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345769</th>\n",
       "      <td>2345769</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345770</th>\n",
       "      <td>2345770</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345771</th>\n",
       "      <td>2345771</td>\n",
       "      <td>0.395677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345772</th>\n",
       "      <td>2345772</td>\n",
       "      <td>0.107522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345773</th>\n",
       "      <td>2345773</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345774</th>\n",
       "      <td>2345774</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345775</th>\n",
       "      <td>2345775</td>\n",
       "      <td>0.247307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345776</th>\n",
       "      <td>2345776</td>\n",
       "      <td>0.178206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345777</th>\n",
       "      <td>2345777</td>\n",
       "      <td>0.079706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345778</th>\n",
       "      <td>2345778</td>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345779</th>\n",
       "      <td>2345779</td>\n",
       "      <td>0.005764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345780</th>\n",
       "      <td>2345780</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345781</th>\n",
       "      <td>2345781</td>\n",
       "      <td>0.145338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345782</th>\n",
       "      <td>2345782</td>\n",
       "      <td>0.195627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345783</th>\n",
       "      <td>2345783</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345784</th>\n",
       "      <td>2345784</td>\n",
       "      <td>0.539111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345785</th>\n",
       "      <td>2345785</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345786</th>\n",
       "      <td>2345786</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345787</th>\n",
       "      <td>2345787</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345788</th>\n",
       "      <td>2345788</td>\n",
       "      <td>0.007245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345789</th>\n",
       "      <td>2345789</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345790</th>\n",
       "      <td>2345790</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345791</th>\n",
       "      <td>2345791</td>\n",
       "      <td>0.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345792</th>\n",
       "      <td>2345792</td>\n",
       "      <td>0.003236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345793</th>\n",
       "      <td>2345793</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345794</th>\n",
       "      <td>2345794</td>\n",
       "      <td>0.434776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345795</th>\n",
       "      <td>2345795</td>\n",
       "      <td>0.116537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2345796 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id  is_duplicate\n",
       "0              0      0.004466\n",
       "1              1      0.235243\n",
       "2              2      0.166915\n",
       "3              3      0.000614\n",
       "4              4      0.457306\n",
       "5              5      0.001726\n",
       "6              6      0.964534\n",
       "7              7      0.138894\n",
       "8              8      0.414888\n",
       "9              9      0.004965\n",
       "10            10      0.527287\n",
       "11            11      0.000123\n",
       "12            12      0.000172\n",
       "13            13      0.059948\n",
       "14            14      0.018945\n",
       "15            15      0.022571\n",
       "16            16      0.000417\n",
       "17            17      0.432894\n",
       "18            18      0.271257\n",
       "19            19      0.156550\n",
       "20            20      0.000088\n",
       "21            21      0.007867\n",
       "22            22      0.001261\n",
       "23            23      0.011597\n",
       "24            24      0.000137\n",
       "25            25      0.091632\n",
       "26            26      0.000139\n",
       "27            27      0.013556\n",
       "28            28      0.033910\n",
       "29            29      0.001042\n",
       "...          ...           ...\n",
       "2345766  2345766      0.000164\n",
       "2345767  2345767      0.000321\n",
       "2345768  2345768      0.178849\n",
       "2345769  2345769      0.000080\n",
       "2345770  2345770      0.127600\n",
       "2345771  2345771      0.395677\n",
       "2345772  2345772      0.107522\n",
       "2345773  2345773      0.000170\n",
       "2345774  2345774      0.001436\n",
       "2345775  2345775      0.247307\n",
       "2345776  2345776      0.178206\n",
       "2345777  2345777      0.079706\n",
       "2345778  2345778      0.000498\n",
       "2345779  2345779      0.005764\n",
       "2345780  2345780      0.001094\n",
       "2345781  2345781      0.145338\n",
       "2345782  2345782      0.195627\n",
       "2345783  2345783      0.001318\n",
       "2345784  2345784      0.539111\n",
       "2345785  2345785      0.000133\n",
       "2345786  2345786      0.000078\n",
       "2345787  2345787      0.000207\n",
       "2345788  2345788      0.007245\n",
       "2345789  2345789      0.000131\n",
       "2345790  2345790      0.000106\n",
       "2345791  2345791      0.000212\n",
       "2345792  2345792      0.003236\n",
       "2345793  2345793      0.000080\n",
       "2345794  2345794      0.434776\n",
       "2345795  2345795      0.116537\n",
       "\n",
       "[2345796 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
