{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/tf3/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/tf3/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['shuffle']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import manifold, decomposition, linear_model, ensemble, neighbors, cross_validation\n",
    "import sklearn\n",
    "from sklearn import pipeline, preprocessing, feature_extraction\n",
    "#import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "#import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, auc, roc_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#import lightgbm as lgbm\n",
    "import scipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cv2\n",
    "from random import shuffle\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "#x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import os\n",
    "zir_files = os.listdir('data/zir')\n",
    "norm_files = os.listdir('data/norm')\n",
    "\n",
    "train_zir = zir_files[:55]\n",
    "val_zir = zir_files[55:]\n",
    "\n",
    "train_norm = norm_files[:14]\n",
    "val_norm = norm_files[14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zir_files), len(norm_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_generator(batch_size):\n",
    "    while(1):\n",
    "        #shuffle(train_zir)\n",
    "        #shuffle(train_norm)\n",
    "        \n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for i in range(batch_size):\n",
    "            zir = random.randint(0,1)\n",
    "            if zir == 1:\n",
    "                idx = random.randint(0,54)\n",
    "                img = cv2.imread('zir/{}'.format(train_zir[idx]))\n",
    "                y_train += [1]\n",
    "            else:\n",
    "                idx = random.randint(0,13)\n",
    "                img = cv2.imread('norm/{}'.format(train_norm[idx]))\n",
    "                y_train += [0]  \n",
    "                \n",
    "            x = random.randint(0,img.shape[0]-224)\n",
    "            y = random.randint(0,img.shape[1]-224)\n",
    "\n",
    "            img = img[x:x+224,y:y+224,:]\n",
    "            \n",
    "            #img = cv2.resize(img, (224, 224))\n",
    "            num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), random.choice([0, 90, 180, 270]), 1)\n",
    "            img = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                img = cv2.flip( img, 0  )\n",
    "\n",
    "            #1\n",
    "            x_train.append(img)\n",
    "            #y_train.append(targets)  \n",
    "            \n",
    "            \n",
    "        y_train = np.array(y_train, np.uint8)\n",
    "        x_train = np.array(x_train, np.float16) / 255.0\n",
    "        yield (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(batch_size):\n",
    "    while(1):\n",
    "        #shuffle(val_zir)\n",
    "        #shuffle(val_norm)\n",
    "        \n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for i in range(batch_size):\n",
    "            zir = random.randint(0,1)\n",
    "            if zir == 1:\n",
    "                idx = random.randint(0,21)\n",
    "                img = cv2.imread('zir/{}'.format(val_zir[idx]))\n",
    "                y_train += [1]\n",
    "            else:\n",
    "                idx = random.randint(0,7)\n",
    "                img = cv2.imread('norm/{}'.format(val_norm[idx]))\n",
    "                y_train += [0]  \n",
    "                \n",
    "            x = random.randint(0,img.shape[0]-224)\n",
    "            y = random.randint(0,img.shape[1]-224)\n",
    "\n",
    "            img = img[x:x+224,y:y+224,:]\n",
    "            \n",
    "            #img = cv2.resize(img, (224, 224))\n",
    "            num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), random.choice([0, 90, 180, 270]), 1)\n",
    "            img = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "\n",
    "            if random.choice([0, 1]) == 1:\n",
    "                img = cv2.flip( img, 0  )\n",
    "\n",
    "            #1\n",
    "            x_train.append(img)\n",
    "            #y_train.append(targets)  \n",
    "            \n",
    "            \n",
    "        y_train = np.array(y_train, np.uint8)\n",
    "        x_train = np.array(x_train, np.float16) / 255.0\n",
    "        yield (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('VGG16_.h5', save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument  `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Update your method calls accordingly.\n",
      "  \n",
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=40, validation_steps=5, callbacks=[<keras.ca..., steps_per_epoch=10, validation_data=<generator..., verbose=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10/10 [==============================] - 66s - loss: 0.8145 - acc: 0.4766 - val_loss: 0.7002 - val_acc: 0.4656\n",
      "Epoch 2/40\n",
      "10/10 [==============================] - 39s - loss: 0.6670 - acc: 0.5547 - val_loss: 0.5899 - val_acc: 0.7656\n",
      "Epoch 3/40\n",
      "10/10 [==============================] - 40s - loss: 0.5942 - acc: 0.7344 - val_loss: 0.5449 - val_acc: 0.9250\n",
      "Epoch 4/40\n",
      "10/10 [==============================] - 40s - loss: 0.5511 - acc: 0.8063 - val_loss: 0.4962 - val_acc: 0.9844\n",
      "Epoch 5/40\n",
      "10/10 [==============================] - 40s - loss: 0.5097 - acc: 0.8625 - val_loss: 0.4598 - val_acc: 0.9531\n",
      "Epoch 6/40\n",
      "10/10 [==============================] - 40s - loss: 0.4811 - acc: 0.8891 - val_loss: 0.4333 - val_acc: 0.9781\n",
      "Epoch 7/40\n",
      "10/10 [==============================] - 40s - loss: 0.4413 - acc: 0.9125 - val_loss: 0.4009 - val_acc: 0.9750\n",
      "Epoch 8/40\n",
      "10/10 [==============================] - 40s - loss: 0.4235 - acc: 0.9234 - val_loss: 0.3647 - val_acc: 0.9875\n",
      "Epoch 9/40\n",
      "10/10 [==============================] - 40s - loss: 0.3827 - acc: 0.9563 - val_loss: 0.3477 - val_acc: 0.9812\n",
      "Epoch 10/40\n",
      "10/10 [==============================] - 40s - loss: 0.3629 - acc: 0.9437 - val_loss: 0.3120 - val_acc: 0.9844\n",
      "Epoch 11/40\n",
      "10/10 [==============================] - 39s - loss: 0.3526 - acc: 0.9437 - val_loss: 0.3049 - val_acc: 0.9750\n",
      "Epoch 12/40\n",
      "10/10 [==============================] - 40s - loss: 0.3316 - acc: 0.9422 - val_loss: 0.3033 - val_acc: 0.9656\n",
      "Epoch 13/40\n",
      "10/10 [==============================] - 40s - loss: 0.3260 - acc: 0.9391 - val_loss: 0.2886 - val_acc: 0.9844\n",
      "Epoch 14/40\n",
      "10/10 [==============================] - 38s - loss: 0.3000 - acc: 0.9625 - val_loss: 0.2558 - val_acc: 0.9688\n",
      "Epoch 15/40\n",
      "10/10 [==============================] - 41s - loss: 0.2979 - acc: 0.9344 - val_loss: 0.2588 - val_acc: 0.9750\n",
      "Epoch 16/40\n",
      "10/10 [==============================] - 40s - loss: 0.2749 - acc: 0.9547 - val_loss: 0.2390 - val_acc: 0.9719\n",
      "Epoch 17/40\n",
      "10/10 [==============================] - 39s - loss: 0.2778 - acc: 0.9437 - val_loss: 0.2268 - val_acc: 0.9844\n",
      "Epoch 18/40\n",
      "10/10 [==============================] - 41s - loss: 0.2417 - acc: 0.9719 - val_loss: 0.2260 - val_acc: 0.9594\n",
      "Epoch 19/40\n",
      "10/10 [==============================] - 40s - loss: 0.2546 - acc: 0.9500 - val_loss: 0.2077 - val_acc: 0.9875\n",
      "Epoch 20/40\n",
      "10/10 [==============================] - 40s - loss: 0.2449 - acc: 0.9563 - val_loss: 0.2028 - val_acc: 0.9812\n",
      "Epoch 21/40\n",
      "10/10 [==============================] - 40s - loss: 0.2211 - acc: 0.9609 - val_loss: 0.1817 - val_acc: 0.9875\n",
      "Epoch 22/40\n",
      "10/10 [==============================] - 40s - loss: 0.2217 - acc: 0.9656 - val_loss: 0.2018 - val_acc: 0.9781\n",
      "Epoch 23/40\n",
      "10/10 [==============================] - 40s - loss: 0.2203 - acc: 0.9594 - val_loss: 0.1759 - val_acc: 0.9875\n",
      "Epoch 24/40\n",
      "10/10 [==============================] - 40s - loss: 0.2142 - acc: 0.9594 - val_loss: 0.1697 - val_acc: 0.9969\n",
      "Epoch 25/40\n",
      "10/10 [==============================] - 40s - loss: 0.2252 - acc: 0.9484 - val_loss: 0.1842 - val_acc: 0.9719\n",
      "Epoch 26/40\n",
      "10/10 [==============================] - 40s - loss: 0.2062 - acc: 0.9625 - val_loss: 0.1725 - val_acc: 0.9812\n",
      "Epoch 27/40\n",
      "10/10 [==============================] - 39s - loss: 0.1950 - acc: 0.9688 - val_loss: 0.1636 - val_acc: 0.9844\n",
      "Epoch 28/40\n",
      "10/10 [==============================] - 40s - loss: 0.1946 - acc: 0.9672 - val_loss: 0.1512 - val_acc: 0.9906\n",
      "Epoch 29/40\n",
      "10/10 [==============================] - 39s - loss: 0.1969 - acc: 0.9625 - val_loss: 0.1415 - val_acc: 0.9875\n",
      "Epoch 30/40\n",
      "10/10 [==============================] - 40s - loss: 0.1825 - acc: 0.9594 - val_loss: 0.1458 - val_acc: 0.9938\n",
      "Epoch 31/40\n",
      "10/10 [==============================] - 41s - loss: 0.1810 - acc: 0.9656 - val_loss: 0.1390 - val_acc: 0.9906\n",
      "Epoch 32/40\n",
      "10/10 [==============================] - 40s - loss: 0.1689 - acc: 0.9688 - val_loss: 0.1495 - val_acc: 0.9844\n",
      "Epoch 33/40\n",
      "10/10 [==============================] - 40s - loss: 0.1833 - acc: 0.9531 - val_loss: 0.1311 - val_acc: 0.9875\n",
      "Epoch 34/40\n",
      "10/10 [==============================] - 40s - loss: 0.1699 - acc: 0.9672 - val_loss: 0.1398 - val_acc: 0.9969\n",
      "Epoch 35/40\n",
      "10/10 [==============================] - 40s - loss: 0.1513 - acc: 0.9750 - val_loss: 0.1391 - val_acc: 0.9812\n",
      "Epoch 36/40\n",
      "10/10 [==============================] - 40s - loss: 0.1487 - acc: 0.9734 - val_loss: 0.1276 - val_acc: 0.9906\n",
      "Epoch 37/40\n",
      "10/10 [==============================] - 41s - loss: 0.1616 - acc: 0.9656 - val_loss: 0.1236 - val_acc: 0.9906\n",
      "Epoch 38/40\n",
      "10/10 [==============================] - 40s - loss: 0.1464 - acc: 0.9797 - val_loss: 0.1131 - val_acc: 0.9969\n",
      "Epoch 39/40\n",
      "10/10 [==============================] - 40s - loss: 0.1597 - acc: 0.9609 - val_loss: 0.1218 - val_acc: 0.9812\n",
      "Epoch 40/40\n",
      "10/10 [==============================] - 40s - loss: 0.1423 - acc: 0.9781 - val_loss: 0.1231 - val_acc: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc597317f28>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit_generator(all_generator(batch_size),\n",
    "                    samples_per_epoch=10,\n",
    "                    validation_data=val_generator(batch_size),\n",
    "                    nb_val_samples=5,\n",
    "                    nb_epoch=40,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument  `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Update your method calls accordingly.\n",
      "  \n",
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=40, validation_steps=5, callbacks=[<keras.ca..., steps_per_epoch=10, validation_data=<generator..., verbose=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10/10 [==============================] - 64s - loss: 0.1481 - acc: 0.9703 - val_loss: 0.1172 - val_acc: 0.9812\n",
      "Epoch 2/40\n",
      "10/10 [==============================] - 40s - loss: 0.1313 - acc: 0.9812 - val_loss: 0.1047 - val_acc: 0.9906\n",
      "Epoch 3/40\n",
      "10/10 [==============================] - 40s - loss: 0.1411 - acc: 0.9719 - val_loss: 0.1108 - val_acc: 0.9844\n",
      "Epoch 4/40\n",
      "10/10 [==============================] - 39s - loss: 0.1450 - acc: 0.9734 - val_loss: 0.1090 - val_acc: 0.9938\n",
      "Epoch 5/40\n",
      "10/10 [==============================] - 41s - loss: 0.1385 - acc: 0.9656 - val_loss: 0.1054 - val_acc: 0.9938\n",
      "Epoch 6/40\n",
      "10/10 [==============================] - 40s - loss: 0.1373 - acc: 0.9734 - val_loss: 0.1012 - val_acc: 0.9969\n",
      "Epoch 7/40\n",
      "10/10 [==============================] - 42s - loss: 0.1445 - acc: 0.9688 - val_loss: 0.0949 - val_acc: 0.9938\n",
      "Epoch 8/40\n",
      "10/10 [==============================] - 40s - loss: 0.1246 - acc: 0.9672 - val_loss: 0.1037 - val_acc: 0.9906\n",
      "Epoch 9/40\n",
      "10/10 [==============================] - 39s - loss: 0.1526 - acc: 0.9563 - val_loss: 0.0979 - val_acc: 0.9875\n",
      "Epoch 10/40\n",
      "10/10 [==============================] - 40s - loss: 0.1122 - acc: 0.9812 - val_loss: 0.0925 - val_acc: 0.9906\n",
      "Epoch 11/40\n",
      "10/10 [==============================] - 40s - loss: 0.1454 - acc: 0.9578 - val_loss: 0.0972 - val_acc: 0.9938\n",
      "Epoch 12/40\n",
      "10/10 [==============================] - 40s - loss: 0.1287 - acc: 0.9766 - val_loss: 0.0828 - val_acc: 1.0000\n",
      "Epoch 13/40\n",
      "10/10 [==============================] - 41s - loss: 0.1163 - acc: 0.9797 - val_loss: 0.1111 - val_acc: 0.9844\n",
      "Epoch 14/40\n",
      "10/10 [==============================] - 40s - loss: 0.1337 - acc: 0.9734 - val_loss: 0.0946 - val_acc: 0.9875\n",
      "Epoch 15/40\n",
      "10/10 [==============================] - 40s - loss: 0.1125 - acc: 0.9859 - val_loss: 0.0894 - val_acc: 0.9969\n",
      "Epoch 16/40\n",
      "10/10 [==============================] - 41s - loss: 0.1146 - acc: 0.9750 - val_loss: 0.0976 - val_acc: 0.9875\n",
      "Epoch 17/40\n",
      "10/10 [==============================] - 40s - loss: 0.1201 - acc: 0.9844 - val_loss: 0.0895 - val_acc: 0.9906\n",
      "Epoch 18/40\n",
      "10/10 [==============================] - 41s - loss: 0.1074 - acc: 0.9844 - val_loss: 0.0812 - val_acc: 0.9938\n",
      "Epoch 19/40\n",
      "10/10 [==============================] - 41s - loss: 0.1198 - acc: 0.9766 - val_loss: 0.0744 - val_acc: 0.9969\n",
      "Epoch 20/40\n",
      "10/10 [==============================] - 40s - loss: 0.1088 - acc: 0.9828 - val_loss: 0.0925 - val_acc: 0.9938\n",
      "Epoch 21/40\n",
      "10/10 [==============================] - 40s - loss: 0.1116 - acc: 0.9719 - val_loss: 0.0914 - val_acc: 0.9906\n",
      "Epoch 22/40\n",
      "10/10 [==============================] - 40s - loss: 0.1122 - acc: 0.9797 - val_loss: 0.0967 - val_acc: 0.9875\n",
      "Epoch 23/40\n",
      "10/10 [==============================] - 40s - loss: 0.1116 - acc: 0.9734 - val_loss: 0.0782 - val_acc: 0.9906\n",
      "Epoch 24/40\n",
      "10/10 [==============================] - 40s - loss: 0.1122 - acc: 0.9750 - val_loss: 0.0851 - val_acc: 0.9938\n",
      "Epoch 25/40\n",
      "10/10 [==============================] - 40s - loss: 0.1079 - acc: 0.9750 - val_loss: 0.0697 - val_acc: 0.9906\n",
      "Epoch 26/40\n",
      "10/10 [==============================] - 41s - loss: 0.1047 - acc: 0.9766 - val_loss: 0.0696 - val_acc: 0.9938\n",
      "Epoch 27/40\n",
      "10/10 [==============================] - 40s - loss: 0.1125 - acc: 0.9719 - val_loss: 0.0701 - val_acc: 0.9906\n",
      "Epoch 28/40\n",
      "10/10 [==============================] - 40s - loss: 0.0907 - acc: 0.9891 - val_loss: 0.0801 - val_acc: 0.9906\n",
      "Epoch 29/40\n",
      "10/10 [==============================] - 41s - loss: 0.1069 - acc: 0.9734 - val_loss: 0.0593 - val_acc: 0.9938\n",
      "Epoch 30/40\n",
      "10/10 [==============================] - 40s - loss: 0.0905 - acc: 0.9891 - val_loss: 0.0637 - val_acc: 1.0000\n",
      "Epoch 31/40\n",
      "10/10 [==============================] - 41s - loss: 0.0881 - acc: 0.9797 - val_loss: 0.0720 - val_acc: 0.9844\n",
      "Epoch 32/40\n",
      "10/10 [==============================] - 40s - loss: 0.1024 - acc: 0.9719 - val_loss: 0.0659 - val_acc: 0.9938\n",
      "Epoch 33/40\n",
      "10/10 [==============================] - 40s - loss: 0.0995 - acc: 0.9750 - val_loss: 0.0819 - val_acc: 0.9844\n",
      "Epoch 34/40\n",
      "10/10 [==============================] - 40s - loss: 0.1039 - acc: 0.9734 - val_loss: 0.0661 - val_acc: 0.9969\n",
      "Epoch 35/40\n",
      "10/10 [==============================] - 40s - loss: 0.1008 - acc: 0.9750 - val_loss: 0.0679 - val_acc: 0.9969\n",
      "Epoch 36/40\n",
      "10/10 [==============================] - 40s - loss: 0.0919 - acc: 0.9812 - val_loss: 0.0781 - val_acc: 0.9875\n",
      "Epoch 37/40\n",
      "10/10 [==============================] - 40s - loss: 0.0970 - acc: 0.9766 - val_loss: 0.0670 - val_acc: 0.9938\n",
      "Epoch 38/40\n",
      "10/10 [==============================] - 41s - loss: 0.0906 - acc: 0.9859 - val_loss: 0.0552 - val_acc: 0.9969\n",
      "Epoch 39/40\n",
      "10/10 [==============================] - 42s - loss: 0.0894 - acc: 0.9781 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 40/40\n",
      "10/10 [==============================] - 39s - loss: 0.0902 - acc: 0.9812 - val_loss: 0.0729 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5972e5748>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit_generator(all_generator(batch_size),\n",
    "                    samples_per_epoch=10,\n",
    "                    validation_data=val_generator(batch_size),\n",
    "                    nb_val_samples=5,\n",
    "                    nb_epoch=40,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "import keras\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(loss='binary_crossentropy', # We NEED binary here, since categorical_crossentropy l1 norms the output before calculating loss.\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('VGG16.h5', save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument  `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Update your method calls accordingly.\n",
      "  \n",
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=40, validation_steps=5, callbacks=[<keras.ca..., steps_per_epoch=10, validation_data=<generator..., verbose=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "10/10 [==============================] - 64s - loss: 0.0902 - acc: 0.9828 - val_loss: 0.0544 - val_acc: 1.0000\n",
      "Epoch 2/40\n",
      "10/10 [==============================] - 41s - loss: 0.0793 - acc: 0.9938 - val_loss: 0.0716 - val_acc: 0.9875\n",
      "Epoch 3/40\n",
      "10/10 [==============================] - 40s - loss: 0.0784 - acc: 0.9938 - val_loss: 0.0752 - val_acc: 0.9875\n",
      "Epoch 4/40\n",
      "10/10 [==============================] - 40s - loss: 0.0899 - acc: 0.9750 - val_loss: 0.0704 - val_acc: 0.9906\n",
      "Epoch 5/40\n",
      "10/10 [==============================] - 40s - loss: 0.0929 - acc: 0.9859 - val_loss: 0.0573 - val_acc: 0.9938\n",
      "Epoch 6/40\n",
      "10/10 [==============================] - 40s - loss: 0.0797 - acc: 0.9859 - val_loss: 0.0637 - val_acc: 0.9938\n",
      "Epoch 7/40\n",
      "10/10 [==============================] - 41s - loss: 0.1023 - acc: 0.9719 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 8/40\n",
      "10/10 [==============================] - 41s - loss: 0.0935 - acc: 0.9766 - val_loss: 0.0470 - val_acc: 1.0000\n",
      "Epoch 9/40\n",
      "10/10 [==============================] - 40s - loss: 0.1007 - acc: 0.9766 - val_loss: 0.0516 - val_acc: 0.9969\n",
      "Epoch 10/40\n",
      "10/10 [==============================] - 40s - loss: 0.0865 - acc: 0.9797 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 11/40\n",
      "10/10 [==============================] - 40s - loss: 0.0881 - acc: 0.9859 - val_loss: 0.0656 - val_acc: 0.9938\n",
      "Epoch 12/40\n",
      "10/10 [==============================] - 40s - loss: 0.0965 - acc: 0.9766 - val_loss: 0.0602 - val_acc: 0.9906\n",
      "Epoch 13/40\n",
      "10/10 [==============================] - 39s - loss: 0.0906 - acc: 0.9875 - val_loss: 0.0557 - val_acc: 1.0000\n",
      "Epoch 14/40\n",
      "10/10 [==============================] - 40s - loss: 0.0989 - acc: 0.9719 - val_loss: 0.0656 - val_acc: 0.9969\n",
      "Epoch 15/40\n",
      "10/10 [==============================] - 40s - loss: 0.0884 - acc: 0.9797 - val_loss: 0.0707 - val_acc: 0.9906\n",
      "Epoch 16/40\n",
      "10/10 [==============================] - 40s - loss: 0.0899 - acc: 0.9797 - val_loss: 0.0544 - val_acc: 0.9969\n",
      "Epoch 17/40\n",
      "10/10 [==============================] - 39s - loss: 0.0833 - acc: 0.9891 - val_loss: 0.0643 - val_acc: 0.9969\n",
      "Epoch 18/40\n",
      "10/10 [==============================] - 39s - loss: 0.0832 - acc: 0.9891 - val_loss: 0.0497 - val_acc: 0.9969\n",
      "Epoch 19/40\n",
      "10/10 [==============================] - 40s - loss: 0.0893 - acc: 0.9844 - val_loss: 0.0638 - val_acc: 0.9938\n",
      "Epoch 20/40\n",
      "10/10 [==============================] - 40s - loss: 0.0843 - acc: 0.9859 - val_loss: 0.0668 - val_acc: 0.9969\n",
      "Epoch 21/40\n",
      "10/10 [==============================] - 40s - loss: 0.0861 - acc: 0.9875 - val_loss: 0.0535 - val_acc: 0.9938\n",
      "Epoch 22/40\n",
      "10/10 [==============================] - 40s - loss: 0.0853 - acc: 0.9844 - val_loss: 0.0614 - val_acc: 0.9969\n",
      "Epoch 23/40\n",
      "10/10 [==============================] - 40s - loss: 0.0880 - acc: 0.9750 - val_loss: 0.0639 - val_acc: 0.9906\n",
      "Epoch 24/40\n",
      "10/10 [==============================] - 40s - loss: 0.0956 - acc: 0.9828 - val_loss: 0.0572 - val_acc: 1.0000\n",
      "Epoch 25/40\n",
      "10/10 [==============================] - 40s - loss: 0.0949 - acc: 0.9734 - val_loss: 0.0688 - val_acc: 0.9906\n",
      "Epoch 26/40\n",
      "10/10 [==============================] - 40s - loss: 0.0915 - acc: 0.9750 - val_loss: 0.0688 - val_acc: 0.9969\n",
      "Epoch 27/40\n",
      "10/10 [==============================] - 40s - loss: 0.0828 - acc: 0.9875 - val_loss: 0.0551 - val_acc: 0.9938\n",
      "Epoch 28/40\n",
      "10/10 [==============================] - 39s - loss: 0.0813 - acc: 0.9812 - val_loss: 0.0583 - val_acc: 0.9938\n",
      "Epoch 29/40\n",
      "10/10 [==============================] - 39s - loss: 0.0906 - acc: 0.9812 - val_loss: 0.0740 - val_acc: 0.9875\n",
      "Epoch 30/40\n",
      "10/10 [==============================] - 40s - loss: 0.0841 - acc: 0.9844 - val_loss: 0.0666 - val_acc: 0.9875\n",
      "Epoch 31/40\n",
      "10/10 [==============================] - 40s - loss: 0.0871 - acc: 0.9828 - val_loss: 0.0528 - val_acc: 0.9969\n",
      "Epoch 32/40\n",
      "10/10 [==============================] - 40s - loss: 0.0930 - acc: 0.9750 - val_loss: 0.0628 - val_acc: 0.9969\n",
      "Epoch 33/40\n",
      "10/10 [==============================] - 40s - loss: 0.0859 - acc: 0.9844 - val_loss: 0.0692 - val_acc: 0.9875\n",
      "Epoch 34/40\n",
      "10/10 [==============================] - 40s - loss: 0.0993 - acc: 0.9781 - val_loss: 0.0694 - val_acc: 0.9938\n",
      "Epoch 35/40\n",
      "10/10 [==============================] - 40s - loss: 0.0888 - acc: 0.9828 - val_loss: 0.0647 - val_acc: 0.9938\n",
      "Epoch 36/40\n",
      "10/10 [==============================] - 39s - loss: 0.0857 - acc: 0.9797 - val_loss: 0.0586 - val_acc: 0.9969\n",
      "Epoch 37/40\n",
      "10/10 [==============================] - 40s - loss: 0.0852 - acc: 0.9859 - val_loss: 0.0613 - val_acc: 0.9969\n",
      "Epoch 38/40\n",
      "10/10 [==============================] - 40s - loss: 0.0887 - acc: 0.9828 - val_loss: 0.0542 - val_acc: 0.9938\n",
      "Epoch 39/40\n",
      "10/10 [==============================] - 40s - loss: 0.0864 - acc: 0.9828 - val_loss: 0.0680 - val_acc: 0.9906\n",
      "Epoch 40/40\n",
      "10/10 [==============================] - 40s - loss: 0.0953 - acc: 0.9734 - val_loss: 0.0549 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc597237c88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "model.fit_generator(all_generator(batch_size),\n",
    "                    samples_per_epoch=10,\n",
    "                    validation_data=val_generator(batch_size),\n",
    "                    nb_val_samples=5,\n",
    "                    nb_epoch=40,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
