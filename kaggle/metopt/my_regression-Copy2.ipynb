{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def color_histogram_hsv(im, nbin=100, xmin=0, xmax=255, normalized=True):\n",
    "\n",
    "    ndim = im.ndim\n",
    "    bins = np.linspace(xmin, xmax, nbin+1)\n",
    "    hsv = matplotlib.colors.rgb_to_hsv(im/xmax) * xmax\n",
    "    imhist, bin_edges = np.histogram(hsv[:,:,0], bins=bins, density=normalized)\n",
    "    imhist = imhist * np.diff(bin_edges)\n",
    "\n",
    "    return imhist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Стратифицированное разбиение на фолды\n",
    "def skf(a):\n",
    "    n = len(a)\n",
    "    b = [0, 0]\n",
    "    for i in a:\n",
    "        b[i] += 1\n",
    "    bb = []\n",
    "    for i in range(5):\n",
    "        bb += [[0, 0]]\n",
    "    for i in range(2):\n",
    "        for j in range(b[i] % 5):\n",
    "            bb[j][i] = b[i] // 5 + 1\n",
    "        for j in range(b[i] % 5, 5):\n",
    "            bb[j][i] = b[i] // 5;\n",
    " \n",
    "    cur = [0, 0]\n",
    "    c = []\n",
    "    for i in range(5):\n",
    "        c += [[0, 0]]\n",
    "    ans = []\n",
    "    for i in range(5):\n",
    "        ans += [[[], []]]\n",
    "    for i in range(n):\n",
    "        if c[cur[a[i]]][a[i]] < bb[cur[a[i]]][a[i]]:\n",
    "            for j in range(5):\n",
    "                if (cur[a[i]] == j):\n",
    "                    ans[j][0].append(i)\n",
    "                else:\n",
    "                    ans[j][1].append(i)\n",
    "            c[cur[a[i]]][a[i]] += 1\n",
    "            if (c[cur[a[i]]][a[i]] == bb[cur[a[i]]][a[i]]):\n",
    "                cur[a[i]] += 1;\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Трёхмерная гистограмма цветов\n",
    "def hist3d(img):\n",
    "    hist = np.zeros((8,8,8))\n",
    "    tmp = img // 32\n",
    "    for i in range(32):\n",
    "        for j in range(32):\n",
    "            hist[tmp[i,j,0],tmp[i,j,1],tmp[i,j,2]] += 1\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter\n",
    "\n",
    "# Перевод в серый\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.144])\n",
    "\n",
    "# Фичи гистограмма направленных градиентов\n",
    "def hog (im):  \n",
    "\n",
    "    image = rgb2gray(im)\n",
    "    # Число направлений\n",
    "    vect_cnt = 9 \n",
    "    # Сколько пикселей на ячейку\n",
    "    cx, cy = (4, 4)\n",
    "\n",
    "    gx = np.zeros(image.shape)\n",
    "    gy = np.zeros(image.shape)\n",
    "    # Градиент по первой координате\n",
    "    gx[:, :-1] = np.diff(image, n=1, axis=1)\n",
    "    # Градиент по второй координате\n",
    "    gy[:-1, :] = np.diff(image, n=1, axis=0)\n",
    "    # Величина градиента\n",
    "    val = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    # Направление градиента\n",
    "    direction = np.arctan2(gy, (gx + 1e-14)) * (180 / np.pi) + 90 \n",
    "    \n",
    "\n",
    "    # Число ячеек по первой координате\n",
    "    n_cellsx = int(np.floor(image.shape[0] / cx))\n",
    "    # Число ячеек по второй координате\n",
    "    n_cellsy = int(np.floor(image.shape[1] / cy))\n",
    "    hist = np.zeros((n_cellsx, n_cellsy, vect_cnt))\n",
    "    for i in range(vect_cnt):\n",
    "        temp_direction = np.where(direction < 180 / vect_cnt * (i + 1), direction, 0)\n",
    "        temp_direction = np.where(direction >= 180 / vect_cnt * i, temp_direction, 0)\n",
    "\n",
    "        cond2 = temp_direction > 0\n",
    "        temp_mag = np.where(cond2, val, 0)\n",
    "        hist[:,:,i] = uniform_filter(temp_mag, size=(cx, cy))[int(cx/2)::cx, int(cy/2)::cy].T\n",
    "  \n",
    "    return hist.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_direction(x, y, threshold_delta):\n",
    "    return 1 if x - y > threshold_delta else 0\n",
    "\n",
    "# 7   0   1\n",
    "# 6   x   2\n",
    "# 5   4   3\n",
    "# Фичи Local binary patterns\n",
    "def compute_lbp(data, i, j, threshold_delta):\n",
    "    result = 0\n",
    "    result +=       compute_direction(data[i, j], data[i-1, j], threshold_delta)\n",
    "    result += 2   * compute_direction(data[i, j], data[i-1, j+1], threshold_delta)\n",
    "    result += 4   * compute_direction(data[i, j], data[i, j+1], threshold_delta)\n",
    "    result += 8   * compute_direction(data[i, j], data[i+1, j+1], threshold_delta)\n",
    "    result += 16  * compute_direction(data[i, j], data[i+1, j], threshold_delta)\n",
    "    result += 32  * compute_direction(data[i, j], data[i+1, j-1], threshold_delta)\n",
    "    result += 64  * compute_direction(data[i, j], data[i, j-1], threshold_delta)\n",
    "    result += 128 * compute_direction(data[i, j], data[i-1, j-1], threshold_delta)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from scipy.stats import logistic\n",
    " \n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def logloss(true_label, predicted, eps=1e-15):\n",
    "    p = np.clip(predicted, eps, 1 - eps)\n",
    "    if true_label == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1 - p)\n",
    "    \n",
    "def log_loss(y_true, y_pred):\n",
    "    los = 0\n",
    "    for i in range(len(y_true)):\n",
    "\n",
    "\n",
    "        los += logloss(y_true[i][1], y_pred[i][1])\n",
    "            \n",
    "    return los / len(y_true)    \n",
    "    \n",
    "def log_loss1(y_true, y_pred):\n",
    "    los = 0\n",
    "    for i in range(len(y_true)):\n",
    "\n",
    "        los += logloss(y_true[i], y_pred[i])\n",
    "            \n",
    "    return los / len(y_true)     \n",
    "\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return logistic.cdf(x)\n",
    "\"\"\"\n",
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x))  # prevent overflow\n",
    "    if e.ndim == 1:\n",
    "        return e / np.sum(e, axis=0)\n",
    "    else:  \n",
    "        return e / np.array([np.sum(e, axis=1)]).T  # ndim = 2\n",
    "\"\"\"\n",
    "\n",
    "def softmax(X, copy=True):\n",
    "\n",
    "    if copy:\n",
    "        X = np.copy(X)\n",
    "    max_prob = np.max(X, axis=1).reshape((-1, 1))\n",
    "    X -= max_prob\n",
    "    np.exp(X, X)\n",
    "    sum_prob = np.sum(X, axis=1).reshape((-1, 1))\n",
    "    X /= sum_prob\n",
    "    return X\n",
    "\n",
    "class LogisticRegression_(object):\n",
    "    def __init__(self, X, y, X_val, y_val):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.W = np.zeros((X.shape[1], y.shape[1]))  # initialize W 0\n",
    "        self.b = np.zeros(y.shape[1])          # initialize bias 0\n",
    "        self.losses_train = []\n",
    "        self.losses_valid = []\n",
    "\n",
    "        # self.params = [self.W, self.b]\n",
    "\n",
    "    def fit(self, n_epochs=1000, lr=0.0001, L2_reg=0.001):\n",
    "        for i in range(n_epochs):\n",
    "            # p_y_given_x = sigmoid(numpy.dot(self.x, self.W) + self.b)\n",
    "            p_y_given_x = softmax(np.dot(self.X, self.W) + self.b)\n",
    "            d_y = self.y - p_y_given_x\n",
    "\n",
    "            self.W += lr * np.dot(self.X.T, d_y) - lr * L2_reg * self.W\n",
    "            self.b += lr * np.mean(d_y, axis=0)\n",
    "            #print(softmax(np.dot(self.X, self.W) + self.b))\n",
    "\n",
    "            #print(softmax(np.dot(self.X_val, self.W) + self.b))\n",
    "            if i % 500 == 0:\n",
    "                loss = log_loss(self.y, softmax(np.dot(self.X, self.W) + self.b))\n",
    "                val_loss = log_loss(self.y_val, softmax(np.dot(self.X_val, self.W) + self.b))\n",
    "                #loss = self.cross_entropy(val=False)\n",
    "                #val_loss = self.cross_entropy(val=True)\n",
    "            \n",
    "                self.losses_train += [loss]\n",
    "                self.losses_valid += [val_loss]\n",
    "                print('Train_loss=', loss,' Val_loss=', val_loss)\n",
    "\n",
    "    def cross_entropy(self, val=False):\n",
    "        if val:\n",
    "            X = self.X_val\n",
    "            y = self.y_val\n",
    "        else:\n",
    "            X = self.X\n",
    "            y = self.y\n",
    "            \n",
    "        # sigmoid_activation = sigmoid(numpy.dot(self.x, self.W) + self.b)\n",
    "        sigmoid_activation = softmax(np.dot(X, self.W) + self.b)\n",
    "\n",
    "        cross_entropy = - np.mean(np.sum(y * np.log(sigmoid_activation) + \n",
    "                                               (1 - y) * np.log(1 - sigmoid_activation),axis=1))\n",
    "        return cross_entropy\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # return sigmoid(np.dot(x, self.W) + self.b)\n",
    "        return softmax(np.dot(X, self.W) + self.b)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # return sigmoid(np.dot(x, self.W) + self.b)\n",
    "        preds = []\n",
    "        probas = softmax(np.dot(X, self.W) + self.b)\n",
    "        for i in probas:\n",
    "            preds += [i == i.max()]\n",
    "        return np.array(preds).astype(int)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy import misc\n",
    "train = os.listdir('train/train')\n",
    "test = os.listdir('test/test')\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "tmp = []\n",
    "for i in train:\n",
    "    tmp += ['train/train/'+i]\n",
    "train = np.array(tmp)\n",
    "\n",
    "tmp = []\n",
    "for i in test:\n",
    "    tmp += ['test/test/'+i]\n",
    "test = np.array(tmp)\n",
    "\n",
    "\n",
    "classes = []\n",
    "y = []\n",
    "for i in train:\n",
    "    if 'indoor' in i:\n",
    "        classes += [[0, 1]]\n",
    "        y += [1]\n",
    "    else:\n",
    "        classes += [[1, 0]]\n",
    "        y += [0]\n",
    "classes = np.array(classes)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение на фолды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y = np.array(y.tolist() * 2)\n",
    "tmp = skf(y)\n",
    "    \n",
    "folds = []    \n",
    "for i in tmp:\n",
    "    folds += [[i[1], i[0]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считывание картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for seed in range(8):\n",
    "    for i in train:\n",
    "        img = misc.imread(i)\n",
    "        img = np.rot90(img, k=seed)\n",
    "        if seed >= 4:\n",
    "            img = np.fliplr(img)    \n",
    "        x_train += [img]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "\n",
    "x_test = []\n",
    "for seed in range(8):\n",
    "    for i in test:\n",
    "        img = misc.imread(i)\n",
    "        img = np.rot90(img, k=seed)\n",
    "        if seed >= 4:\n",
    "            img = np.fliplr(img)       \n",
    "        x_test += [img]\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55240, 32, 32, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6905.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55240 / 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23680"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Цветовые гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_train = []\n",
    "for i in x_train:\n",
    "    tmp = []\n",
    "    for j in range(3):\n",
    "        tmp += [np.histogram(i[:,:,j], bins=50)[0]]\n",
    "    hist_train += [tmp]\n",
    "hist_train = np.array(hist_train).reshape(x_train.shape[0], 150)\n",
    "\n",
    "\n",
    "hist_test = []\n",
    "for i in x_test:\n",
    "    tmp = []\n",
    "    for j in range(3):\n",
    "        tmp += [np.histogram(i[:,:,j], bins=50)[0]]\n",
    "    hist_test += [tmp]\n",
    "hist_test = np.array(hist_test).reshape(23680, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_hsv_train = []\n",
    "for i in x_train:\n",
    "    hist_hsv_train += [color_histogram_hsv(i)]\n",
    "hist_hsv_train = np.array(hist_hsv_train)\n",
    "\n",
    "hist_hsv_test = []\n",
    "for i in x_test:\n",
    "    hist_hsv_test += [color_histogram_hsv(i)]\n",
    "hist_hsv_test = np.array(hist_hsv_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_train = []\n",
    "for i in x_train:\n",
    "    hog_train += [hog(i)]\n",
    "hog_train = np.array(hog_train)\n",
    "\n",
    "\n",
    "hog_test = []\n",
    "for i in x_test:\n",
    "    hog_test += [hog(i)]\n",
    "hog_test = np.array(hog_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LBP фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbp_train = []\n",
    "for t in x_train:\n",
    "    image = t\n",
    "    image = rgb2gray(image)\n",
    "\n",
    "    lbps_histdata = []\n",
    "    mean_delta = 0\n",
    "\n",
    "    for i in range(1, image.shape[1]-1):\n",
    "        for j in range(1, image.shape[0]-1):\n",
    "            mean_delta += (abs(image[i, j] - image[i, j-1]) + abs(image[i, j] - image[i-1, j-1]) +\n",
    "                abs(image[i, j] - image[i-1, j]) + abs(image[i, j] - image[i-1, j+1]) )/4.0\n",
    "    mean_delta /= (image.shape[1]-2) * (image.shape[0]-2) \n",
    "    mean_delta *= 1.5 \n",
    "\n",
    "    for i in range(0, image.shape[1]):\n",
    "        for j in range(0, image.shape[0]):\n",
    "            if i != 0 and j != 0 and i != image.shape[1]-1 and j != image.shape[0]-1:\n",
    "                tmp = compute_lbp(image, i, j, mean_delta)\n",
    "                if tmp != 0:\n",
    "                    lbps_histdata.append(tmp)\n",
    "    hist, bins = np.histogram(lbps_histdata, bins=254, normed=True)\n",
    "                 \n",
    "    lbp_train += [hist]\n",
    "lbp_train = np.array(lbp_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lbp_test = []\n",
    "for t in x_test:\n",
    "    image = t\n",
    "    image = rgb2gray(image)\n",
    "\n",
    "    lbps_histdata = []\n",
    "    mean_delta = 0\n",
    "\n",
    "    for i in range(1, image.shape[1]-1):\n",
    "        for j in range(1, image.shape[0]-1):\n",
    "            mean_delta += (abs(image[i, j] - image[i, j-1]) + abs(image[i, j] - image[i-1, j-1]) +\n",
    "                abs(image[i, j] - image[i-1, j]) + abs(image[i, j] - image[i-1, j+1]) )/4.0\n",
    "    mean_delta /= (image.shape[1]-2) * (image.shape[0]-2) \n",
    "    mean_delta *= 1.5 \n",
    "\n",
    "    for i in range(0, image.shape[1]):\n",
    "        for j in range(0, image.shape[0]):\n",
    "            if i != 0 and j != 0 and i != image.shape[1]-1 and j != image.shape[0]-1:\n",
    "                tmp = compute_lbp(image, i, j, mean_delta)\n",
    "                if tmp != 0:\n",
    "                    lbps_histdata.append(tmp)\n",
    "    hist, bins = np.histogram(lbps_histdata, bins=254, normed=True)\n",
    "                 \n",
    "    lbp_test += [hist]\n",
    "lbp_test = np.array(lbp_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Трёхмерные гистограммы цвета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist3d_train = []\n",
    "for i in x_train:\n",
    "    hist = hist3d(i)\n",
    "    hist3d_train += [hist]\n",
    "hist3d_train = np.array(hist3d_train)\n",
    "\n",
    "\n",
    "hist3d_test = []\n",
    "for i in x_test:\n",
    "    hist = hist3d(i)\n",
    "    hist3d_test += [hist]\n",
    "hist3d_test = np.array(hist3d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи - статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms_train = []\n",
    "for i in x_train:\n",
    "    tmp = []\n",
    "    for j in range(3):\n",
    "        tmp += [i[:,:,j].mean()]\n",
    "        tmp += [i[:,:,j].std()]\n",
    "        tmp += [np.median(i[:,:,j])]\n",
    "    ms_train += [tmp]\n",
    "ms_train = np.array(ms_train)\n",
    "\n",
    "\n",
    "ms_test = []\n",
    "for i in x_test:\n",
    "    tmp = []\n",
    "    for j in range(3):\n",
    "        tmp += [i[:,:,j].mean()]\n",
    "        tmp += [i[:,:,j].std()]\n",
    "        tmp += [np.median(i[:,:,j])]\n",
    "    ms_test += [tmp]\n",
    "ms_test = np.array(ms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3])\n",
    "#x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация  и склейка фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hog_test = hog_test / hog_train.max() * 1.\n",
    "hog_train = hog_train / hog_train.max() * 1.\n",
    "\n",
    "hist3d_test = hist3d_test / hist3d_train.max() * 1.\n",
    "hist3d_train = hist3d_train / hist3d_train.max() * 1.\n",
    "\n",
    "hist_test = hist_test / hist_train.max() * 1.\n",
    "hist_train = hist_train / hist_train.max() * 1.\n",
    "\n",
    "ms_test = ms_test / 255.\n",
    "ms_train = ms_train / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.mlab import PCA\n",
    "\n",
    "tmp = PCA(np.vstack([x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3]), x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3])]))\n",
    "tmp = tmp.Y[:, :200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55240, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2960, 32, 32, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = tmp[:55240]\n",
    "pca_test = tmp[55240:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp[55240:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_test = pca_test / pca_train.max() * 1.\n",
    "pca_train = pca_train / pca_train.max() * 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2960, 200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = np.hstack([hist_train, hog_train, lbp_train, hist3d_train, pca_train])\n",
    "te = np.hstack([hist_test, hog_test, lbp_test, hist3d_test, pca_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55240, 1692)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss= 0.913184970785  Val_loss= 0.912074937933\n",
      "Train_loss= 0.150315958815  Val_loss= 0.194097580043\n",
      "Train_loss= 0.138417213279  Val_loss= 0.187906615238\n",
      "Train_loss= 0.132222218223  Val_loss= 0.186064013652\n",
      "Train_loss= 0.128091815106  Val_loss= 0.185659447835\n",
      "0.173230693009\n",
      "0.218392669878\n",
      "Train_loss= 0.915223404768  Val_loss= 0.919865740666\n",
      "Train_loss= 0.156763318372  Val_loss= 0.165326717076\n",
      "Train_loss= 0.144722965838  Val_loss= 0.157404527964\n",
      "Train_loss= 0.138381560772  Val_loss= 0.15487001789\n",
      "Train_loss= 0.134138290492  Val_loss= 0.153960900617\n",
      "0.142587653742\n",
      "0.200227637994\n",
      "Train_loss= 0.914438181716  Val_loss= 0.907615697138\n",
      "Train_loss= 0.151647664075  Val_loss= 0.185465283039\n",
      "Train_loss= 0.139700672325  Val_loss= 0.180127668733\n",
      "Train_loss= 0.133507378516  Val_loss= 0.178352286527\n",
      "Train_loss= 0.129419882353  Val_loss= 0.177667101418\n",
      "0.167165690236\n",
      "0.217179976161\n",
      "Train_loss= 0.922098501607  Val_loss= 0.930333685026\n",
      "Train_loss= 0.160041253969  Val_loss= 0.150762141662\n",
      "Train_loss= 0.147471269482  Val_loss= 0.148036149293\n",
      "Train_loss= 0.140907275471  Val_loss= 0.148046397613\n",
      "Train_loss= 0.13657472116  Val_loss= 0.1487925224\n",
      "0.135136184419\n",
      "0.194382887936\n",
      "Train_loss= 0.916384660373  Val_loss= 0.927043318557\n",
      "Train_loss= 0.150093118125  Val_loss= 0.190614244123\n",
      "Train_loss= 0.138145089091  Val_loss= 0.18707137113\n",
      "Train_loss= 0.132001326845  Val_loss= 0.186140129967\n",
      "Train_loss= 0.127949415881  Val_loss= 0.186079988773\n",
      "0.173381263342\n",
      "0.22550091086\n",
      "logreg: 0.158 +- 0.016\n",
      "rmse: 0.211 +- 0.012\n"
     ]
    }
   ],
   "source": [
    "pred_train = np.zeros(len(tr))\n",
    "est = []\n",
    "f_ll,f_rmse = [],[]\n",
    "\n",
    "for itr, ite in folds:\n",
    "    ypred = []\n",
    "    tmp_tr = tr[itr]\n",
    "    for part in range(1,8):   \n",
    "        tmp_tr = np.vstack([tmp_tr, tr[6905*part + np.array(itr)]])\n",
    "    tmp_classes = np.array(classes[itr].tolist()*8)\n",
    "    classifier = LogisticRegression_(tmp_tr, tmp_classes, tr[ite], classes[ite])\n",
    "    classifier.fit(n_epochs=2500, lr=0.0005, L2_reg=0.0001)\n",
    "    \n",
    "    ypred = classifier.predict_proba(tr[ite])[:, 1]\n",
    "    for part in range(1, 8):\n",
    "        ypred += classifier.predict_proba(tr[6905*part + np.array(ite)])[:, 1]\n",
    "\n",
    "    \n",
    "    pred_train[ite] = ypred / 8.\n",
    "\n",
    "    print(log_loss1(y[ite], pred_train[ite]))\n",
    "    print(rmse(y[ite], pred_train[ite]))\n",
    "    \n",
    "    f_ll.append(log_loss1(y[ite], pred_train[ite]))\n",
    "    f_rmse.append(rmse(y[ite], pred_train[ite]))\n",
    "\n",
    "    est.append(classifier)\n",
    "    \n",
    "print('logreg: {:.3f} +- {:.3f}'.format(np.mean(f_ll), np.std(f_ll)))\n",
    "print('rmse: {:.3f} +- {:.3f}'.format(np.mean(f_rmse), np.std(f_rmse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(pred_train).to_csv('preds/3_train.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Усреднение \n",
    "res = est[0].predict_proba(te[:2960])\n",
    "for part in range(1,8):\n",
    "    res += est[0].predict_proba(te[2960 * part:2960 * (part+1)])\n",
    "\n",
    "for i in range(1,5):\n",
    "    for part in range(8):\n",
    "        res += est[i].predict_proba(te[2960 * part:2960 * (part+1)])\n",
    "\n",
    "res = res / 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(test)\n",
    "tmp.columns = ['id']\n",
    "tmp['id'] = tmp['id'].apply(lambda x: int(x.split('_')[1][:-4]))\n",
    "tmp['res'] = res[:,1]\n",
    "tmp.to_csv('preds/3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223</td>\n",
       "      <td>0.042007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1878</td>\n",
       "      <td>0.987742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409</td>\n",
       "      <td>0.828963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993</td>\n",
       "      <td>0.742050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>783</td>\n",
       "      <td>0.981607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>900</td>\n",
       "      <td>0.275407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2508</td>\n",
       "      <td>0.976372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1848</td>\n",
       "      <td>0.999862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1285</td>\n",
       "      <td>0.987167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2889</td>\n",
       "      <td>0.118860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2134</td>\n",
       "      <td>0.020987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>160</td>\n",
       "      <td>0.994699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>815</td>\n",
       "      <td>0.963102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>363</td>\n",
       "      <td>0.088325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1570</td>\n",
       "      <td>0.995374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1435</td>\n",
       "      <td>0.003609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>246</td>\n",
       "      <td>0.005980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1108</td>\n",
       "      <td>0.999758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1955</td>\n",
       "      <td>0.979742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2826</td>\n",
       "      <td>0.122506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1836</td>\n",
       "      <td>0.987904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>646</td>\n",
       "      <td>0.999738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.928178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>559</td>\n",
       "      <td>0.942328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>903</td>\n",
       "      <td>0.998139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2367</td>\n",
       "      <td>0.998944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.989878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1289</td>\n",
       "      <td>0.395431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2847</td>\n",
       "      <td>0.061026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>2178</td>\n",
       "      <td>0.535640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>1966</td>\n",
       "      <td>0.036767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>1743</td>\n",
       "      <td>0.031158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>792</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>509</td>\n",
       "      <td>0.953649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>1793</td>\n",
       "      <td>0.656576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>1617</td>\n",
       "      <td>0.994152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>2771</td>\n",
       "      <td>0.996606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>1554</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>1755</td>\n",
       "      <td>0.061672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2940</th>\n",
       "      <td>666</td>\n",
       "      <td>0.056054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>248</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>2158</td>\n",
       "      <td>0.018267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>2950</td>\n",
       "      <td>0.192011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2944</th>\n",
       "      <td>1315</td>\n",
       "      <td>0.999429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>300</td>\n",
       "      <td>0.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2211</td>\n",
       "      <td>0.015124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2903</td>\n",
       "      <td>0.999639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>28</td>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>1734</td>\n",
       "      <td>0.998832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>49</td>\n",
       "      <td>0.999019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.002010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>607</td>\n",
       "      <td>0.975701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.997907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>1050</td>\n",
       "      <td>0.006298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>2191</td>\n",
       "      <td>0.390819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>475</td>\n",
       "      <td>0.998965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>1431</td>\n",
       "      <td>0.964767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>507</td>\n",
       "      <td>0.939981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>541</td>\n",
       "      <td>0.013979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2960 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       res\n",
       "0      223  0.042007\n",
       "1     1878  0.987742\n",
       "2      409  0.828963\n",
       "3     1993  0.742050\n",
       "4      783  0.981607\n",
       "5      900  0.275407\n",
       "6     2508  0.976372\n",
       "7     1848  0.999862\n",
       "8     1285  0.987167\n",
       "9     2889  0.118860\n",
       "10    2134  0.020987\n",
       "11     160  0.994699\n",
       "12     815  0.963102\n",
       "13       1  0.995367\n",
       "14     363  0.088325\n",
       "15    1570  0.995374\n",
       "16    1435  0.003609\n",
       "17     246  0.005980\n",
       "18    1108  0.999758\n",
       "19    1955  0.979742\n",
       "20    2826  0.122506\n",
       "21    1836  0.987904\n",
       "22     646  0.999738\n",
       "23    2006  0.928178\n",
       "24     559  0.942328\n",
       "25     903  0.998139\n",
       "26    2367  0.998944\n",
       "27    1754  0.989878\n",
       "28    1289  0.395431\n",
       "29    2847  0.061026\n",
       "...    ...       ...\n",
       "2930  2178  0.535640\n",
       "2931  1966  0.036767\n",
       "2932  1743  0.031158\n",
       "2933   792  0.999996\n",
       "2934   509  0.953649\n",
       "2935  1793  0.656576\n",
       "2936  1617  0.994152\n",
       "2937  2771  0.996606\n",
       "2938  1554  0.000614\n",
       "2939  1755  0.061672\n",
       "2940   666  0.056054\n",
       "2941   248  0.000058\n",
       "2942  2158  0.018267\n",
       "2943  2950  0.192011\n",
       "2944  1315  0.999429\n",
       "2945   300  0.166000\n",
       "2946  2211  0.015124\n",
       "2947  2903  0.999639\n",
       "2948    28  0.002596\n",
       "2949  1734  0.998832\n",
       "2950    49  0.999019\n",
       "2951  1800  0.002010\n",
       "2952   607  0.975701\n",
       "2953  2004  0.997907\n",
       "2954  1050  0.006298\n",
       "2955  2191  0.390819\n",
       "2956   475  0.998965\n",
       "2957  1431  0.964767\n",
       "2958   507  0.939981\n",
       "2959   541  0.013979\n",
       "\n",
       "[2960 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
