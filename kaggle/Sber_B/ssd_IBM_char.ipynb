{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement = True\n",
    "K.set_session(tf.Session(config=config))\n",
    "\n",
    "MAX_NB_WORDS = 100000\n",
    "MAX_PARAGRAPH_LENGTH = 200\n",
    "MAX_QUESTION_LENGTH = 30\n",
    "\n",
    "X_train = pd.read_csv('../train_task_b.csv')\n",
    "\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, split=\" \", char_level=False)\n",
    "word_tokenizer.fit_on_texts(X_train.paragraph.tolist() + X_train.question.tolist())\n",
    "\n",
    "train_sequences_1 = word_tokenizer.texts_to_sequences(X_train.paragraph.tolist())\n",
    "train_sequences_2 = word_tokenizer.texts_to_sequences(X_train.question.tolist())\n",
    "train_sequences_3 = word_tokenizer.texts_to_sequences(X_train.answer.tolist())\n",
    "\n",
    "train_sequences_1 = pad_sequences(train_sequences_1, maxlen=MAX_PARAGRAPH_LENGTH)\n",
    "train_sequences_2 = pad_sequences(train_sequences_2, maxlen=MAX_QUESTION_LENGTH)\n",
    "#train_sequences_3 = pad_sequences(train_sequences_3, maxlen=MAX_QUESTION_LENGTH)\n",
    "train_sequences_3 = np.array(train_sequences_3)\n",
    "\n",
    "\n",
    "char_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, split=\" \", char_level=True)\n",
    "char_tokenizer.fit_on_texts(X_train.paragraph + X_train.question)\n",
    "\n",
    "\n",
    "def find(arr, sub_arr):\n",
    "    for i in range(len(arr) - len(sub_arr)):\n",
    "        flag = 1\n",
    "        for j in range(len(sub_arr)):\n",
    "            if arr[i + j] != sub_arr[j]:\n",
    "                flag = 0\n",
    "        if flag == 1:\n",
    "            return i, i + len(sub_arr)\n",
    "        \n",
    "        \n",
    "start_end = np.zeros([len(train_sequences_1),2])\n",
    "for i in range(len(train_sequences_1)):\n",
    "    start_end[i] = find(train_sequences_1[i], train_sequences_3[i])\n",
    "    \n",
    "    \n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#word2vec = KeyedVectors.load_word2vec_format('../ruwikiruscorpora_0_300_20.bin', binary=True)\n",
    "word2vec = KeyedVectors.load_word2vec_format('../news_0_300_2.bin', binary=True)\n",
    "#word2vec = KeyedVectors.load_word2vec_format('../ruscorpora_1_600_2.bin', binary=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['paragraph'] = X_train['paragraph'].apply(lambda x: x.lower().split())\n",
    "X_train['question'] = X_train['question'].apply(lambda x: x.lower().split())\n",
    "X_train['answer'] = X_train['answer'].apply(lambda x: x.lower().split())\n",
    "\n",
    "train_sequences_1_ = X_train.paragraph.apply(lambda x: pad_sequences(char_tokenizer.texts_to_sequences(x), maxlen=20).tolist()[-200:])\n",
    "train_sequences_2_ = X_train.question.apply(lambda x: pad_sequences(char_tokenizer.texts_to_sequences(x), maxlen=20).tolist()[-30:])\n",
    "train_sequences_3_ = X_train.answer.apply(lambda x: pad_sequences(char_tokenizer.texts_to_sequences(x), maxlen=20).tolist()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_sequences_1_.apply(lambda x: np.vstack((np.zeros([201-len(x), 20]),np.array(x))))\n",
    "arr = []\n",
    "for i in np.array(tmp):\n",
    "    arr += [i.tolist()]\n",
    "train_sequences_1_ = np.array(arr)\n",
    "\n",
    "tmp = train_sequences_2_.apply(lambda x: np.vstack((np.zeros([31-len(x), 20]),np.array(x))))\n",
    "arr = []\n",
    "for i in np.array(tmp):\n",
    "    arr += [i.tolist()]\n",
    "train_sequences_2_ = np.array(arr)\n",
    "\n",
    "tmp = train_sequences_3_.apply(lambda x: np.vstack((np.zeros([31-len(x), 20]),np.array(x))))\n",
    "arr = []\n",
    "for i in np.array(tmp):\n",
    "    arr += [i.tolist()]\n",
    "train_sequences_3_ = np.array(arr)\n",
    "\n",
    "\n",
    "train_sequences_1_ = train_sequences_1_[:,:200,:]\n",
    "train_sequences_2_ = train_sequences_2_[:,:30,:]\n",
    "train_sequences_3_ = train_sequences_3_[:,:30,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = char_tokenizer.word_index\n",
    "\n",
    "embedding_char1 = Embedding(len(word_index),\n",
    "                            50,\n",
    "                            input_length=20,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139609/139609 [00:38<00:00, 3627.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_vect(p):\n",
    "    vect = []\n",
    "    for i in list(p.KNOWN_GRAMMEMES):\n",
    "        if i in p:\n",
    "            vect += [1]\n",
    "        else:\n",
    "            vect += [0]\n",
    "    return np.array(vect)\n",
    "\n",
    "from tqdm import tqdm\n",
    "word_index = word_tokenizer.word_index\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "cnt = 0 \n",
    "for word, i in tqdm(word_index.items()):\n",
    "    p = morph.parse(word)[0]\n",
    "    vect = get_vect(p.tag)\n",
    "    word = p.normalized[0]\n",
    "    for part_sp in p.tag.PARTS_OF_SPEECH:\n",
    "        if word+'_'+part_sp in word2vec.vocab:\n",
    "            #embedding_matrix[i] = np.concatenate((word2vec.word_vec(word+'_'+part_sp), vect))\n",
    "            embedding_matrix[i] = word2vec.word_vec(word+'_'+part_sp)\n",
    "            cnt += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer1 = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_PARAGRAPH_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "embedding_layer2 = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_QUESTION_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "embedding_layer3 = Embedding(embedding_matrix.shape[0],\n",
    "                            embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=1,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequences_1_ = train_sequences_1_[40000:]\n",
    "train_sequences_1_ = train_sequences_1_[:40000]\n",
    "\n",
    "val_sequences_2_ = train_sequences_2_[40000:]\n",
    "train_sequences_2_ = train_sequences_2_[:40000]\n",
    "\n",
    "val_sequences_3_ = train_sequences_3_[40000:]\n",
    "train_sequences_3_ = train_sequences_3_[:40000]\n",
    "\n",
    "\n",
    "\n",
    "val_sequences_1 = train_sequences_1[40000:]\n",
    "train_sequences_1 = train_sequences_1[:40000]\n",
    "\n",
    "val_sequences_2 = train_sequences_2[40000:]\n",
    "train_sequences_2 = train_sequences_2[:40000]\n",
    "\n",
    "val_sequences_3 = train_sequences_3[40000:]\n",
    "train_sequences_3 = train_sequences_3[:40000]\n",
    "\n",
    "start_end_val = start_end[40000:]\n",
    "start_end_train = start_end[:40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import add\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers.wrappers import Bidirectional \n",
    "from keras.layers import multiply, average\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras.layers.core import *\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import *\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "INPUT_DIM = 2\n",
    "TIME_STEPS = 20\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = False\n",
    "APPLY_ATTENTION_BEFORE_LSTM = False\n",
    " \n",
    "\n",
    "def attention_3d_block230(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, 230))(a)\n",
    "    a = Dense(230, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec230')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul230', mode='mul')\n",
    "    return output_attention_mul\n",
    "\n",
    "def attention_3d_block200(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, 200))(a)\n",
    "    a = Dense(200, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec200')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul200', mode='mul')\n",
    "    return output_attention_mul\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice(x):\n",
    "    return x[:, :200, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice1(x):\n",
    "    return x[:, 200:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice2(x):\n",
    "    return x[:, :20, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(x, i):\n",
    "    return x[:, i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "from keras.layers import multiply, Multiply\n",
    "LSTM_DIM=100\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(LSTM_DIM, self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):        \n",
    "        #return tf.multiply(x, self.kernel)\n",
    "        return x*self.kernel\n",
    "\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_sqrt(x):\n",
    "    return K.sqrt(x)\n",
    "\n",
    "def K_mul(x):\n",
    "    return x[0]*x[1]\n",
    "\n",
    "def K_cos(x):\n",
    "    return x[0] / (x[1] + x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import multiply, average,Multiply\n",
    "from keras.layers import dot, merge\n",
    "\n",
    "LSTM_DIM=100\n",
    "W_DIM = 90\n",
    "\n",
    "ch_lstm_p = LSTM(50, return_sequences=False)\n",
    "ch_input_p = Input(shape=(200,20,), dtype='int32')\n",
    "ch_emb_p = TimeDistributed(embedding_char1)(ch_input_p)\n",
    "ch_repr_p = TimeDistributed(ch_lstm_p)(ch_emb_p)\n",
    "\n",
    "\n",
    "ch_lstm_q = LSTM(50, return_sequences=False)\n",
    "ch_input_q = Input(shape=(30,20,), dtype='int32')\n",
    "ch_emb_q = TimeDistributed(embedding_char1)(ch_input_q)\n",
    "ch_repr_q = TimeDistributed(ch_lstm_q)(ch_emb_q)\n",
    "\n",
    "\n",
    "lstm_layer1_1 = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=True, go_backwards=False)\n",
    "lstm_layer1_1_rev = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=True, go_backwards=True)\n",
    "\n",
    "lstm_layer1_2 = Bidirectional(LSTM(200, dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
    "lstm_layer1_3 = Bidirectional(LSTM(200, dropout=0.5, recurrent_dropout=0.4,return_sequences=True))\n",
    "\n",
    "lstm_layer2_1 = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=True, go_backwards=False)\n",
    "lstm_layer2_1_rev = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=True, go_backwards=True)\n",
    "\n",
    "lstm_layer2_1_ = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=False, go_backwards=False)\n",
    "lstm_layer2_1_rev_ = LSTM(LSTM_DIM, dropout=0.5, recurrent_dropout=0.5,return_sequences=False, go_backwards=True)\n",
    "#lstm_layer2_2 = LSTM(200, dropout=0.2, recurrent_dropout=0.2,return_sequences=False)\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_PARAGRAPH_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer1(sequence_1_input)\n",
    "embedded_sequences_1 = concatenate([embedded_sequences_1, ch_repr_p],axis=2)\n",
    "\n",
    "\n",
    "p = lstm_layer1_1(embedded_sequences_1)\n",
    "p_rev = lstm_layer1_1_rev(embedded_sequences_1)\n",
    "\n",
    "p1 = Reshape((200, LSTM_DIM, 1))(p)\n",
    "p1 = concatenate([p1]*W_DIM, axis=3)\n",
    "\n",
    "p2 = Reshape((200, LSTM_DIM, 1))(p_rev)\n",
    "p2 = concatenate([p2]*W_DIM, axis=3)\n",
    "\n",
    "p3 = Reshape((200, LSTM_DIM, 1))(p)\n",
    "p3 = concatenate([p3]*W_DIM, axis=3)\n",
    "p3 = Reshape((200, LSTM_DIM, W_DIM, 1))(p3)\n",
    "p3 = concatenate([p3]*30, axis=4)\n",
    "p3 = Reshape((200, 30, LSTM_DIM,W_DIM))(p3)\n",
    "\n",
    "p4 = Reshape((200, LSTM_DIM, 1))(p_rev)\n",
    "p4 = concatenate([p4]*W_DIM, axis=3)\n",
    "p4 = Reshape((200, LSTM_DIM, W_DIM, 1))(p4)\n",
    "p4 = concatenate([p4]*30, axis=4)\n",
    "p4 = Reshape((200, 30, LSTM_DIM,W_DIM))(p4)\n",
    "\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_QUESTION_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer2(sequence_2_input)\n",
    "embedded_sequences_2 = concatenate([embedded_sequences_2, ch_repr_q],axis=2)\n",
    "\n",
    "\n",
    "q_ = lstm_layer2_1_(embedded_sequences_2)\n",
    "q_rev_ = lstm_layer2_1_rev_(embedded_sequences_2)\n",
    "q = lstm_layer2_1(embedded_sequences_2)\n",
    "q_rev = lstm_layer2_1_rev(embedded_sequences_2)\n",
    "\n",
    "q1 = Reshape((1, LSTM_DIM))(q_)\n",
    "q1 = concatenate([q1]*200, axis=1)\n",
    "q1 = Reshape((200, LSTM_DIM, 1))(q1)\n",
    "q1 = concatenate([q1]*W_DIM, axis=3)\n",
    "\n",
    "q2 = Reshape((1, LSTM_DIM))(q_rev_)\n",
    "q2 = concatenate([q2]*200, axis=1)\n",
    "q2 = Reshape((200, LSTM_DIM, 1))(q2)\n",
    "q2 = concatenate([q2]*W_DIM, axis=3)\n",
    "\n",
    "q3 = Reshape((30, LSTM_DIM))(q)\n",
    "q3 = concatenate([q3]*200, axis=1)\n",
    "q3 = Reshape((200, 30, LSTM_DIM, 1))(q3)\n",
    "q3 = concatenate([q3]*W_DIM, axis=4)\n",
    "\n",
    "q4 = Reshape((30, LSTM_DIM))(q_rev)\n",
    "q4 = concatenate([q4]*200, axis=1)\n",
    "q4 = Reshape((200, 30, LSTM_DIM, 1))(q4)\n",
    "q4 = concatenate([q4]*W_DIM, axis=4)\n",
    "\n",
    "#########################################\n",
    "W1 = MyLayer(W_DIM)\n",
    "p1 = W1(p1)\n",
    "q1 = W1(q1)\n",
    "\n",
    "m1 = Lambda(K_mul)([p1, q1])\n",
    "m1 = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(m1)\n",
    "\n",
    "p1_norm = Lambda(K_mul)([p1,p1])\n",
    "p1_norm = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(p1_norm)\n",
    "p1_norm = Lambda(K_sqrt)(p1_norm)\n",
    "\n",
    "q1_norm = Lambda(K_mul)([q1,q1])\n",
    "q1_norm = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(q1_norm)\n",
    "q1_norm = Lambda(K_sqrt)(q1_norm)\n",
    "\n",
    "m1 = Lambda(K_cos)([m1, p1_norm, q1_norm])\n",
    "\n",
    "#########################################\n",
    "W2 = MyLayer(W_DIM)\n",
    "p2 = W2(p2)\n",
    "q2 = W2(q2)\n",
    "\n",
    "m2 = Lambda(K_mul)([p2, q2])\n",
    "m2 = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(m2)\n",
    "\n",
    "p2_norm = Lambda(K_mul)([p2,p2])\n",
    "p2_norm = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(p2_norm)\n",
    "p2_norm = Lambda(K_sqrt)(p2_norm)\n",
    "\n",
    "q2_norm = Lambda(K_mul)([q2,q2])\n",
    "q2_norm = Lambda(lambda x: K.sum(x, axis=2), output_shape=(200, W_DIM))(q2_norm)\n",
    "q2_norm = Lambda(K_sqrt)(q2_norm)\n",
    "\n",
    "m2 = Lambda(K_cos)([m2, p2_norm, q2_norm])\n",
    "#########################################\n",
    "\n",
    "W3 = MyLayer(W_DIM)\n",
    "p3 = W3(p3)\n",
    "q3 = W3(q3)\n",
    "\n",
    "m3 = Lambda(K_mul)([p3, q3])\n",
    "m3 = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(m3)\n",
    "\n",
    "p3_norm = Lambda(K_mul)([p3,p3])\n",
    "p3_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(p3_norm)\n",
    "p3_norm = Lambda(K_sqrt)(p3_norm)\n",
    "\n",
    "q3_norm = Lambda(K_mul)([q3,q3])\n",
    "q3_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(q3_norm)\n",
    "q3_norm = Lambda(K_sqrt)(q3_norm)\n",
    "\n",
    "m3 = Lambda(K_cos)([m3, p3_norm, q3_norm])\n",
    "m3 = Lambda(lambda x: K.max(x, axis=2), output_shape=(200, W_DIM))(m3)\n",
    "#########################################\n",
    "W4 = MyLayer(W_DIM)\n",
    "p4 = W4(p4)\n",
    "q4 = W4(q4)\n",
    "\n",
    "m4 = Lambda(K_mul)([p4, q4])\n",
    "m4 = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(m4)\n",
    "\n",
    "p4_norm = Lambda(K_mul)([p4,p4])\n",
    "p4_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(p4_norm)\n",
    "p4_norm = Lambda(K_sqrt)(p4_norm)\n",
    "\n",
    "q4_norm = Lambda(K_mul)([q4,q4])\n",
    "q4_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(q4_norm)\n",
    "q4_norm = Lambda(K_sqrt)(q4_norm)\n",
    "\n",
    "m4 = Lambda(K_cos)([m4, p4_norm, q4_norm])\n",
    "m4 = Lambda(lambda x: K.max(x, axis=2), output_shape=(200, W_DIM))(m4)\n",
    "#########################################\n",
    "\n",
    "W5 = MyLayer(W_DIM)\n",
    "p5 = W3(p3)\n",
    "q5 = W3(q3)\n",
    "\n",
    "m5 = Lambda(K_mul)([p5, q5])\n",
    "m5 = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(m5)\n",
    "\n",
    "p5_norm = Lambda(K_mul)([p5,p5])\n",
    "p5_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(p5_norm)\n",
    "p5_norm = Lambda(K_sqrt)(p5_norm)\n",
    "\n",
    "q5_norm = Lambda(K_mul)([q5,q5])\n",
    "q5_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(q5_norm)\n",
    "q5_norm = Lambda(K_sqrt)(q5_norm)\n",
    "\n",
    "m5 = Lambda(K_cos)([m5, p5_norm, q5_norm])\n",
    "m5 = Lambda(lambda x: K.mean(x, axis=2), output_shape=(200, W_DIM))(m5)\n",
    "#########################################\n",
    "W6 = MyLayer(W_DIM)\n",
    "p6 = W4(p4)\n",
    "q6 = W4(q4)\n",
    "\n",
    "m6 = Lambda(K_mul)([p6, q6])\n",
    "m6 = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(m6)\n",
    "\n",
    "p6_norm = Lambda(K_mul)([p6,p6])\n",
    "p6_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(p6_norm)\n",
    "p6_norm = Lambda(K_sqrt)(p6_norm)\n",
    "\n",
    "q6_norm = Lambda(K_mul)([q6,q6])\n",
    "q6_norm = Lambda(lambda x: K.sum(x, axis=3), output_shape=(200, 30, W_DIM))(q6_norm)\n",
    "q6_norm = Lambda(K_sqrt)(q6_norm)\n",
    "\n",
    "m6 = Lambda(K_cos)([m6, p6_norm, q6_norm])\n",
    "m6 = Lambda(lambda x: K.mean(x, axis=2), output_shape=(200, W_DIM))(m6)\n",
    "#########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "merged = concatenate([p,m1,m2,m3,m4,m5,m6],axis=2)\n",
    "merged = lstm_layer1_2(merged)\n",
    "#merged = lstm_layer1_3(merged)\n",
    "#merged = attention_3d_block200(merged)\n",
    "merged = Dense(240, activation='relu')(merged)\n",
    "merged = Dropout(0.1)(merged)\n",
    "merged = Dense(120, activation='relu')(merged)\n",
    "merged = Dropout(0.2)(merged)\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_38/Max:0' shape=(?, 200, 70) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_68/Sqrt:0' shape=(?, 200, 30, 70) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_46/concat:0' shape=(?, 200, 30, 90, 70) dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lambda_60/Sqrt:0' shape=(?, 200, 70) dtype=float32>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "adam = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "\n",
    "model = Model(inputs=[sequence_1_input,ch_input_p, sequence_2_input, ch_input_q], \\\n",
    "        outputs=[preds])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer=adam,\n",
    "        metrics=['acc'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('IBM_char.h5', save_best_only=True, save_weights_only=True, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 230, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([x_train1, x_train2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('b1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_generator(batch_size, tr_p, tr_p_, tr_q, tr_q_, st_end):\n",
    "    while(1):\n",
    "        idx = np.array(range(tr_p.shape[0]))\n",
    "        np.random.shuffle(idx)\n",
    "        x_train1 = np.zeros([batch_size, MAX_PARAGRAPH_LENGTH])\n",
    "        x_train1_ = np.zeros([batch_size, MAX_PARAGRAPH_LENGTH, 20])\n",
    "\n",
    "        x_train2 = np.zeros([batch_size, 30])\n",
    "        x_train2_ = np.zeros([batch_size, 30, 20])\n",
    "        #x_train3 = np.zeros([batch_size, 30])\n",
    "\n",
    "        y_train = np.zeros([batch_size,200,1])\n",
    "\n",
    "        curr_batch_size = 0\n",
    "        for i in range(batch_size):\n",
    "            y = []\n",
    "            for j in range(200):\n",
    "                #y += [j == st_end[idx[i]][0]]\n",
    "                #y += [[j == st_end[idx[i]][0], j == st_end[idx[i]][1]- 1]]\n",
    "                y += [j >= st_end[idx[i]][0] and j < st_end[idx[i]][1]]\n",
    "            x_train1[i] = tr_p[idx[i]]\n",
    "            x_train2[i] = tr_q[idx[i]]\n",
    "            \n",
    "            x_train1_[i] = tr_p_[idx[i]]\n",
    "            x_train2_[i] = tr_q_[idx[i]]\n",
    "\n",
    "            \n",
    "            y_train[i] = np.array(y).reshape(200,1)\n",
    "\n",
    "        yield ([x_train1, x_train1_, x_train2, x_train2_], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 30, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_3_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: The semantics of the Keras 2 argument  `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Update your method calls accordingly.\n",
      "  \n",
      "/home/afattahov/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=100, epochs=40, validation_steps=100, verbose=1, callbacks=[<keras.ca...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 150s - loss: 0.2731 - acc: 0.9764 - val_loss: 0.3022 - val_acc: 0.9812\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 145s - loss: 0.2394 - acc: 0.9851 - val_loss: 0.2813 - val_acc: 0.9825\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 147s - loss: 0.2531 - acc: 0.9843 - val_loss: 0.2587 - val_acc: 0.9839\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 146s - loss: 0.2458 - acc: 0.9847 - val_loss: 0.2619 - val_acc: 0.9837\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 145s - loss: 0.2555 - acc: 0.9841 - val_loss: 0.2635 - val_acc: 0.9836\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 144s - loss: 0.2547 - acc: 0.9842 - val_loss: 0.2651 - val_acc: 0.9835\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 146s - loss: 0.2805 - acc: 0.9826 - val_loss: 0.2692 - val_acc: 0.9833\n",
      "Epoch 8/40\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.2320 - acc: 0.9856"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "model.fit_generator(all_generator(batch_size, train_sequences_1,train_sequences_1_,train_sequences_2,train_sequences_2_,start_end_train),\n",
    "                    samples_per_epoch=100,\n",
    "                    validation_data=all_generator(batch_size,val_sequences_1,val_sequences_1_,val_sequences_2,val_sequences_2_,start_end_val),\n",
    "                    nb_val_samples=100,\n",
    "                    nb_epoch=40,\n",
    "                    verbose=1,\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('b2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([x_train1,x_train2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 200, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = len(val_sequences_1)\n",
    "batch = 2\n",
    "x_train1 = np.zeros([batch,MAX_PARAGRAPH_LENGTH])\n",
    "x_train2 = np.zeros([batch,30])\n",
    "\n",
    "x_train1_ = np.zeros([batch,MAX_PARAGRAPH_LENGTH, 20])\n",
    "x_train2_ = np.zeros([batch,30, 20])\n",
    "\n",
    "st_end = np.zeros([batch,2])\n",
    "\n",
    "for i in range(batch):\n",
    "    x_train1[i] = val_sequences_1[i]\n",
    "    x_train2[i] = val_sequences_2[i]\n",
    "        \n",
    "    x_train1_[i] = val_sequences_1_[i]\n",
    "    x_train2_[i] = val_sequences_2_[i]\n",
    "    \n",
    "    st_end[i] = start_end_val[i]\n",
    "\n",
    "    \n",
    "    \n",
    "pred = model.predict([x_train1, x_train1_, x_train2, x_train2_])    \n",
    "    \n",
    "real_arr = []\n",
    "for i in range(batch):\n",
    "    real = []\n",
    "    for j in range(200):\n",
    "        real += [float(j >= st_end[i][0] and j < st_end[i][1]) / 5.0]\n",
    "        #real += [float(j == st_end[i][1]-1) / 5.0]\n",
    "\n",
    "    tmp = real\n",
    "    real_arr += [tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = len(val_sequences_1)\n",
    "batch = 20\n",
    "x_train1 = np.zeros([batch,MAX_PARAGRAPH_LENGTH])\n",
    "x_train2 = np.zeros([batch,30])\n",
    "st_end = np.zeros([batch,2])\n",
    "\n",
    "for i in range(batch):\n",
    "    x_train1[i] = train_sequences_1[i]\n",
    "    x_train2[i] = train_sequences_2[i]\n",
    "    st_end[i] = start_end_train[i]\n",
    "\n",
    "    \n",
    "    \n",
    "pred = model.predict([x_train1,x_train2])    \n",
    "    \n",
    "real_arr = []\n",
    "for i in range(batch):\n",
    "    real = []\n",
    "    for j in range(200):\n",
    "        real += [float(j >= st_end[i][0] and j < st_end[i][1]) / 5.0]\n",
    "        #real += [float(j == st_end[i][1]-1) / 5.0]\n",
    "\n",
    "    tmp = real\n",
    "    real_arr += [tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/afattahov/tf3/lib/python3.5/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['real']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNQrRJgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f30f2723eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSH65FNDjyJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f319ca65048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "for i in range(batch):\n",
    "    #plt.plot(range(200), pred2[i].reshape(200))\n",
    "    plt.plot(range(200), pred[i].reshape(200))\n",
    "    plt.plot(range(200), real_arr[i])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pred > 0.09\n",
    "\n",
    "predict = []\n",
    "for i in range(len(val_sequences_1)):\n",
    "    predict += [val_sequences_1[i][mask[i]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3182,     5,  3324, 15426,     2, 25770,  3836,  3665, 33643,\n",
       "       38453,  1475,   962,   463,     3, 38478,  5317,  1336,  8667,\n",
       "           2, 13692], dtype=int32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(prediction, ground_truth):\n",
    "    if len(prediction) == 0:\n",
    "        return 0\n",
    "    if len(ground_truth) == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * len(list(set(prediction) & set(ground_truth))) / len(prediction)\n",
    "    recall = 1.0 * len(list(set(prediction) & set(ground_truth))) / len(ground_truth)\n",
    "    if precision + recall != 0:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46153846153846156"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(tmp, tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(predict[0], val_sequences_3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = []\n",
    "for i in range(len(predict)):\n",
    "    f1 += [f1_score(predict[i], val_sequences_3[i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094258449787767276"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
